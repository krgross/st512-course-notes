<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 ANCOVA | ST 512 course notes</title>
  <meta name="description" content="Course notes for ST 512, Statistical Methods for Researchers II." />
  <meta name="generator" content="bookdown 0.30 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 ANCOVA | ST 512 course notes" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Course notes for ST 512, Statistical Methods for Researchers II." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 ANCOVA | ST 512 course notes" />
  
  <meta name="twitter:description" content="Course notes for ST 512, Statistical Methods for Researchers II." />
  

<meta name="author" content="Kevin Gross" />


<meta name="date" content="2022-12-09" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="regression-models-with-several-predictors.html"/>
<link rel="next" href="bibliography.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#philosophy"><i class="fa fa-check"></i>Philosophy</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#scope-and-coverage"><i class="fa fa-check"></i>Scope and coverage</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#mathematical-level"><i class="fa fa-check"></i>Mathematical level</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#computing"><i class="fa fa-check"></i>Computing</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#format-of-the-notes"><i class="fa fa-check"></i>Format of the notes</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgments"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>1</b> Simple linear regression</a>
<ul>
<li class="chapter" data-level="1.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#the-basics-of-slr"><i class="fa fa-check"></i><b>1.1</b> The basics of SLR</a></li>
<li class="chapter" data-level="1.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#least-squares-estimation"><i class="fa fa-check"></i><b>1.2</b> Least-squares estimation</a></li>
<li class="chapter" data-level="1.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#inference-for-the-slope"><i class="fa fa-check"></i><b>1.3</b> Inference for the slope</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#standard-errors"><i class="fa fa-check"></i><b>1.3.1</b> Standard errors</a></li>
<li class="chapter" data-level="1.3.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#confidence-intervals"><i class="fa fa-check"></i><b>1.3.2</b> Confidence intervals</a></li>
<li class="chapter" data-level="1.3.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#statistical-hypothesis-tests"><i class="fa fa-check"></i><b>1.3.3</b> Statistical hypothesis tests</a></li>
<li class="chapter" data-level="1.3.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#inference-for-the-intercept"><i class="fa fa-check"></i><b>1.3.4</b> Inference for the intercept</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#sums-of-squares-decomposition-and-r2"><i class="fa fa-check"></i><b>1.4</b> Sums of squares decomposition and <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="1.5" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#fitting-the-slr-model-in-r"><i class="fa fa-check"></i><b>1.5</b> Fitting the SLR model in R</a></li>
<li class="chapter" data-level="1.6" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#diagnostic-plots"><i class="fa fa-check"></i><b>1.6</b> Diagnostic plots</a></li>
<li class="chapter" data-level="1.7" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#consequences-of-violating-model-assumptions-and-possible-fixes"><i class="fa fa-check"></i><b>1.7</b> Consequences of violating model assumptions, and possible fixes</a></li>
<li class="chapter" data-level="1.8" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#prediction-with-regression-models"><i class="fa fa-check"></i><b>1.8</b> Prediction with regression models</a></li>
<li class="chapter" data-level="1.9" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#regression-design"><i class="fa fa-check"></i><b>1.9</b> Regression design</a></li>
<li class="chapter" data-level="" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#appendix-regression-models-in-sas-proc-reg"><i class="fa fa-check"></i>Appendix: Regression models in SAS PROC REG</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="regression-models-with-several-predictors.html"><a href="regression-models-with-several-predictors.html"><i class="fa fa-check"></i><b>2</b> Regression models with several predictors</a>
<ul>
<li class="chapter" data-level="2.1" data-path="regression-models-with-several-predictors.html"><a href="regression-models-with-several-predictors.html#multiple-regression-basics"><i class="fa fa-check"></i><b>2.1</b> Multiple regression basics</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="regression-models-with-several-predictors.html"><a href="regression-models-with-several-predictors.html#the-multiple-regression-model"><i class="fa fa-check"></i><b>2.1.1</b> The multiple regression model</a></li>
<li class="chapter" data-level="2.1.2" data-path="regression-models-with-several-predictors.html"><a href="regression-models-with-several-predictors.html#interpreting-partial-regression-coefficients."><i class="fa fa-check"></i><b>2.1.2</b> Interpreting partial regression coefficients.</a></li>
<li class="chapter" data-level="2.1.3" data-path="regression-models-with-several-predictors.html"><a href="regression-models-with-several-predictors.html#statistical-inference-for-partial-regression-coefficients"><i class="fa fa-check"></i><b>2.1.3</b> Statistical inference for partial regression coefficients</a></li>
<li class="chapter" data-level="2.1.4" data-path="regression-models-with-several-predictors.html"><a href="regression-models-with-several-predictors.html#prediction"><i class="fa fa-check"></i><b>2.1.4</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="regression-models-with-several-predictors.html"><a href="regression-models-with-several-predictors.html#categorical-predictors"><i class="fa fa-check"></i><b>2.2</b> Categorical predictors</a></li>
<li class="chapter" data-level="2.3" data-path="regression-models-with-several-predictors.html"><a href="regression-models-with-several-predictors.html#interactions-between-predictors"><i class="fa fa-check"></i><b>2.3</b> Interactions between predictors</a></li>
<li class="chapter" data-level="2.4" data-path="regression-models-with-several-predictors.html"><a href="regression-models-with-several-predictors.html#testing-multiple-regression-coefficients-at-once"><i class="fa fa-check"></i><b>2.4</b> Testing multiple regression coefficients at once</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="regression-models-with-several-predictors.html"><a href="regression-models-with-several-predictors.html#model-utility-tests"><i class="fa fa-check"></i><b>2.4.1</b> Model utility tests</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="regression-models-with-several-predictors.html"><a href="regression-models-with-several-predictors.html#multi-collinearity"><i class="fa fa-check"></i><b>2.5</b> (Multi-)Collinearity</a></li>
<li class="chapter" data-level="2.6" data-path="regression-models-with-several-predictors.html"><a href="regression-models-with-several-predictors.html#variable-selection-choosing-the-best-model"><i class="fa fa-check"></i><b>2.6</b> Variable selection: Choosing the best model</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="regression-models-with-several-predictors.html"><a href="regression-models-with-several-predictors.html#ranking-methods"><i class="fa fa-check"></i><b>2.6.1</b> Ranking methods</a></li>
<li class="chapter" data-level="2.6.2" data-path="regression-models-with-several-predictors.html"><a href="regression-models-with-several-predictors.html#sequential-methods"><i class="fa fa-check"></i><b>2.6.2</b> Sequential methods</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="regression-models-with-several-predictors.html"><a href="regression-models-with-several-predictors.html#leverage-influential-points-and-standardized-residuals"><i class="fa fa-check"></i><b>2.7</b> Leverage, influential points, and standardized residuals</a></li>
<li class="chapter" data-level="" data-path="regression-models-with-several-predictors.html"><a href="regression-models-with-several-predictors.html#appendix-regression-as-a-linear-algebra-problem"><i class="fa fa-check"></i>Appendix: Regression as a linear algebra problem</a>
<ul>
<li class="chapter" data-level="" data-path="regression-models-with-several-predictors.html"><a href="regression-models-with-several-predictors.html#singular-or-pathological-design-matrices"><i class="fa fa-check"></i>Singular, or pathological, design matrices</a></li>
<li class="chapter" data-level="" data-path="regression-models-with-several-predictors.html"><a href="regression-models-with-several-predictors.html#additional-results"><i class="fa fa-check"></i>Additional results</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ancova.html"><a href="ancova.html"><i class="fa fa-check"></i><b>3</b> ANCOVA</a></li>
<li class="chapter" data-level="" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i>Bibliography</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">ST 512 course notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ancova" class="section level1 hasAnchor" number="3">
<h1><span class="header-section-number">Chapter 3</span> ANCOVA<a href="ancova.html#ancova" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Statistical tests compare the estimated magnitude of a treatment effect to the precision with which that effect is estimated. Often, the magnitude of a treatment effect is set by nature. Thus, if we want to increase our chances of observing a statistically significant result, we must find ways to make our estimates more precise. Statistical precision is a function of (a) the degree of replication and (b) the experimental error. Thus, precision can be improved by including more replicates or reducing experimental error.</p>
<p>One technique for reducing experimental error and hence increasing precision is to use a covariate that accounts for heterogeneity among EUs. Inclusion of covariates in ANOVA models is called the analysis of covariance, or ANCOVA. Mathematically, ANCOVA is no different from regression with both quantitative and categorical predictors. However, the emphases differ depending on the context. In ANCOVA, our primary focus is analyzing the differences among the treatment groups. We model the relationship between the response and the covariate to gain a more precise estimate of the differences among treatment groups, but the relationship between the response and the covariate is of secondary interest at best. In regression, both quantitative and categorical predictors are on equal footing, and we have no reason to prioritize one versus the other.</p>
<p>Example: <span class="citation">Partridge and Farquhar (<a href="#ref-partridge1981sexual" role="doc-biblioref">1981</a>)</span>; as reported in Hanley &amp; Shapiro, 1994) conducted an experiment to determine if increased reproduction reduces longevity in male fruitflies. (Such a cost had already been established for females.) There were 5 experimental treatments: male fruitflies reared alone, reared with 1 or 8 non-mated females, and reared with 1 or 8 recently mated females. 25 male flies were assigned to each treatment. The data recorded are longevity (days lived) and thorax length. The data are shown below:</p>
<p><img src="05-Ancova_files/figure-html/unnamed-chunk-2-1.png" width="720" style="display: block; margin: auto;" />
Suppose we analyze these data with a one-way ANOVA and ignore differences in the sizes of the flies:</p>
<pre><code>proc glm;
  class trt;
  model life = trt;
run;

The GLM Procedure
Dependent Variable: life

                                        Sum of
Source                      DF         Squares     Mean Square    F Value    Pr &gt; F
Model                        4     11939.28000      2984.82000      13.61    &lt;.0001
Error                      120     26313.52000       219.27933
Corrected Total            124     38252.80000

Source                      DF     Type III SS     Mean Square    F Value    Pr &gt; F
trt                          4     11939.28000      2984.82000      13.61    &lt;.0001</code></pre>
<p>Although the <span class="math inline">\(F\)</span>-test for treatment is significant, notice that <span class="math inline">\(MS_{Error} = 219.3\)</span>. Of course, the plot above suggests that much of the variation in lifespan among flies in the same treatment group can be explained by variation in fly size. Suppose we include thorax size as a covariate:</p>
<pre><code>proc glm;
  class trt;
  model life = thorax trt;
run;

The GLM Procedure
Dependent Variable: life

Sum of
Source                      DF         Squares     Mean Square    F Value    Pr &gt; F
Model                        5     25108.13347      5021.62669      45.46    &lt;.0001
Error                      119     13144.66653       110.45938
Corrected Total            124     38252.80000

Source                      DF     Type III SS     Mean Square    F Value    Pr &gt; F
thorax                       1     13168.85347     13168.85347     119.22    &lt;.0001
trt                          4      9611.49254      2402.87314      21.75    &lt;.0001</code></pre>
<p>The experimental error has been cut in half: <span class="math inline">\(MS_{Error} = 110.5\)</span>. The experimental error has been reduced because the covariate thorax size has accounted for half of the previously unexplained variation. Note that including the covariate is also “cheap”, in the sense that it only costs a single df.</p>
<p>This is an example of an Analysis of Covariance (ANCOVA) model. We can write the model using the following mathematical notation:</p>
<ul>
<li><span class="math inline">\(y_{ij}\)</span>: observation <span class="math inline">\(j\)</span> from treatment group <span class="math inline">\(i\)</span></li>
<li><span class="math inline">\(x_{ij}\)</span>: value of the covariate for observation <span class="math inline">\(j\)</span> from treatment group <span class="math inline">\(i\)</span></li>
</ul>
<p>Equipped with this notation, we can write the model as
<span class="math display">\[
y_{ij} =\mu +\alpha_{i} +\beta x_{ij} +\varepsilon_{ij}
\]</span>
where <span class="math inline">\(\mu\)</span> is the reference level, <span class="math inline">\(\alpha_i\)</span> is the effect parameter for group <span class="math inline">\(i\)</span> (subject to one of the standard constraints), <span class="math inline">\(\beta\)</span> is a regression slope that quantifies the (linear) relationship between the covariate and the response, and <span class="math inline">\(\varepsilon_{ij}\)</span> is the residual error with the standard assumptions (independence, normality, equal variance).</p>
<p>Geometrically, we can think of this model as specifying a regression line for each level of the experimental treatment. Importantly, without an interaction between the treatment and the covariate, the lines are parallel and differ only in their intercept. That is to say, the differences among the various treatments are the same regardless of the value of the covariate. We have encountered this type of model before in a regression context. In ANCOVA, our primary interest is in testing for a treatment effect after using the covariate to control for variability among EUs.</p>
<p>Before going any further with the fly data, we observe that residual plots clearly indicate a non-constant variance problem. (Notice that the inclusion of a covariate makes the residual plots substantially richer.) Here is how we might generate a plot of residuals vs. fitted values in PROC GLM and PROC GPLOT:</p>
<pre><code>proc glm;
  class trt;
  model life = thorax trt;
  output out=flyout p=pred r=resid;
run;

proc gplot data = flyout;
  plot resid * pred / vref = 0;
run;</code></pre>
<p><img src="05-Ancova_files/figure-html/unnamed-chunk-3-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Log-transforming the response stabilizes the variance nicely:
<img src="05-Ancova_files/figure-html/unnamed-chunk-4-1.png" width="768" style="display: block; margin: auto;" />
We re-do the analysis with a log-transformed response:</p>
<pre><code>proc glm;
  class trt;
  model loglife = thorax trt;
run;

The GLM Procedure
Dependent Variable: loglife

                                        Sum of
Source                      DF         Squares     Mean Square    F Value    Pr &gt; F
Model                        5      2.01797568      0.40359514      57.43    &lt;.0001
Error                      119      0.83630432      0.00702777
Corrected Total            124      2.85428000

Source                      DF     Type III SS     Mean Square    F Value    Pr &gt; F
thorax                       1      1.03374368      1.03374368     147.09    &lt;.0001
trt                          4      0.78904783      0.19726196      28.07    &lt;.0001</code></pre>
<p>The residual plot looks much better:
<img src="05-Ancova_files/figure-html/unnamed-chunk-5-1.png" width="480" style="display: block; margin: auto;" />
The Type III SS can be used for <span class="math inline">\(F\)</span>-tests that test for a treatment effect (<span class="math inline">\(H_0\)</span>: <span class="math inline">\(\alpha_{1} =\alpha_{2} =...=\alpha_{p} =0\)</span>) and to test for the significance of the linear relationship between the covariate and the response (<span class="math inline">\(H_0\)</span>: <span class="math inline">\(\beta=0\)</span>). Again, our main interest is in comparing the treatment groups. Here, the <span class="math inline">\(F\)</span>-test for the treatment groups suggests that there is strong evidence of an effect of treatment on longevity (<span class="math inline">\(F_{4,119}=28.07\)</span>, <span class="math inline">\(p&lt;.0001\)</span>).</p>
<p>In ANOVA, we spent substantial energy analyzing the average responses for the different treatment groups. In ANCOVA, we expect the average response for a treatment group to depend on the value of the covariate. Thus, we can define {} (or what we might just call adjusted treatment means) as the average response for a given treatment group, and for a given value of the covariate. In notation, we might write the adjusted treatment mean for treatment group <span class="math inline">\(i\)</span> and covariate value <span class="math inline">\(x\)</span> as <span class="math inline">\(\mu_i \left(x\right)\)</span> . We can estimate this adjusted treatment mean in the following way:
<span class="math display">\[
\hat{\mu }_i \left(x\right)=\bar{y}_{i+} -\hat{\beta }(\bar{x}_{i+} -x)
\]</span>
The default choice is to calculate an adjusted treatment mean at the average value of the covariate observed in the data set, that is,
<span class="math display">\[
\hat{\mu }_i \left(\bar{x}_{++} \right)=\bar{y}_{i+} -\hat{\beta }(\bar{x}_{i+} -\bar{x}_{++} )
\]</span>
We can find the value of <span class="math inline">\(\hat{\beta }\)</span> using the SOLUTION option to the MODEL statement in PROC GLM. We can find the raw treatment means and the means of the covariate values using the MEANS statement:</p>
<pre><code>proc glm data = fly;
  class trt;
  model loglife = trt thorax / solution;
  means trt;
run;

                                       Standard
Parameter            Estimate             Error    t Value    Pr &gt; |t|

Intercept         0.600921260 B      0.08112643       7.41      &lt;.0001
trt       a       0.181879457 B      0.02397873       7.59      &lt;.0001
trt       m1      0.204394280 B      0.02384687       8.57      &lt;.0001
trt       m8      0.219661249 B      0.02371772       9.26      &lt;.0001
trt       u1      0.127954099 B      0.02400289       5.33      &lt;.0001
trt       u8      0.000000000 B       .                .         .
thorax            1.203348424        0.09921873      12.13      &lt;.0001

NOTE: The X&#39;X matrix has been found to be singular, and a generalized inverse was used to
solve the normal equations.  Terms whose estimates are followed by the letter &#39;B&#39;
are not uniquely estimable.

The GLM Procedure

Level of            -----------loglife-----------     ------------thorax-----------
trt           N             Mean          Std Dev             Mean          Std Dev

a            25       1.78880000       0.11515642       0.83600000       0.08426150
m1           25       1.79880000       0.10763828       0.82560000       0.06988562
m8           25       1.79000000       0.11221260       0.80560000       0.08155162
u1           25       1.73680000       0.13145722       0.83760000       0.07055022
u8           25       1.56360000       0.15231218       0.80000000       0.07831560</code></pre>
<p>For example, suppose we were to calculate the adjusted treatment mean for the flies reared alone. Our calculation (using the log-transformed data) gives
<span class="math display">\[\begin{eqnarray*}
    \hat{\mu }_i \left(\bar{x}_{++} \right) &amp; = &amp; \bar{y}_{i+} -\hat{\beta }(\bar{x}_{i+} -\bar{x}_{++} ) \\
    &amp; = &amp;  1.789-(1.203) \times (0.836-0.821) \\
    &amp; = &amp;  1.771
\end{eqnarray*}\]</span>
Notice that flies assigned to the alone treatment were slightly larger than the other flies in the experiment. Because there is a positive association between size and lifetime, the adjusted treatment mean for the alone treatment should be slightly <em>less</em> than the raw mean. In PROC GLM, we can calculate adjusted treatment means using the LSMEANS statement. We can also perform multiple comparisons among the adjusted treatment means, although the syntax differs a bit:</p>
<pre><code>proc glm data = fly;
  class trt;
  model loglife = trt thorax;
  lsmeans trt / pdiff adjust = tukey;
run;    

The GLM Procedure
Least Squares Means
Adjustment for Multiple Comparisons: Tukey-Kramer

loglife      LSMEAN
trt          LSMEAN      Number

a        1.77070164           1
m1       1.79321646           2
m8       1.80848343           3
u1       1.71677628           4
u8       1.58882218           5

Least Squares Means for effect trt
Pr &gt; |t| for H0: LSMean(i)=LSMean(j)

Dependent Variable: loglife

i/j           1             2             3             4             5
1                      0.8771        0.5127        0.1606        &lt;.0001
2        0.8771                      0.9679        0.0140        &lt;.0001
3        0.5127        0.9679                      0.0019        &lt;.0001
4        0.1606        0.0140        0.0019                      &lt;.0001
5        &lt;.0001        &lt;.0001        &lt;.0001        &lt;.0001</code></pre>
<p>We can also calculate adjusted treatment means using the parameters of the effects model:
<span class="math display">\[\begin{eqnarray*}
\hat{\mu }_i \left(\bar{x}_{++} \right) &amp; = &amp;  \hat{\mu }+\hat{\alpha }_i +\hat{\beta }\bar{x}_{++} \\
&amp; = &amp; 0.601 + 0.182 + 1.203 \times 0.821 \\
&amp; = &amp; 1.771
\end{eqnarray*}\]</span>
This is the calculation that the LSMEANS statement performs.</p>
<p>Finally, note that the <span class="math inline">\(F\)</span>-test for the treatment groups tests the null hypothesis that the adjusted treatment means are equal, that is, <span class="math inline">\(H_{0} :\mu_{1} \left(\bar{x}_{++} \right)=\mu_{2} \left(\bar{x}_{++} \right)=...=\mu_{g} \left(\bar{x}_{++} \right)\)</span>.</p>
<p><em>Caution:</em> Covariates should {} be affected or influenced by the treatment itself. In an experimental study, a good way to ensure that the covariate is not influenced by the treatment is to measure the covariate before assigning treatments to EUs. If the covariate is affected by the treatment (as may be the case in an observational study), it is best to treat the covariate as a separate response.</p>
<p>If the relationship between the covariate and the response is different for different treatment levels, then we need to fit a model that allows the regression lines to be non-parallel. Non-parallel lines can be accommodated in an ANCOVA model by including an interaction between the covariate and the treatment factor:</p>
<pre><code>proc glm;
  class trt;
  model loglife = thorax | trt;
run; 

The GLM Procedure
Dependent Variable: loglife

                                        Sum of
Source                      DF         Squares     Mean Square    F Value    Pr &gt; F
Model                        9      2.05753663      0.22861518      33.00    &lt;.0001
Error                      115      0.79674337      0.00692820
Corrected Total            124      2.85428000

Source                      DF     Type III SS     Mean Square    F Value    Pr &gt; F
thorax                       1      1.00724047      1.00724047     145.38    &lt;.0001
trt                          4      0.07751033      0.01937758       2.80    0.0293
thorax*trt                   4      0.03956095      0.00989024       1.43    0.2293</code></pre>
<p>The <span class="math inline">\(F\)</span>-test associated with the interaction is a test of <span class="math inline">\(H_0\)</span>: the parallel slopes model vs. <span class="math inline">\(H_a\)</span>: the non-parallel slopes model. Here, the large <span class="math inline">\(p\)</span>-value indicates that there is no evidence against the parallel slopes model (in other words, there is no evidence that the effect of thorax length on fruitfly longevity differs among the 5 treatment groups).</p>
<p>In notation, the non-parallel slopes model can be written:
<span class="math display">\[
y_{ij} =\mu +\alpha _i +\left(\beta +\delta _i \right)x_{ij} +\varepsilon_{ij}
\]</span>
Here, we interpret <span class="math inline">\(\beta\)</span> as a reference level for the slope, and <span class="math inline">\(\delta_i\)</span> as the ``effect’’ of treatment group <span class="math inline">\(i\)</span> on the slope. The <span class="math inline">\(\delta_i\)</span> parameters are subject to a constraint in the same way that the <span class="math inline">\(\alpha_i\)</span> parameters are subject to a constraint. The <span class="math inline">\(F\)</span>-test of the interaction is a test of <span class="math inline">\(H_0\)</span>: <span class="math inline">\(\delta_{1} =\delta_{2} =...=\delta_{p} =0\)</span>.</p>
<p>Here is a second example where the association between the covariate and the response does differ among the treatment groups:</p>
<p>Example (from Milliken &amp; Johnson vol 3): An exercise physiologist is interested in studying the effectiveness of 3 types of exercise programs. 24 males between the ages of 28 and 35 are enrolled in the study. Each individual has his heart rate measured at rest. The 24 subjects are then randomly assigned to the 3 programs (a CRD). At the end of the 8 weeks on the exercise program, each subject has his heart rate measured again after a 6-minute run.
<img src="05-Ancova_files/figure-html/unnamed-chunk-6-1.png" width="480" style="display: block; margin: auto;" /></p>
<pre><code>proc glm;
  class program;
  model hrate = initrate | program;
run;

                                        Sum of
Source                      DF         Squares     Mean Square    F Value    Pr &gt; F
Model                        5     2432.463977      486.492795      29.50    &lt;.0001
Error                       18      296.869356       16.492742
Corrected Total             23     2729.333333

Source                      DF     Type III SS     Mean Square    F Value    Pr &gt; F
initrate                     1     1539.535965     1539.535965      93.35    &lt;.0001
program                      2      388.117289      194.058645      11.77    0.0005
initrate*program             2      381.126973      190.563487      11.55    0.0006</code></pre>
<p>When there is a significant interaction between the covariate and the treatment, then a comparison of treatments depend on the value of the covariate being considered. We might still want to compare the adjusted treatment means at the average value of the covariate in the data set, or we might select a different value of the covariate. In the LSMEANS statement, we can specify the particular value of the covariate to calculate adjusted treatment means using the AT option, as illustrated below:</p>
<pre><code>proc glm;
  class program;
  model hrate = initrate|program;
  lsmeans program / at initrate=60 stderr pdiff adjust=tukey;
  lsmeans program / at initrate=80 stderr pdiff adjust=tukey;
run;

Least Squares Means at initrate=60
Adjustment for Multiple Comparisons: Tukey-Kramer

                               Standard                  LSMEAN
program    hrate LSMEAN           Error    Pr &gt; |t|      Number

p1           141.472996        2.007926      &lt;.0001           1
p2           153.470778        2.254376      &lt;.0001           2
p3           153.310267        1.913754      &lt;.0001           3

Least Squares Means for effect program
Pr &gt; |t| for H0: LSMean(i)=LSMean(j)

i/j           1             2             3
1                      0.0024        0.0013
2        0.0024                      0.9984
3        0.0013        0.9984

Least Squares Means at initrate=80
Adjustment for Multiple Comparisons: Tukey-Kramer

                               Standard                  LSMEAN
program    hrate LSMEAN           Error    Pr &gt; |t|      Number
p1           164.696418        1.960674      &lt;.0001           1
p2           172.230730        1.905086      &lt;.0001           2
p3           158.585366        2.055177      &lt;.0001           3

Least Squares Means for effect program
Pr &gt; |t| for H0: LSMean(i)=LSMean(j)

i/j           1             2             3
1                      0.0332        0.1074
2        0.0332                      0.0003
3        0.1074        0.0003</code></pre>
<p>Interpretation: For subjects with an initial resting heart rate of 60 bpm, there is no significant difference between exercise programs 2 and 3. For subjects with an initial resting heart rate of 80 bpm, there is no significant difference between exercise programs 1 and 3.</p>
<p>If we wish, we can have a look at the parameter estimates of the separate-slopes model using the SOLUTION option to the MODEL statement:</p>
<pre><code>proc glm;
  class program;
  model hrate = initrate|program / solution;
run;

                                              Standard
Parameter                   Estimate             Error    t Value    Pr &gt; |t|

Intercept                137.4849688 B      9.58049571      14.35      &lt;.0001
initrate                   0.2637550 B      0.13678399       1.93      0.0697
program          p1      -65.6822400 B     13.65253792      -4.81      0.0001
program          p2      -40.2940489 B     14.44003897      -2.79      0.0121
program          p3        0.0000000 B       .                .         .
initrate*program p1        0.8974162 B      0.19355172       4.64      0.0002
initrate*program p2        0.6742427 B      0.20263646       3.33      0.0037
initrate*program p3        0.0000000 B       .                .         .

NOTE: The X&#39;X matrix has been found to be singular, and a generalized inverse was used to
solve the normal equations.  Terms whose estimates are followed by the letter &#39;B&#39;
are not uniquely estimable.</code></pre>
<p>In these notes, we have seen simple examples of a single covariate with a one-factor layout. It is possible to have multiple covariates, and it is also possible to use covariates with factorial treatment structures that cross multiple experimental factors.</p>

</div>
<h3>Bibliography<a href="bibliography.html#bibliography" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-partridge1981sexual" class="csl-entry">
Partridge, Linda, and Marion Farquhar. 1981. <span>“Sexual Activity Reduces Lifespan of Male Fruitflies.”</span> <em>Nature</em> 294 (5841): 580–82.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="regression-models-with-several-predictors.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bibliography.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
