<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 ANCOVA | Statistical analysis of designed experiments: yesterday, today, and tomorrow</title>
  <meta name="description" content="An online text in statistical analysis using the linear model" />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 ANCOVA | Statistical analysis of designed experiments: yesterday, today, and tomorrow" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="An online text in statistical analysis using the linear model" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 ANCOVA | Statistical analysis of designed experiments: yesterday, today, and tomorrow" />
  
  <meta name="twitter:description" content="An online text in statistical analysis using the linear model" />
  

<meta name="author" content="Kevin Gross" />


<meta name="date" content="2025-11-04" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="factorial-experiments.html"/>
<link rel="next" href="random-effects.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#philosophy"><i class="fa fa-check"></i>Philosophy</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#scope-and-coverage"><i class="fa fa-check"></i>Scope and coverage</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#mathematical-level"><i class="fa fa-check"></i>Mathematical level</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#computing"><i class="fa fa-check"></i>Computing</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#llms-in-statistical-analysis"><i class="fa fa-check"></i>LLMs in statistical analysis</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#format-of-the-notes"><i class="fa fa-check"></i>Format of the notes</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#a-word-on-the-title"><i class="fa fa-check"></i>A word on the title</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgments-and-license"><i class="fa fa-check"></i>Acknowledgments and license</a></li>
</ul></li>
<li class="part"><span><b>Part I: Regression modeling</b></span></li>
<li class="chapter" data-level="1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>1</b> Simple linear regression</a>
<ul>
<li class="chapter" data-level="1.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#the-basics-of-slr"><i class="fa fa-check"></i><b>1.1</b> The basics of SLR</a></li>
<li class="chapter" data-level="1.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#least-squares-estimation"><i class="fa fa-check"></i><b>1.2</b> Least-squares estimation</a></li>
<li class="chapter" data-level="1.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#inference-for-the-slope"><i class="fa fa-check"></i><b>1.3</b> Inference for the slope</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#standard-errors"><i class="fa fa-check"></i><b>1.3.1</b> Standard errors</a></li>
<li class="chapter" data-level="1.3.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#confidence-intervals"><i class="fa fa-check"></i><b>1.3.2</b> Confidence intervals</a></li>
<li class="chapter" data-level="1.3.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#statistical-hypothesis-tests"><i class="fa fa-check"></i><b>1.3.3</b> Statistical hypothesis tests</a></li>
<li class="chapter" data-level="1.3.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#inference-for-the-intercept"><i class="fa fa-check"></i><b>1.3.4</b> Inference for the intercept</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#sums-of-squares-decomposition-and-r2"><i class="fa fa-check"></i><b>1.4</b> Sums of squares decomposition and <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="1.5" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#diagnostic-plots"><i class="fa fa-check"></i><b>1.5</b> Diagnostic plots</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#residuals-vs.-fitted-values"><i class="fa fa-check"></i><b>1.5.1</b> Residuals vs. fitted values</a></li>
<li class="chapter" data-level="1.5.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#residuals-vs.-predictors"><i class="fa fa-check"></i><b>1.5.2</b> Residuals vs. predictor(s)</a></li>
<li class="chapter" data-level="1.5.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#residuals-vs.-other-variables"><i class="fa fa-check"></i><b>1.5.3</b> Residuals vs. other variables</a></li>
<li class="chapter" data-level="1.5.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#normal-probability-plot"><i class="fa fa-check"></i><b>1.5.4</b> Normal probability plot</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#consequences-of-violating-model-assumptions-and-possible-fixes"><i class="fa fa-check"></i><b>1.6</b> Consequences of violating model assumptions, and possible fixes</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#linearity"><i class="fa fa-check"></i><b>1.6.1</b> Linearity</a></li>
<li class="chapter" data-level="1.6.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#independence"><i class="fa fa-check"></i><b>1.6.2</b> Independence</a></li>
<li class="chapter" data-level="1.6.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#constant-variance"><i class="fa fa-check"></i><b>1.6.3</b> Constant variance</a></li>
<li class="chapter" data-level="1.6.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#normality"><i class="fa fa-check"></i><b>1.6.4</b> Normality</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#prediction-with-regression-models"><i class="fa fa-check"></i><b>1.7</b> Prediction with regression models</a></li>
<li class="chapter" data-level="1.8" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#regression-design"><i class="fa fa-check"></i><b>1.8</b> Regression design</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#choice-of-predictor-values"><i class="fa fa-check"></i><b>1.8.1</b> Choice of predictor values</a></li>
<li class="chapter" data-level="1.8.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#powerSLR"><i class="fa fa-check"></i><b>1.8.2</b> Power</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#centering-the-predictor"><i class="fa fa-check"></i><b>1.9</b> <span class="math inline">\(^\star\)</span>Centering the predictor</a></li>
<li class="chapter" data-level="" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#appendix-a-fitting-the-slr-model-in-r"><i class="fa fa-check"></i>Appendix A: Fitting the SLR model in R</a></li>
<li class="chapter" data-level="" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#appendix-b-regression-models-in-sas-proc-reg"><i class="fa fa-check"></i>Appendix B: Regression models in SAS PROC REG</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="multiple-regression.html"><a href="multiple-regression.html"><i class="fa fa-check"></i><b>2</b> Multiple regression</a>
<ul>
<li class="chapter" data-level="2.1" data-path="multiple-regression.html"><a href="multiple-regression.html#multiple-regression-basics"><i class="fa fa-check"></i><b>2.1</b> Multiple regression basics</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="multiple-regression.html"><a href="multiple-regression.html#ideas-that-carry-over-from-slr-to-multiple-regression"><i class="fa fa-check"></i><b>2.1.1</b> Ideas that carry over from SLR to multiple regression</a></li>
<li class="chapter" data-level="2.1.2" data-path="multiple-regression.html"><a href="multiple-regression.html#interpreting-partial-regression-coefficients."><i class="fa fa-check"></i><b>2.1.2</b> Interpreting partial regression coefficients.</a></li>
<li class="chapter" data-level="2.1.3" data-path="multiple-regression.html"><a href="multiple-regression.html#visualizing-a-multiple-regression-model"><i class="fa fa-check"></i><b>2.1.3</b> Visualizing a multiple regression model</a></li>
<li class="chapter" data-level="2.1.4" data-path="multiple-regression.html"><a href="multiple-regression.html#statistical-inference-for-partial-regression-coefficients"><i class="fa fa-check"></i><b>2.1.4</b> Statistical inference for partial regression coefficients</a></li>
<li class="chapter" data-level="2.1.5" data-path="multiple-regression.html"><a href="multiple-regression.html#prediction"><i class="fa fa-check"></i><b>2.1.5</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="multiple-regression.html"><a href="multiple-regression.html#F-test"><i class="fa fa-check"></i><b>2.2</b> <span class="math inline">\(F\)</span>-tests for several regression coefficients</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="multiple-regression.html"><a href="multiple-regression.html#basic-machinery"><i class="fa fa-check"></i><b>2.2.1</b> Basic machinery</a></li>
<li class="chapter" data-level="2.2.2" data-path="multiple-regression.html"><a href="multiple-regression.html#model-utility-test"><i class="fa fa-check"></i><b>2.2.2</b> Model utility test</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="multiple-regression.html"><a href="multiple-regression.html#categorical-predictors"><i class="fa fa-check"></i><b>2.3</b> Categorical predictors</a></li>
<li class="chapter" data-level="2.4" data-path="multiple-regression.html"><a href="multiple-regression.html#regression-interactions"><i class="fa fa-check"></i><b>2.4</b> Interactions between predictors</a></li>
<li class="chapter" data-level="2.5" data-path="multiple-regression.html"><a href="multiple-regression.html#collinearity"><i class="fa fa-check"></i><b>2.5</b> (Multi-)Collinearity</a></li>
<li class="chapter" data-level="2.6" data-path="multiple-regression.html"><a href="multiple-regression.html#variable-selection-choosing-the-best-model"><i class="fa fa-check"></i><b>2.6</b> Variable selection: Choosing the best model</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="multiple-regression.html"><a href="multiple-regression.html#model-selection-and-inference"><i class="fa fa-check"></i><b>2.6.1</b> Model selection and inference</a></li>
<li class="chapter" data-level="2.6.2" data-path="multiple-regression.html"><a href="multiple-regression.html#ranking-methods"><i class="fa fa-check"></i><b>2.6.2</b> Ranking methods</a></li>
<li class="chapter" data-level="2.6.3" data-path="multiple-regression.html"><a href="multiple-regression.html#sequential-methods"><i class="fa fa-check"></i><b>2.6.3</b> Sequential methods</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="multiple-regression.html"><a href="multiple-regression.html#leverage-influential-points-and-standardized-residuals"><i class="fa fa-check"></i><b>2.7</b> Leverage, influential points, and standardized residuals</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="multiple-regression.html"><a href="multiple-regression.html#leverage"><i class="fa fa-check"></i><b>2.7.1</b> Leverage</a></li>
<li class="chapter" data-level="2.7.2" data-path="multiple-regression.html"><a href="multiple-regression.html#standardized-residuals"><i class="fa fa-check"></i><b>2.7.2</b> Standardized residuals</a></li>
<li class="chapter" data-level="2.7.3" data-path="multiple-regression.html"><a href="multiple-regression.html#cooks-distance"><i class="fa fa-check"></i><b>2.7.3</b> Cook’s distance</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="multiple-regression.html"><a href="multiple-regression.html#appendix-regression-as-a-linear-algebra-problem"><i class="fa fa-check"></i>Appendix: Regression as a linear algebra problem</a>
<ul>
<li class="chapter" data-level="" data-path="multiple-regression.html"><a href="multiple-regression.html#singular-or-pathological-design-matrices"><i class="fa fa-check"></i>Singular, or pathological, design matrices</a></li>
<li class="chapter" data-level="" data-path="multiple-regression.html"><a href="multiple-regression.html#additional-results"><i class="fa fa-check"></i>Additional results</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="non-linear-regression.html"><a href="non-linear-regression.html"><i class="fa fa-check"></i><b>3</b> Non-linear regression</a>
<ul>
<li class="chapter" data-level="3.1" data-path="non-linear-regression.html"><a href="non-linear-regression.html#polynomial-regression"><i class="fa fa-check"></i><b>3.1</b> Polynomial regression</a></li>
<li class="chapter" data-level="3.2" data-path="non-linear-regression.html"><a href="non-linear-regression.html#nls"><i class="fa fa-check"></i><b>3.2</b> Non-linear least squares</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>4</b> Generalized linear models</a>
<ul>
<li class="chapter" data-level="4.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#poisson-regression"><i class="fa fa-check"></i><b>4.1</b> Poisson regression</a></li>
<li class="chapter" data-level="4.2" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#binary-responses"><i class="fa fa-check"></i><b>4.2</b> Binary responses</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#individual-binary-responses-tb-in-boar"><i class="fa fa-check"></i><b>4.2.1</b> Individual binary responses: TB in boar</a></li>
<li class="chapter" data-level="4.2.2" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#grouped-binary-data-industrial-melanism"><i class="fa fa-check"></i><b>4.2.2</b> Grouped binary data: Industrial melanism</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#implementation-in-sas"><i class="fa fa-check"></i><b>4.3</b> Implementation in SAS</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#complete-separation"><i class="fa fa-check"></i><b>4.3.1</b> Complete separation</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Part II: Statistical learning</b></span></li>
<li class="chapter" data-level="5" data-path="smoothing.html"><a href="smoothing.html"><i class="fa fa-check"></i><b>5</b> Smoothing</a>
<ul>
<li class="chapter" data-level="5.1" data-path="smoothing.html"><a href="smoothing.html#nearest-neighbor-methods"><i class="fa fa-check"></i><b>5.1</b> Nearest-neighbor methods</a></li>
<li class="chapter" data-level="5.2" data-path="smoothing.html"><a href="smoothing.html#loess-smoothers"><i class="fa fa-check"></i><b>5.2</b> Loess smoothers</a></li>
<li class="chapter" data-level="5.3" data-path="smoothing.html"><a href="smoothing.html#splines"><i class="fa fa-check"></i><b>5.3</b> Splines</a></li>
<li class="chapter" data-level="5.4" data-path="smoothing.html"><a href="smoothing.html#generalized-additive-models-gams"><i class="fa fa-check"></i><b>5.4</b> Generalized additive models (GAMs)</a></li>
</ul></li>
<li class="part"><span><b>Part III: Designed experiments</b></span></li>
<li class="chapter" data-level="6" data-path="one-way.html"><a href="one-way.html"><i class="fa fa-check"></i><b>6</b> One-factor layout</a>
<ul>
<li class="chapter" data-level="6.1" data-path="one-way.html"><a href="one-way.html#grouped-data-and-the-design-of-experiments-doe-an-overview"><i class="fa fa-check"></i><b>6.1</b> Grouped data and the design of experiments (DoE): an overview</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="one-way.html"><a href="one-way.html#a-vocabulary-for-describing-designed-experiments"><i class="fa fa-check"></i><b>6.1.1</b> A vocabulary for describing designed experiments</a></li>
<li class="chapter" data-level="6.1.2" data-path="one-way.html"><a href="one-way.html#roadmap"><i class="fa fa-check"></i><b>6.1.2</b> Roadmap</a></li>
<li class="chapter" data-level="6.1.3" data-path="one-way.html"><a href="one-way.html#the-simplest-experiment"><i class="fa fa-check"></i><b>6.1.3</b> The simplest experiment</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="one-way.html"><a href="one-way.html#one-factor-anova"><i class="fa fa-check"></i><b>6.2</b> One-factor ANOVA</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="one-way.html"><a href="one-way.html#f-test-to-compare-means"><i class="fa fa-check"></i><b>6.2.1</b> <span class="math inline">\(F\)</span>-test to compare means</a></li>
<li class="chapter" data-level="6.2.2" data-path="one-way.html"><a href="one-way.html#connections-between-one-factor-anova-and-other-statistical-procedures"><i class="fa fa-check"></i><b>6.2.2</b> Connections between one-factor ANOVA and other statistical procedures</a></li>
<li class="chapter" data-level="6.2.3" data-path="one-way.html"><a href="one-way.html#assumptions-in-anova"><i class="fa fa-check"></i><b>6.2.3</b> Assumptions in ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="one-way.html"><a href="one-way.html#contrasts"><i class="fa fa-check"></i><b>6.3</b> Contrasts of group means</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="one-way.html"><a href="one-way.html#simple-contrasts"><i class="fa fa-check"></i><b>6.3.1</b> Simple contrasts</a></li>
<li class="chapter" data-level="6.3.2" data-path="one-way.html"><a href="one-way.html#complex-contrasts"><i class="fa fa-check"></i><b>6.3.2</b> Complex contrasts</a></li>
<li class="chapter" data-level="6.3.3" data-path="one-way.html"><a href="one-way.html#orthogonal-contrasts"><i class="fa fa-check"></i><b>6.3.3</b> Orthogonal contrasts</a></li>
<li class="chapter" data-level="6.3.4" data-path="one-way.html"><a href="one-way.html#polynomial-contrasts"><i class="fa fa-check"></i><b>6.3.4</b> Polynomial contrasts</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="one-way.html"><a href="one-way.html#multiple-testing"><i class="fa fa-check"></i><b>6.4</b> Multiple comparisons</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="one-way.html"><a href="one-way.html#multiple-testing-in-general"><i class="fa fa-check"></i><b>6.4.1</b> Multiple testing in general</a></li>
<li class="chapter" data-level="6.4.2" data-path="one-way.html"><a href="one-way.html#bonferroni-and-bonferroni-like-procedures"><i class="fa fa-check"></i><b>6.4.2</b> Bonferroni and Bonferroni-like procedures</a></li>
<li class="chapter" data-level="6.4.3" data-path="one-way.html"><a href="one-way.html#multiple-comparisons-in-anova"><i class="fa fa-check"></i><b>6.4.3</b> Multiple comparisons in ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="one-way.html"><a href="one-way.html#starpower-and-sample-size-determination-in-anova"><i class="fa fa-check"></i><b>6.5</b> <span class="math inline">\(^\star\)</span>Power and sample-size determination in ANOVA</a></li>
<li class="chapter" data-level="6.6" data-path="one-way.html"><a href="one-way.html#sas-contrasts"><i class="fa fa-check"></i><b>6.6</b> Using SAS: The effects parameterization of the one-factor ANOVA</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="one-way.html"><a href="one-way.html#one-factor-effects-model"><i class="fa fa-check"></i><b>6.6.1</b> Effects-model parameterization of the one-factor ANOVA model</a></li>
<li class="chapter" data-level="6.6.2" data-path="one-way.html"><a href="one-way.html#coding-contrasts-in-proc-glm"><i class="fa fa-check"></i><b>6.6.2</b> Coding contrasts in PROC GLM</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="factorial-experiments.html"><a href="factorial-experiments.html"><i class="fa fa-check"></i><b>7</b> Factorial experiments</a>
<ul>
<li class="chapter" data-level="7.1" data-path="factorial-experiments.html"><a href="factorial-experiments.html#combining-factors-crossed-vs.-nested-designs"><i class="fa fa-check"></i><b>7.1</b> Combining factors: Crossed vs. nested designs</a></li>
<li class="chapter" data-level="7.2" data-path="factorial-experiments.html"><a href="factorial-experiments.html#two-factor-anova"><i class="fa fa-check"></i><b>7.2</b> Two-factor ANOVA</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="factorial-experiments.html"><a href="factorial-experiments.html#interaction-plots"><i class="fa fa-check"></i><b>7.2.1</b> Interaction plots</a></li>
<li class="chapter" data-level="7.2.2" data-path="factorial-experiments.html"><a href="factorial-experiments.html#getting-organized-notation-and-bookkeeping"><i class="fa fa-check"></i><b>7.2.2</b> Getting organized: Notation and bookkeeping</a></li>
<li class="chapter" data-level="7.2.3" data-path="factorial-experiments.html"><a href="factorial-experiments.html#anova-f-tests"><i class="fa fa-check"></i><b>7.2.3</b> ANOVA <span class="math inline">\(F\)</span>-tests</a></li>
<li class="chapter" data-level="7.2.4" data-path="factorial-experiments.html"><a href="factorial-experiments.html#an-example-with-a-significant-interaction"><i class="fa fa-check"></i><b>7.2.4</b> An example with a significant interaction</a></li>
<li class="chapter" data-level="7.2.5" data-path="factorial-experiments.html"><a href="factorial-experiments.html#two-factor-effects-model"><i class="fa fa-check"></i><b>7.2.5</b> The effects model for a two-factor ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="factorial-experiments.html"><a href="factorial-experiments.html#unreplicated-designs"><i class="fa fa-check"></i><b>7.3</b> Unreplicated factorial designs</a></li>
<li class="chapter" data-level="7.4" data-path="factorial-experiments.html"><a href="factorial-experiments.html#more-than-two-factors"><i class="fa fa-check"></i><b>7.4</b> More than two factors</a></li>
<li class="chapter" data-level="7.5" data-path="factorial-experiments.html"><a href="factorial-experiments.html#analysis-using-proc-glm-in-sas"><i class="fa fa-check"></i><b>7.5</b> Analysis using PROC GLM in SAS</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ancova.html"><a href="ancova.html"><i class="fa fa-check"></i><b>8</b> ANCOVA</a>
<ul>
<li class="chapter" data-level="8.1" data-path="ancova.html"><a href="ancova.html#common-slopes-model"><i class="fa fa-check"></i><b>8.1</b> Common-slopes model</a></li>
<li class="chapter" data-level="8.2" data-path="ancova.html"><a href="ancova.html#separate-slopes-model"><i class="fa fa-check"></i><b>8.2</b> Separate-slopes model</a></li>
<li class="chapter" data-level="8.3" data-path="ancova.html"><a href="ancova.html#further-reading"><i class="fa fa-check"></i><b>8.3</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="random-effects.html"><a href="random-effects.html"><i class="fa fa-check"></i><b>9</b> Random effects</a>
<ul>
<li class="chapter" data-level="9.1" data-path="random-effects.html"><a href="random-effects.html#fixed-vs.-random-effects-the-big-picture"><i class="fa fa-check"></i><b>9.1</b> Fixed vs. random effects: the big picture</a></li>
<li class="chapter" data-level="9.2" data-path="random-effects.html"><a href="random-effects.html#random-effects-models"><i class="fa fa-check"></i><b>9.2</b> Random-effects models</a></li>
<li class="chapter" data-level="9.3" data-path="random-effects.html"><a href="random-effects.html#subsampling"><i class="fa fa-check"></i><b>9.3</b> Subsampling</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="random-effects.html"><a href="random-effects.html#equal-subsamples-per-eu"><i class="fa fa-check"></i><b>9.3.1</b> Equal subsamples per EU</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="random-effects.html"><a href="random-effects.html#starmathematical-foundations"><i class="fa fa-check"></i><b>9.4</b> <span class="math inline">\(^\star\)</span>Mathematical foundations</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="random-effects.html"><a href="random-effects.html#probability-refresher"><i class="fa fa-check"></i><b>9.4.1</b> Probability refresher</a></li>
<li class="chapter" data-level="9.4.2" data-path="random-effects.html"><a href="random-effects.html#application-to-models-with-random-effects"><i class="fa fa-check"></i><b>9.4.2</b> Application to models with random effects</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="blocked-designs.html"><a href="blocked-designs.html"><i class="fa fa-check"></i><b>10</b> Blocked designs</a>
<ul>
<li class="chapter" data-level="10.1" data-path="blocked-designs.html"><a href="blocked-designs.html#randomized-complete-block-designs"><i class="fa fa-check"></i><b>10.1</b> Randomized complete block designs</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="blocked-designs.html"><a href="blocked-designs.html#should-a-blocking-factor-be-a-fixed-or-random-effect"><i class="fa fa-check"></i><b>10.1.1</b> *Should a blocking factor be a fixed or random effect?</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="blocked-designs.html"><a href="blocked-designs.html#latin-squares-designs"><i class="fa fa-check"></i><b>10.2</b> Latin-squares designs</a></li>
<li class="chapter" data-level="10.3" data-path="blocked-designs.html"><a href="blocked-designs.html#split-plot-designs"><i class="fa fa-check"></i><b>10.3</b> Split-plot designs</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="blocked-designs.html"><a href="blocked-designs.html#denominator-degrees-of-freedom-in-split-plot-designs-and-the-satterthwaite-approximation"><i class="fa fa-check"></i><b>10.3.1</b> Denominator degrees of freedom in split-plot designs and the Satterthwaite approximation</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="blocked-designs.html"><a href="blocked-designs.html#repeated-measures"><i class="fa fa-check"></i><b>10.4</b> Repeated measures</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i>Bibliography</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical analysis of designed experiments: yesterday, today, and tomorrow</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ancova" class="section level1 hasAnchor" number="8">
<h1><span class="header-section-number">Chapter 8</span> ANCOVA<a href="ancova.html#ancova" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Statistical tests compare the estimated magnitude of a treatment effect to the precision with which that effect is estimated. Often, the magnitude of a treatment effect is set by nature. Thus, if we want to increase our chances of observing a statistically significant result, we must find ways to make our estimates more precise. Statistical precision is a function of (a) the degree of replication and (b) the experimental error. Thus, precision can be improved by including more replicates or reducing experimental error.</p>
<p>One technique for reducing experimental error and hence increasing precision is to use a covariate that accounts for heterogeneity among EUs. Inclusion of covariates in ANOVA models is called the analysis of covariance, or ANCOVA. Mathematically, ANCOVA is no different from regression with both quantitative and categorical predictors. However, the emphases differ depending on the context. In ANCOVA, our primary focus is analyzing the differences among the treatment groups. We model the relationship between the response and the covariate to gain a more precise estimate of the differences among treatment groups, but the relationship between the response and the covariate is of secondary interest at best. In regression, both quantitative and categorical predictors are on equal footing, and we have no reason to prioritize one versus the other.</p>
<p>For a variable to qualify as a covariate, it is important that it not be affected or influenced by the treatment itself. If the covariate is affected by the treatment, it is best to treat the covariate as a separate response.</p>
<div id="common-slopes-model" class="section level2 hasAnchor" number="8.1">
<h2><span class="header-section-number">8.1</span> Common-slopes model<a href="ancova.html#common-slopes-model" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Example (from <span class="citation">Hanley and Shapiro (<a href="#ref-hanley1994sexual">1994</a>)</span>): <span class="citation">Partridge and Farquhar (<a href="#ref-partridge1981sexual">1981</a>)</span> conducted an experiment to determine if reproduction reduces longevity in male fruitflies. (Such a cost had already been established for females.) There were 5 experimental treatments: male flies reared alone, male flies reared with 1 or 8 non-mated females, and male flies reared with 1 or 8 recently mated females. 25 male flies were assigned to each treatment. The data recorded are longevity (days lived) and thorax length. The data are shown below:</p>
<p><img src="08-Ancova_files/figure-html/unnamed-chunk-2-1.png" width="816" style="display: block; margin: auto;" />
Suppose we analyze these data with a one-way ANOVA and ignore differences in the sizes of the flies:</p>
<pre><code>proc glm;
  class trt;
  model life = trt;
run;

The GLM Procedure
Dependent Variable: life

                                        Sum of
Source                      DF         Squares     Mean Square    F Value    Pr &gt; F
Model                        4     11939.28000      2984.82000      13.61    &lt;.0001
Error                      120     26313.52000       219.27933
Corrected Total            124     38252.80000

Source                      DF     Type III SS     Mean Square    F Value    Pr &gt; F
trt                          4     11939.28000      2984.82000      13.61    &lt;.0001</code></pre>
<p>Although the <span class="math inline">\(F\)</span>-test for treatment is significant, notice that <span class="math inline">\(MS_{Error} = 219.3\)</span>. However, the plot above suggests that much of the variation in lifespan among flies in the same treatment group can be explained by variation in fly size. Suppose we include thorax size as a covariate:</p>
<pre><code>proc glm;
  class trt;
  model life = thorax trt;
run;

The GLM Procedure
Dependent Variable: life

Sum of
Source                      DF         Squares     Mean Square    F Value    Pr &gt; F
Model                        5     25108.13347      5021.62669      45.46    &lt;.0001
Error                      119     13144.66653       110.45938
Corrected Total            124     38252.80000

Source                      DF     Type III SS     Mean Square    F Value    Pr &gt; F
thorax                       1     13168.85347     13168.85347     119.22    &lt;.0001
trt                          4      9611.49254      2402.87314      21.75    &lt;.0001</code></pre>
<p>The experimental error has been cut in half: <span class="math inline">\(MS_{Error} = 110.5\)</span>. The experimental error has been reduced because the covariate thorax size has accounted for half of the previously unexplained variation.</p>
<p>This is an example of an Analysis of Covariance (ANCOVA) model. We can write the model using the following mathematical notation:</p>
<ul>
<li><span class="math inline">\(y_{ij}\)</span>: observation <span class="math inline">\(j\)</span> from treatment group <span class="math inline">\(i\)</span></li>
<li><span class="math inline">\(x_{ij}\)</span>: value of the covariate for observation <span class="math inline">\(j\)</span> from treatment group <span class="math inline">\(i\)</span></li>
</ul>
<p>Equipped with this notation, we can write the model as
<span class="math display">\[
y_{ij} =\mu_i + \beta( x_{ij} - \bar{x}_{++}) +\varepsilon_{ij}
\]</span>
where <span class="math inline">\(\mu_i\)</span> is the adjusted treatment mean for treatment group <span class="math inline">\(i\)</span>, <span class="math inline">\(\beta\)</span> is a regression slope that quantifies the (linear) relationship between the covariate and the response, <span class="math inline">\(\bar{x}_{++}\)</span> is the average value of the covariate <span class="math inline">\(x\)</span> (across all treatment groups), and <span class="math inline">\(\varepsilon_{ij}\)</span> is the residual error with the standard assumptions (independence, normality, equal variance). By “adjusted treatment mean”, we mean that <span class="math inline">\(\mu_i\)</span> represents the average response in treatment group <span class="math inline">\(i\)</span> when the covariate <span class="math inline">\(x\)</span> exactly equals the average value in the data set, <span class="math inline">\(\bar{x}_{++}\)</span>.</p>
<p>Geometrically, we can think of this model as specifying a regression line for each level of the experimental treatment. In this model, the effect of the covariate (<span class="math inline">\(\beta\)</span>) is the same for all of the treatment groups. Consequently, comparisons of adjusted treatment means do not depend on the particular value of the covariate at which the treatment means are being compared, as long as the treatment groups are all being adjusted to the same value of the covariate.</p>
<p>Before going any further with the fly data, we observe that residual plots clearly indicate that the variance increases as the predicted response increases. (The inclusion of a covariate makes the residual plots substantially richer.)</p>
<p><img src="08-Ancova_files/figure-html/unnamed-chunk-3-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Log-transforming the response stabilizes the variance nicely:
<img src="08-Ancova_files/figure-html/unnamed-chunk-4-1.png" width="768" style="display: block; margin: auto;" />
We re-do the analysis with a log-transformed response:</p>
<pre><code>proc glm;
  class trt;
  model loglife = thorax trt;
run;

The GLM Procedure
Dependent Variable: loglife

                                        Sum of
Source                      DF         Squares     Mean Square    F Value    Pr &gt; F
Model                        5      2.01797568      0.40359514      57.43    &lt;.0001
Error                      119      0.83630432      0.00702777
Corrected Total            124      2.85428000

Source                      DF     Type III SS     Mean Square    F Value    Pr &gt; F
thorax                       1      1.03374368      1.03374368     147.09    &lt;.0001
trt                          4      0.78904783      0.19726196      28.07    &lt;.0001</code></pre>
<p>The residual plot looks much better:
<img src="08-Ancova_files/figure-html/unnamed-chunk-5-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>The <span class="math inline">\(F\)</span>-test of <code>trt</code> shown above provides a test for equality of the adjusted treatment means (<span class="math inline">\(H_0\)</span>: <span class="math inline">\(\mu_1 = \mu_2 =... = \mu_g\)</span>). In the fruitfly data, there is strong evidence that the adjusted treatment means differ among the groups (<span class="math inline">\(F_{4,119}=28.07\)</span>, <span class="math inline">\(p&lt;.0001\)</span>).</p>
<p>There are several routes to obtaining the adjusted treatment means themselves. In PROC GLM, the LSMEANS statement generates adjusted treatment means. The PDIFF option generates <span class="math inline">\(p\)</span>-values for tests of pairwise differences, and the ADJUST = TUKEY option applies an adjustment to the <span class="math inline">\(p\)</span>-values to control the strong familywise type I error rate.</p>
<pre><code>proc glm data = fly;
  class trt;
  model loglife = trt thorax;
  lsmeans trt / pdiff adjust = tukey;
run;    

The GLM Procedure
Least Squares Means
Adjustment for Multiple Comparisons: Tukey-Kramer

loglife      LSMEAN
trt          LSMEAN      Number

a        1.77070164           1
m1       1.79321646           2
m8       1.80848343           3
u1       1.71677628           4
u8       1.58882218           5

Least Squares Means for effect trt
Pr &gt; |t| for H0: LSMean(i)=LSMean(j)

Dependent Variable: loglife

i/j           1             2             3             4             5
1                      0.8771        0.5127        0.1606        &lt;.0001
2        0.8771                      0.9679        0.0140        &lt;.0001
3        0.5127        0.9679                      0.0019        &lt;.0001
4        0.1606        0.0140        0.0019                      &lt;.0001
5        &lt;.0001        &lt;.0001        &lt;.0001        &lt;.0001</code></pre>
<p>Above, we see that the adjusted treatment mean for the “alone” treatment group is 1.77 (remember this is on the log scale). The table in the second portion of the output shows that adjusted treatment mean of treatment group “u8” is significantly different from the adjusted treatment means of all other treatment groups, and the adjusted treatment mean of the “u1” group is significantly different from all groups except the “alone” group.</p>
<p>Alternatively, a little algebra shows that the (estimate of the) adjusted treatment mean for treatment group <span class="math inline">\(i\)</span> can be written as
<span class="math display">\[
\hat{\mu }_i =\bar{y}_{i+} -\hat{\beta }(\bar{x}_{i+} -\bar{x}_{++} )
\]</span>
where <span class="math inline">\(\bar{y}_{i+}\)</span> is the raw (unadjusted) sample mean for treatment group <span class="math inline">\(i\)</span>, <span class="math inline">\(\hat{\beta}\)</span> is the estimate of the covariate effect, and <span class="math inline">\(\bar{x}_{i+}\)</span> is the average of the covariate values for treatment group <span class="math inline">\(i\)</span>.</p>
<p>We can find the value of <span class="math inline">\(\hat{\beta }\)</span> using the SOLUTION option to the MODEL statement in PROC GLM. We can find the raw treatment means and the means of the covariate values using the MEANS statement:</p>
<pre><code>proc glm data = fly;
  class trt;
  model loglife = trt thorax / solution;
  means trt;
run;

                                       Standard
Parameter            Estimate             Error    t Value    Pr &gt; |t|

Intercept         0.600921260 B      0.08112643       7.41      &lt;.0001
trt       a       0.181879457 B      0.02397873       7.59      &lt;.0001
trt       m1      0.204394280 B      0.02384687       8.57      &lt;.0001
trt       m8      0.219661249 B      0.02371772       9.26      &lt;.0001
trt       u1      0.127954099 B      0.02400289       5.33      &lt;.0001
trt       u8      0.000000000 B       .                .         .
thorax            1.203348424        0.09921873      12.13      &lt;.0001

NOTE: The X&#39;X matrix has been found to be singular, and a generalized inverse was used to
solve the normal equations.  Terms whose estimates are followed by the letter &#39;B&#39;
are not uniquely estimable.

The GLM Procedure

Level of            -----------loglife-----------     ------------thorax-----------
trt           N             Mean          Std Dev             Mean          Std Dev

a            25       1.78880000       0.11515642       0.83600000       0.08426150
m1           25       1.79880000       0.10763828       0.82560000       0.06988562
m8           25       1.79000000       0.11221260       0.80560000       0.08155162
u1           25       1.73680000       0.13145722       0.83760000       0.07055022
u8           25       1.56360000       0.15231218       0.80000000       0.07831560</code></pre>
<p>For example, consider the treatment group with flies reared alone. In these data, it turns out that the average covariate value is <span class="math inline">\(\bar{x}_{++} = 0.821\)</span>. Our calculation (using the log-transformed data) gives
<span class="math display">\[\begin{eqnarray*}
    \hat{\mu }_i &amp; = &amp; \bar{y}_{i+} -\hat{\beta }(\bar{x}_{i+} -\bar{x}_{++} ) \\
    &amp; = &amp;  1.789-(1.203) \times (0.836-0.821) \\
    &amp; = &amp;  1.771
\end{eqnarray*}\]</span>
Flies assigned to the “alone” treatment were slightly larger than the other flies in the experiment. Because larger flies tend to live longer, the adjusted treatment mean for the “alone” treatment is slightly smaller than the raw mean.</p>
</div>
<div id="separate-slopes-model" class="section level2 hasAnchor" number="8.2">
<h2><span class="header-section-number">8.2</span> Separate-slopes model<a href="ancova.html#separate-slopes-model" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>If the relationship between the covariate and the response differs across the treatment groups, then we need a model that allows the regression lines to be non-parallel. Non-parallel lines can be accommodated in an ANCOVA model by including an interaction between the covariate and the treatment factor:</p>
<pre><code>proc glm;
  class trt;
  model loglife = thorax | trt;
run; 

The GLM Procedure
Dependent Variable: loglife

                                        Sum of
Source                      DF         Squares     Mean Square    F Value    Pr &gt; F
Model                        9      2.05753663      0.22861518      33.00    &lt;.0001
Error                      115      0.79674337      0.00692820
Corrected Total            124      2.85428000

Source                      DF     Type III SS     Mean Square    F Value    Pr &gt; F
thorax                       1      1.00724047      1.00724047     145.38    &lt;.0001
trt                          4      0.07751033      0.01937758       2.80    0.0293
thorax*trt                   4      0.03956095      0.00989024       1.43    0.2293</code></pre>
<p>In notation, the non-parallel slopes model can be written:
<span class="math display">\[
y_{ij} =\mu_i + \beta_i( x_{ij} - \bar{x}_{++}) +\varepsilon_{ij}
\]</span></p>
<p>The <span class="math inline">\(F\)</span>-test associated with the interaction is a test of <span class="math inline">\(H_0\)</span>: <span class="math inline">\(\beta_1 = \beta_2 = \ldots = \beta_g\)</span>, that is, a test of null hypothesis that the covariate has the same effect on the response in every group. Here, the large <span class="math inline">\(p\)</span>-value indicates that there is no evidence that the effect of size on fruitfly longevity differs among the 5 treatment groups. The common-slopes model is adequate for these data.</p>
<p>Here is an example where the association between the covariate and the response differs among the treatment groups:</p>
<p>Example (from <span class="citation">Milliken and Johnson (<a href="#ref-milliken2001analysis">2001</a>)</span>): An exercise physiologist is interested in studying the effectiveness of 3 types of exercise programs. 24 males between the ages of 28 and 35 are enrolled in the study. Each individual has his heart rate measured at rest. The 24 subjects are then randomly assigned to the 3 programs (a CRD). At the end of the 8 weeks on the exercise program, each subject has his heart rate measured again after a 6-minute run.
<img src="08-Ancova_files/figure-html/unnamed-chunk-6-1.png" width="576" style="display: block; margin: auto;" /></p>
<pre><code>proc glm;
  class program;
  model hrate = initrate | program;
run;

                                        Sum of
Source                      DF         Squares     Mean Square    F Value    Pr &gt; F
Model                        5     2432.463977      486.492795      29.50    &lt;.0001
Error                       18      296.869356       16.492742
Corrected Total             23     2729.333333

Source                      DF     Type III SS     Mean Square    F Value    Pr &gt; F
initrate                     1     1539.535965     1539.535965      93.35    &lt;.0001
program                      2      388.117289      194.058645      11.77    0.0005
initrate*program             2      381.126973      190.563487      11.55    0.0006</code></pre>
<p>When there is a significant interaction between the covariate and the treatment, then a comparison of treatments depend on the value of the covariate being considered. We might still want to compare the adjusted treatment means at the average value of the covariate in the data set, or we might select a different value of the covariate. In the LSMEANS statement, we can specify the particular value of the covariate to calculate adjusted treatment means using the AT option, as illustrated below:</p>
<pre><code>proc glm;
  class program;
  model hrate = initrate|program;
  lsmeans program / at initrate=60 stderr pdiff adjust=tukey;
  lsmeans program / at initrate=80 stderr pdiff adjust=tukey;
run;

Least Squares Means at initrate=60
Adjustment for Multiple Comparisons: Tukey-Kramer

                               Standard                  LSMEAN
program    hrate LSMEAN           Error    Pr &gt; |t|      Number

p1           141.472996        2.007926      &lt;.0001           1
p2           153.470778        2.254376      &lt;.0001           2
p3           153.310267        1.913754      &lt;.0001           3

Least Squares Means for effect program
Pr &gt; |t| for H0: LSMean(i)=LSMean(j)

i/j           1             2             3
1                      0.0024        0.0013
2        0.0024                      0.9984
3        0.0013        0.9984

Least Squares Means at initrate=80
Adjustment for Multiple Comparisons: Tukey-Kramer

                               Standard                  LSMEAN
program    hrate LSMEAN           Error    Pr &gt; |t|      Number
p1           164.696418        1.960674      &lt;.0001           1
p2           172.230730        1.905086      &lt;.0001           2
p3           158.585366        2.055177      &lt;.0001           3

Least Squares Means for effect program
Pr &gt; |t| for H0: LSMean(i)=LSMean(j)

i/j           1             2             3
1                      0.0332        0.1074
2        0.0332                      0.0003
3        0.1074        0.0003</code></pre>
<p>Interpretation: For subjects with an initial resting heart rate of 60 bpm, there is no significant difference between exercise programs 2 and 3. For subjects with an initial resting heart rate of 80 bpm, there is no significant difference between exercise programs 1 and 3.</p>
<!-- If we wish, we can have a look at the parameter estimates of the separate-slopes model using the SOLUTION option to the MODEL statement: -->
<!-- ```{} -->
<!-- proc glm; -->
<!--   class program; -->
<!--   model hrate = initrate|program / solution; -->
<!-- run; -->
<!--                                               Standard -->
<!-- Parameter                   Estimate             Error    t Value    Pr > |t| -->
<!-- Intercept                137.4849688 B      9.58049571      14.35      <.0001 -->
<!-- initrate                   0.2637550 B      0.13678399       1.93      0.0697 -->
<!-- program          p1      -65.6822400 B     13.65253792      -4.81      0.0001 -->
<!-- program          p2      -40.2940489 B     14.44003897      -2.79      0.0121 -->
<!-- program          p3        0.0000000 B       .                .         . -->
<!-- initrate*program p1        0.8974162 B      0.19355172       4.64      0.0002 -->
<!-- initrate*program p2        0.6742427 B      0.20263646       3.33      0.0037 -->
<!-- initrate*program p3        0.0000000 B       .                .         . -->
<!-- NOTE: The X'X matrix has been found to be singular, and a generalized inverse was used to -->
<!-- solve the normal equations.  Terms whose estimates are followed by the letter 'B' -->
<!-- are not uniquely estimable. -->
<!-- ``` -->
</div>
<div id="further-reading" class="section level2 hasAnchor" number="8.3">
<h2><span class="header-section-number">8.3</span> Further reading<a href="ancova.html#further-reading" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In these notes, we have seen simple examples of a single covariate with a one-factor layout. Of course, things can get much more complicated. Experiments can include multiple covariates, or several treatment factors, or covariates with non-linear associations with the response. See <span class="citation">Milliken and Johnson (<a href="#ref-milliken2001analysis">2001</a>)</span> for a lengthier treatment.</p>

</div>
</div>
<h3>Bibliography<a href="bibliography.html#bibliography" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-hanley1994sexual" class="csl-entry">
Hanley, James A, and Stanley H Shapiro. 1994. <span>“Sexual Activity and the Lifespan of Male Fruitflies: A Dataset That Gets Attention.”</span> <em>Journal of Statistics Education</em> 2 (1).
</div>
<div id="ref-milliken2001analysis" class="csl-entry">
Milliken, George A, and Dallas E Johnson. 2001. <em>Analysis of Messy Data, Volume III: Analysis of Covariance</em>. Chapman; Hall/CRC.
</div>
<div id="ref-partridge1981sexual" class="csl-entry">
Partridge, Linda, and Marion Farquhar. 1981. <span>“Sexual Activity Reduces Lifespan of Male Fruitflies.”</span> <em>Nature</em> 294 (5841): 580–82.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="factorial-experiments.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="random-effects.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "serif",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "section"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
