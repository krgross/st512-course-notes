<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Smoothing | Statistical analysis of designed experiments: yesterday, today, and tomorrow</title>
  <meta name="description" content="An online text in statistical analysis using the linear model" />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Smoothing | Statistical analysis of designed experiments: yesterday, today, and tomorrow" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="An online text in statistical analysis using the linear model" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Smoothing | Statistical analysis of designed experiments: yesterday, today, and tomorrow" />
  
  <meta name="twitter:description" content="An online text in statistical analysis using the linear model" />
  

<meta name="author" content="Kevin Gross" />


<meta name="date" content="2025-10-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="generalized-linear-models.html"/>
<link rel="next" href="one-factor-anova.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#philosophy"><i class="fa fa-check"></i>Philosophy</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#scope-and-coverage"><i class="fa fa-check"></i>Scope and coverage</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#mathematical-level"><i class="fa fa-check"></i>Mathematical level</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#computing"><i class="fa fa-check"></i>Computing</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#llms-in-statistical-analysis"><i class="fa fa-check"></i>LLMs in statistical analysis</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#format-of-the-notes"><i class="fa fa-check"></i>Format of the notes</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#a-word-on-the-title"><i class="fa fa-check"></i>A word on the title</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgments-and-license"><i class="fa fa-check"></i>Acknowledgments and license</a></li>
</ul></li>
<li class="part"><span><b>Part I: Regression modeling</b></span></li>
<li class="chapter" data-level="1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>1</b> Simple linear regression</a>
<ul>
<li class="chapter" data-level="1.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#the-basics-of-slr"><i class="fa fa-check"></i><b>1.1</b> The basics of SLR</a></li>
<li class="chapter" data-level="1.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#least-squares-estimation"><i class="fa fa-check"></i><b>1.2</b> Least-squares estimation</a></li>
<li class="chapter" data-level="1.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#inference-for-the-slope"><i class="fa fa-check"></i><b>1.3</b> Inference for the slope</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#standard-errors"><i class="fa fa-check"></i><b>1.3.1</b> Standard errors</a></li>
<li class="chapter" data-level="1.3.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#confidence-intervals"><i class="fa fa-check"></i><b>1.3.2</b> Confidence intervals</a></li>
<li class="chapter" data-level="1.3.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#statistical-hypothesis-tests"><i class="fa fa-check"></i><b>1.3.3</b> Statistical hypothesis tests</a></li>
<li class="chapter" data-level="1.3.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#inference-for-the-intercept"><i class="fa fa-check"></i><b>1.3.4</b> Inference for the intercept</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#sums-of-squares-decomposition-and-r2"><i class="fa fa-check"></i><b>1.4</b> Sums of squares decomposition and <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="1.5" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#diagnostic-plots"><i class="fa fa-check"></i><b>1.5</b> Diagnostic plots</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#residuals-vs.-fitted-values"><i class="fa fa-check"></i><b>1.5.1</b> Residuals vs. fitted values</a></li>
<li class="chapter" data-level="1.5.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#residuals-vs.-predictors"><i class="fa fa-check"></i><b>1.5.2</b> Residuals vs. predictor(s)</a></li>
<li class="chapter" data-level="1.5.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#residuals-vs.-other-variables"><i class="fa fa-check"></i><b>1.5.3</b> Residuals vs. other variables</a></li>
<li class="chapter" data-level="1.5.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#normal-probability-plot"><i class="fa fa-check"></i><b>1.5.4</b> Normal probability plot</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#consequences-of-violating-model-assumptions-and-possible-fixes"><i class="fa fa-check"></i><b>1.6</b> Consequences of violating model assumptions, and possible fixes</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#linearity"><i class="fa fa-check"></i><b>1.6.1</b> Linearity</a></li>
<li class="chapter" data-level="1.6.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#independence"><i class="fa fa-check"></i><b>1.6.2</b> Independence</a></li>
<li class="chapter" data-level="1.6.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#constant-variance"><i class="fa fa-check"></i><b>1.6.3</b> Constant variance</a></li>
<li class="chapter" data-level="1.6.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#normality"><i class="fa fa-check"></i><b>1.6.4</b> Normality</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#prediction-with-regression-models"><i class="fa fa-check"></i><b>1.7</b> Prediction with regression models</a></li>
<li class="chapter" data-level="1.8" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#regression-design"><i class="fa fa-check"></i><b>1.8</b> Regression design</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#choice-of-predictor-values"><i class="fa fa-check"></i><b>1.8.1</b> Choice of predictor values</a></li>
<li class="chapter" data-level="1.8.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#powerSLR"><i class="fa fa-check"></i><b>1.8.2</b> Power</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#centering-the-predictor"><i class="fa fa-check"></i><b>1.9</b> <span class="math inline">\(^\star\)</span>Centering the predictor</a></li>
<li class="chapter" data-level="" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#appendix-a-fitting-the-slr-model-in-r"><i class="fa fa-check"></i>Appendix A: Fitting the SLR model in R</a></li>
<li class="chapter" data-level="" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#appendix-b-regression-models-in-sas-proc-reg"><i class="fa fa-check"></i>Appendix B: Regression models in SAS PROC REG</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="multiple-regression.html"><a href="multiple-regression.html"><i class="fa fa-check"></i><b>2</b> Multiple regression</a>
<ul>
<li class="chapter" data-level="2.1" data-path="multiple-regression.html"><a href="multiple-regression.html#multiple-regression-basics"><i class="fa fa-check"></i><b>2.1</b> Multiple regression basics</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="multiple-regression.html"><a href="multiple-regression.html#ideas-that-carry-over-from-slr-to-multiple-regression"><i class="fa fa-check"></i><b>2.1.1</b> Ideas that carry over from SLR to multiple regression</a></li>
<li class="chapter" data-level="2.1.2" data-path="multiple-regression.html"><a href="multiple-regression.html#interpreting-partial-regression-coefficients."><i class="fa fa-check"></i><b>2.1.2</b> Interpreting partial regression coefficients.</a></li>
<li class="chapter" data-level="2.1.3" data-path="multiple-regression.html"><a href="multiple-regression.html#visualizing-a-multiple-regression-model"><i class="fa fa-check"></i><b>2.1.3</b> Visualizing a multiple regression model</a></li>
<li class="chapter" data-level="2.1.4" data-path="multiple-regression.html"><a href="multiple-regression.html#statistical-inference-for-partial-regression-coefficients"><i class="fa fa-check"></i><b>2.1.4</b> Statistical inference for partial regression coefficients</a></li>
<li class="chapter" data-level="2.1.5" data-path="multiple-regression.html"><a href="multiple-regression.html#prediction"><i class="fa fa-check"></i><b>2.1.5</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="multiple-regression.html"><a href="multiple-regression.html#F-test"><i class="fa fa-check"></i><b>2.2</b> <span class="math inline">\(F\)</span>-tests for several regression coefficients</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="multiple-regression.html"><a href="multiple-regression.html#basic-machinery"><i class="fa fa-check"></i><b>2.2.1</b> Basic machinery</a></li>
<li class="chapter" data-level="2.2.2" data-path="multiple-regression.html"><a href="multiple-regression.html#model-utility-test"><i class="fa fa-check"></i><b>2.2.2</b> Model utility test</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="multiple-regression.html"><a href="multiple-regression.html#categorical-predictors"><i class="fa fa-check"></i><b>2.3</b> Categorical predictors</a></li>
<li class="chapter" data-level="2.4" data-path="multiple-regression.html"><a href="multiple-regression.html#regression-interactions"><i class="fa fa-check"></i><b>2.4</b> Interactions between predictors</a></li>
<li class="chapter" data-level="2.5" data-path="multiple-regression.html"><a href="multiple-regression.html#collinearity"><i class="fa fa-check"></i><b>2.5</b> (Multi-)Collinearity</a></li>
<li class="chapter" data-level="2.6" data-path="multiple-regression.html"><a href="multiple-regression.html#variable-selection-choosing-the-best-model"><i class="fa fa-check"></i><b>2.6</b> Variable selection: Choosing the best model</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="multiple-regression.html"><a href="multiple-regression.html#model-selection-and-inference"><i class="fa fa-check"></i><b>2.6.1</b> Model selection and inference</a></li>
<li class="chapter" data-level="2.6.2" data-path="multiple-regression.html"><a href="multiple-regression.html#ranking-methods"><i class="fa fa-check"></i><b>2.6.2</b> Ranking methods</a></li>
<li class="chapter" data-level="2.6.3" data-path="multiple-regression.html"><a href="multiple-regression.html#sequential-methods"><i class="fa fa-check"></i><b>2.6.3</b> Sequential methods</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="multiple-regression.html"><a href="multiple-regression.html#leverage-influential-points-and-standardized-residuals"><i class="fa fa-check"></i><b>2.7</b> Leverage, influential points, and standardized residuals</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="multiple-regression.html"><a href="multiple-regression.html#leverage"><i class="fa fa-check"></i><b>2.7.1</b> Leverage</a></li>
<li class="chapter" data-level="2.7.2" data-path="multiple-regression.html"><a href="multiple-regression.html#standardized-residuals"><i class="fa fa-check"></i><b>2.7.2</b> Standardized residuals</a></li>
<li class="chapter" data-level="2.7.3" data-path="multiple-regression.html"><a href="multiple-regression.html#cooks-distance"><i class="fa fa-check"></i><b>2.7.3</b> Cook’s distance</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="multiple-regression.html"><a href="multiple-regression.html#appendix-regression-as-a-linear-algebra-problem"><i class="fa fa-check"></i>Appendix: Regression as a linear algebra problem</a>
<ul>
<li class="chapter" data-level="" data-path="multiple-regression.html"><a href="multiple-regression.html#singular-or-pathological-design-matrices"><i class="fa fa-check"></i>Singular, or pathological, design matrices</a></li>
<li class="chapter" data-level="" data-path="multiple-regression.html"><a href="multiple-regression.html#additional-results"><i class="fa fa-check"></i>Additional results</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="non-linear-regression.html"><a href="non-linear-regression.html"><i class="fa fa-check"></i><b>3</b> Non-linear regression</a>
<ul>
<li class="chapter" data-level="3.1" data-path="non-linear-regression.html"><a href="non-linear-regression.html#polynomial-regression"><i class="fa fa-check"></i><b>3.1</b> Polynomial regression</a></li>
<li class="chapter" data-level="3.2" data-path="non-linear-regression.html"><a href="non-linear-regression.html#nls"><i class="fa fa-check"></i><b>3.2</b> Non-linear least squares</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>4</b> Generalized linear models</a>
<ul>
<li class="chapter" data-level="4.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#poisson-regression"><i class="fa fa-check"></i><b>4.1</b> Poisson regression</a></li>
<li class="chapter" data-level="4.2" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#binary-responses"><i class="fa fa-check"></i><b>4.2</b> Binary responses</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#individual-binary-responses-tb-in-boar"><i class="fa fa-check"></i><b>4.2.1</b> Individual binary responses: TB in boar</a></li>
<li class="chapter" data-level="4.2.2" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#grouped-binary-data-industrial-melanism"><i class="fa fa-check"></i><b>4.2.2</b> Grouped binary data: Industrial melanism</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#implementation-in-sas"><i class="fa fa-check"></i><b>4.3</b> Implementation in SAS</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#complete-separation"><i class="fa fa-check"></i><b>4.3.1</b> Complete separation</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Part II: Statistical learning</b></span></li>
<li class="chapter" data-level="5" data-path="smoothing.html"><a href="smoothing.html"><i class="fa fa-check"></i><b>5</b> Smoothing</a>
<ul>
<li class="chapter" data-level="5.1" data-path="smoothing.html"><a href="smoothing.html#nearest-neighbor-methods"><i class="fa fa-check"></i><b>5.1</b> Nearest-neighbor methods</a></li>
<li class="chapter" data-level="5.2" data-path="smoothing.html"><a href="smoothing.html#loess-smoothers"><i class="fa fa-check"></i><b>5.2</b> Loess smoothers</a></li>
<li class="chapter" data-level="5.3" data-path="smoothing.html"><a href="smoothing.html#splines"><i class="fa fa-check"></i><b>5.3</b> Splines</a></li>
<li class="chapter" data-level="5.4" data-path="smoothing.html"><a href="smoothing.html#generalized-additive-models-gams"><i class="fa fa-check"></i><b>5.4</b> Generalized additive models (GAMs)</a></li>
</ul></li>
<li class="part"><span><b>Part III: Designed experiments</b></span></li>
<li class="chapter" data-level="6" data-path="one-factor-anova.html"><a href="one-factor-anova.html"><i class="fa fa-check"></i><b>6</b> One-factor ANOVA</a>
<ul>
<li class="chapter" data-level="6.1" data-path="one-factor-anova.html"><a href="one-factor-anova.html#grouped-data-and-the-design-of-experiments-doe-an-overview"><i class="fa fa-check"></i><b>6.1</b> Grouped data and the design of experiments (DoE): an overview</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="one-factor-anova.html"><a href="one-factor-anova.html#a-vocabulary-for-describing-designed-experiments"><i class="fa fa-check"></i><b>6.1.1</b> A vocabulary for describing designed experiments</a></li>
<li class="chapter" data-level="6.1.2" data-path="one-factor-anova.html"><a href="one-factor-anova.html#roadmap"><i class="fa fa-check"></i><b>6.1.2</b> Roadmap</a></li>
<li class="chapter" data-level="6.1.3" data-path="one-factor-anova.html"><a href="one-factor-anova.html#the-simplest-experiment"><i class="fa fa-check"></i><b>6.1.3</b> The simplest experiment</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="one-factor-anova.html"><a href="one-factor-anova.html#one-factor-anova-the-basics"><i class="fa fa-check"></i><b>6.2</b> One-factor ANOVA: The basics</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="one-factor-anova.html"><a href="one-factor-anova.html#f-test-to-compare-means"><i class="fa fa-check"></i><b>6.2.1</b> <span class="math inline">\(F\)</span>-test to compare means</a></li>
<li class="chapter" data-level="6.2.2" data-path="one-factor-anova.html"><a href="one-factor-anova.html#connections-between-one-factor-anova-and-other-statistical-procedures"><i class="fa fa-check"></i><b>6.2.2</b> Connections between one-factor ANOVA and other statistical procedures</a></li>
<li class="chapter" data-level="6.2.3" data-path="one-factor-anova.html"><a href="one-factor-anova.html#assumptions-in-anova"><i class="fa fa-check"></i><b>6.2.3</b> Assumptions in ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="one-factor-anova.html"><a href="one-factor-anova.html#contrasts"><i class="fa fa-check"></i><b>6.3</b> Contrasts of group means</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="one-factor-anova.html"><a href="one-factor-anova.html#simple-contrasts"><i class="fa fa-check"></i><b>6.3.1</b> Simple contrasts</a></li>
<li class="chapter" data-level="6.3.2" data-path="one-factor-anova.html"><a href="one-factor-anova.html#complex-contrasts"><i class="fa fa-check"></i><b>6.3.2</b> Complex contrasts</a></li>
<li class="chapter" data-level="6.3.3" data-path="one-factor-anova.html"><a href="one-factor-anova.html#orthogonal-contrasts"><i class="fa fa-check"></i><b>6.3.3</b> Orthogonal contrasts</a></li>
<li class="chapter" data-level="6.3.4" data-path="one-factor-anova.html"><a href="one-factor-anova.html#polynomial-contrasts"><i class="fa fa-check"></i><b>6.3.4</b> Polynomial contrasts</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="one-factor-anova.html"><a href="one-factor-anova.html#multiple-testing"><i class="fa fa-check"></i><b>6.4</b> Multiple comparisons</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="one-factor-anova.html"><a href="one-factor-anova.html#multiple-testing-in-general"><i class="fa fa-check"></i><b>6.4.1</b> Multiple testing in general</a></li>
<li class="chapter" data-level="6.4.2" data-path="one-factor-anova.html"><a href="one-factor-anova.html#bonferroni-and-bonferroni-like-procedures"><i class="fa fa-check"></i><b>6.4.2</b> Bonferroni and Bonferroni-like procedures</a></li>
<li class="chapter" data-level="6.4.3" data-path="one-factor-anova.html"><a href="one-factor-anova.html#multiple-comparisons-in-anova"><i class="fa fa-check"></i><b>6.4.3</b> Multiple comparisons in ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="one-factor-anova.html"><a href="one-factor-anova.html#starpower-and-sample-size-determination-in-anova"><i class="fa fa-check"></i><b>6.5</b> <span class="math inline">\(^\star\)</span>Power and sample-size determination in ANOVA</a></li>
<li class="chapter" data-level="6.6" data-path="one-factor-anova.html"><a href="one-factor-anova.html#sas-contrasts"><i class="fa fa-check"></i><b>6.6</b> Using SAS: The effects parameterization of the one-factor ANOVA</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="one-factor-anova.html"><a href="one-factor-anova.html#effects-model-parameterization-of-the-one-factor-anova-model"><i class="fa fa-check"></i><b>6.6.1</b> Effects-model parameterization of the one-factor ANOVA model</a></li>
<li class="chapter" data-level="6.6.2" data-path="one-factor-anova.html"><a href="one-factor-anova.html#coding-contrasts-in-proc-glm"><i class="fa fa-check"></i><b>6.6.2</b> Coding contrasts in PROC GLM</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="factorial-experiments.html"><a href="factorial-experiments.html"><i class="fa fa-check"></i><b>7</b> Factorial experiments</a>
<ul>
<li class="chapter" data-level="7.1" data-path="factorial-experiments.html"><a href="factorial-experiments.html#combining-factors-crossed-vs.-nested-designs"><i class="fa fa-check"></i><b>7.1</b> Combining factors: Crossed vs. nested designs</a></li>
<li class="chapter" data-level="7.2" data-path="factorial-experiments.html"><a href="factorial-experiments.html#times-2-factorial-design"><i class="fa fa-check"></i><b>7.2</b> 2 <span class="math inline">\(\times\)</span> 2 factorial design</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="factorial-experiments.html"><a href="factorial-experiments.html#example-weight-gain-in-rats"><i class="fa fa-check"></i><b>7.2.1</b> Example: Weight gain in rats</a></li>
<li class="chapter" data-level="7.2.2" data-path="factorial-experiments.html"><a href="factorial-experiments.html#two-factor-anova-hypothesis-tests"><i class="fa fa-check"></i><b>7.2.2</b> Two-factor ANOVA hypothesis tests</a></li>
<li class="chapter" data-level="7.2.3" data-path="factorial-experiments.html"><a href="factorial-experiments.html#analysis-using-proc-glm-in-sas"><i class="fa fa-check"></i><b>7.2.3</b> Analysis using PROC GLM in SAS</a></li>
<li class="chapter" data-level="7.2.4" data-path="factorial-experiments.html"><a href="factorial-experiments.html#effects-notation-for-the-two-factor-anova"><i class="fa fa-check"></i><b>7.2.4</b> Effects notation for the two-factor ANOVA</a></li>
<li class="chapter" data-level="7.2.5" data-path="factorial-experiments.html"><a href="factorial-experiments.html#a-second-example-when-the-interaction-is-significant"><i class="fa fa-check"></i><b>7.2.5</b> A second example when the interaction is significant</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="factorial-experiments.html"><a href="factorial-experiments.html#a-times-b-factorial-designs"><i class="fa fa-check"></i><b>7.3</b> <span class="math inline">\(a \times b\)</span> factorial designs</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="factorial-experiments.html"><a href="factorial-experiments.html#example-without-a-significant-interaction"><i class="fa fa-check"></i><b>7.3.1</b> Example without a significant interaction</a></li>
<li class="chapter" data-level="7.3.2" data-path="factorial-experiments.html"><a href="factorial-experiments.html#example-with-a-significant-interaction"><i class="fa fa-check"></i><b>7.3.2</b> Example with a significant interaction</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="factorial-experiments.html"><a href="factorial-experiments.html#unreplicated-factorial-designs"><i class="fa fa-check"></i><b>7.4</b> Unreplicated factorial designs</a></li>
<li class="chapter" data-level="7.5" data-path="factorial-experiments.html"><a href="factorial-experiments.html#missing-cells"><i class="fa fa-check"></i><b>7.5</b> Missing cells</a></li>
<li class="chapter" data-level="7.6" data-path="factorial-experiments.html"><a href="factorial-experiments.html#more-than-two-factors"><i class="fa fa-check"></i><b>7.6</b> More than two factors</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ancova.html"><a href="ancova.html"><i class="fa fa-check"></i><b>8</b> ANCOVA</a></li>
<li class="chapter" data-level="9" data-path="random-effects.html"><a href="random-effects.html"><i class="fa fa-check"></i><b>9</b> Random effects</a>
<ul>
<li class="chapter" data-level="9.1" data-path="random-effects.html"><a href="random-effects.html#fixed-vs.-random-effects-the-big-picture"><i class="fa fa-check"></i><b>9.1</b> Fixed vs. random effects: the big picture</a></li>
<li class="chapter" data-level="9.2" data-path="random-effects.html"><a href="random-effects.html#random-effects-models"><i class="fa fa-check"></i><b>9.2</b> Random-effects models</a></li>
<li class="chapter" data-level="9.3" data-path="random-effects.html"><a href="random-effects.html#subsampling"><i class="fa fa-check"></i><b>9.3</b> Subsampling</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="random-effects.html"><a href="random-effects.html#equal-subsamples-per-eu"><i class="fa fa-check"></i><b>9.3.1</b> Equal subsamples per EU</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="random-effects.html"><a href="random-effects.html#starmathematical-foundations"><i class="fa fa-check"></i><b>9.4</b> <span class="math inline">\(^\star\)</span>Mathematical foundations</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="random-effects.html"><a href="random-effects.html#probability-refresher"><i class="fa fa-check"></i><b>9.4.1</b> Probability refresher</a></li>
<li class="chapter" data-level="9.4.2" data-path="random-effects.html"><a href="random-effects.html#application-to-models-with-random-effects"><i class="fa fa-check"></i><b>9.4.2</b> Application to models with random effects</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="blocked-designs.html"><a href="blocked-designs.html"><i class="fa fa-check"></i><b>10</b> Blocked designs</a>
<ul>
<li class="chapter" data-level="10.1" data-path="blocked-designs.html"><a href="blocked-designs.html#randomized-complete-block-designs"><i class="fa fa-check"></i><b>10.1</b> Randomized complete block designs</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="blocked-designs.html"><a href="blocked-designs.html#should-a-blocking-factor-be-a-fixed-or-random-effect"><i class="fa fa-check"></i><b>10.1.1</b> *Should a blocking factor be a fixed or random effect?</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="blocked-designs.html"><a href="blocked-designs.html#latin-squares-designs"><i class="fa fa-check"></i><b>10.2</b> Latin-squares designs</a></li>
<li class="chapter" data-level="10.3" data-path="blocked-designs.html"><a href="blocked-designs.html#split-plot-designs"><i class="fa fa-check"></i><b>10.3</b> Split-plot designs</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="blocked-designs.html"><a href="blocked-designs.html#denominator-degrees-of-freedom-in-split-plot-designs-and-the-satterthwaite-approximation"><i class="fa fa-check"></i><b>10.3.1</b> Denominator degrees of freedom in split-plot designs and the Satterthwaite approximation</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="blocked-designs.html"><a href="blocked-designs.html#repeated-measures"><i class="fa fa-check"></i><b>10.4</b> Repeated measures</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i>Bibliography</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical analysis of designed experiments: yesterday, today, and tomorrow</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="smoothing" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">Chapter 5</span> Smoothing<a href="smoothing.html#smoothing" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>To this point, we have focused on models that generate a useful equation for the trend. This model equation usually contains a small number of parameters that we hope to attach to scientific phenomena of interest. In other words, we have been working in Breiman’s “data-modeling culture”.</p>
<p>This chapter is different. Here, we focus on obtaining a curve (or its multi-dimensional equivalent) that characterizes the relationship between a predictor variable(s) and a response, but we don’t necessarily care about finding a mathematical equation to capture this curve. In other words, in this chapter we enter what Breiman describes as “algorithmic modeling”, or what is more commonly known as machine learning. The purpose of this chapter is to illustrate some machine-learning ideas ever so briefly to see how they compare with conventional statistical models.</p>
<p>As a running example, we will consider a data set originally published by <span class="citation">Gillibrand et al. (<a href="#ref-gillibrand2007deep">2007</a>)</span>, and analyzed extensively in the textbook by <span class="citation">Zuur et al. (<a href="#ref-zuur2009mixed">2009</a>)</span>. Zuur et al. say that these data describe the number of sources of “pelagic bioluminescence along a depth gradient in the northeast Atlantic Ocean.” We focus particulary on the data at station 16. The pattern that we wish to characterize is shown below.</p>
<p>This chapter is in an early stage of development.</p>
<div class="sourceCode" id="cb174"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb174-1"><a href="smoothing.html#cb174-1" tabindex="-1"></a><span class="do">## download the data from the book&#39;s website</span></span>
<span id="cb174-2"><a href="smoothing.html#cb174-2" tabindex="-1"></a>isit <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="st">&quot;data/ISIT.txt&quot;</span>, <span class="at">head =</span> T)</span>
<span id="cb174-3"><a href="smoothing.html#cb174-3" tabindex="-1"></a></span>
<span id="cb174-4"><a href="smoothing.html#cb174-4" tabindex="-1"></a><span class="do">## extract the data from station 16</span></span>
<span id="cb174-5"><a href="smoothing.html#cb174-5" tabindex="-1"></a></span>
<span id="cb174-6"><a href="smoothing.html#cb174-6" tabindex="-1"></a>st16 <span class="ot">&lt;-</span> <span class="fu">subset</span>(isit, Station <span class="sc">==</span> <span class="dv">16</span>)</span>
<span id="cb174-7"><a href="smoothing.html#cb174-7" tabindex="-1"></a></span>
<span id="cb174-8"><a href="smoothing.html#cb174-8" tabindex="-1"></a><span class="do">## retain just the variables that we want, and rename</span></span>
<span id="cb174-9"><a href="smoothing.html#cb174-9" tabindex="-1"></a></span>
<span id="cb174-10"><a href="smoothing.html#cb174-10" tabindex="-1"></a>st16 <span class="ot">&lt;-</span> st16[, <span class="fu">c</span>(<span class="st">&quot;SampleDepth&quot;</span>, <span class="st">&quot;Sources&quot;</span>)]</span>
<span id="cb174-11"><a href="smoothing.html#cb174-11" tabindex="-1"></a><span class="fu">names</span>(st16) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;depth&quot;</span>, <span class="st">&quot;sources&quot;</span>)</span>
<span id="cb174-12"><a href="smoothing.html#cb174-12" tabindex="-1"></a><span class="fu">with</span>(st16, <span class="fu">plot</span>(sources <span class="sc">~</span> depth))</span></code></pre></div>
<p><img src="05-Smoothing_files/figure-html/unnamed-chunk-1-1.png" width="480" style="display: block; margin: auto;" /></p>
<div id="nearest-neighbor-methods" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> Nearest-neighbor methods<a href="smoothing.html#nearest-neighbor-methods" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<!-- Some coding assistance in this section from ChatGPT 5. -->
<p>The simplest of all possible smoothing methods is a <span class="math inline">\(k\)</span>-nearest neighbor method. For this method, the value of the smooth at a target depth (<span class="math inline">\(x\)</span>) is given by the average of the response (<span class="math inline">\(y\)</span>) values of the <span class="math inline">\(k\)</span> nearest observed depths to <span class="math inline">\(x\)</span>. We implement this with <code>kknn::kknn()</code> using <code>kernel = "rectangular"</code>, which assigns equal weights to the <code>k</code> nearest neighbors.</p>
<div class="sourceCode" id="cb175"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb175-1"><a href="smoothing.html#cb175-1" tabindex="-1"></a>depth_grid <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">depth =</span> <span class="fu">seq</span>(<span class="fu">min</span>(st16<span class="sc">$</span>depth), <span class="fu">max</span>(st16<span class="sc">$</span>depth), <span class="at">length.out =</span> <span class="dv">300</span>))</span>
<span id="cb175-2"><a href="smoothing.html#cb175-2" tabindex="-1"></a></span>
<span id="cb175-3"><a href="smoothing.html#cb175-3" tabindex="-1"></a>fit_knn_grid <span class="ot">&lt;-</span> <span class="cf">function</span>(train_df, new_df, k) {</span>
<span id="cb175-4"><a href="smoothing.html#cb175-4" tabindex="-1"></a>  mod <span class="ot">&lt;-</span> kknn<span class="sc">::</span><span class="fu">kknn</span>(</span>
<span id="cb175-5"><a href="smoothing.html#cb175-5" tabindex="-1"></a>    <span class="at">formula =</span> sources <span class="sc">~</span> depth,</span>
<span id="cb175-6"><a href="smoothing.html#cb175-6" tabindex="-1"></a>    <span class="at">train =</span> train_df,</span>
<span id="cb175-7"><a href="smoothing.html#cb175-7" tabindex="-1"></a>    <span class="at">test  =</span> new_df,</span>
<span id="cb175-8"><a href="smoothing.html#cb175-8" tabindex="-1"></a>    <span class="at">k     =</span> k,</span>
<span id="cb175-9"><a href="smoothing.html#cb175-9" tabindex="-1"></a>    <span class="at">kernel =</span> <span class="st">&quot;rectangular&quot;</span></span>
<span id="cb175-10"><a href="smoothing.html#cb175-10" tabindex="-1"></a>  )</span>
<span id="cb175-11"><a href="smoothing.html#cb175-11" tabindex="-1"></a>  <span class="fu">data.frame</span>(<span class="at">depth =</span> new_df<span class="sc">$</span>depth, <span class="at">fit =</span> <span class="fu">fitted</span>(mod))</span>
<span id="cb175-12"><a href="smoothing.html#cb175-12" tabindex="-1"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb176-1"><a href="smoothing.html#cb176-1" tabindex="-1"></a>Ks_demo <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">15</span>, <span class="dv">31</span>)</span>
<span id="cb176-2"><a href="smoothing.html#cb176-2" tabindex="-1"></a>cols <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(Ks_demo)  <span class="co"># base palette</span></span>
<span id="cb176-3"><a href="smoothing.html#cb176-3" tabindex="-1"></a></span>
<span id="cb176-4"><a href="smoothing.html#cb176-4" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb176-5"><a href="smoothing.html#cb176-5" tabindex="-1"></a></span>
<span id="cb176-6"><a href="smoothing.html#cb176-6" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq_along</span>(Ks_demo)) {</span>
<span id="cb176-7"><a href="smoothing.html#cb176-7" tabindex="-1"></a>  <span class="co"># Base scatter</span></span>
<span id="cb176-8"><a href="smoothing.html#cb176-8" tabindex="-1"></a>  <span class="fu">with</span>(st16, <span class="fu">plot</span>(depth, sources, <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">cex =</span> <span class="fl">0.7</span>,</span>
<span id="cb176-9"><a href="smoothing.html#cb176-9" tabindex="-1"></a>       <span class="at">xlab =</span> <span class="st">&quot;Depth&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Sources&quot;</span>))</span>
<span id="cb176-10"><a href="smoothing.html#cb176-10" tabindex="-1"></a>  </span>
<span id="cb176-11"><a href="smoothing.html#cb176-11" tabindex="-1"></a><span class="co"># Add k-NN smooth lines</span></span>
<span id="cb176-12"><a href="smoothing.html#cb176-12" tabindex="-1"></a></span>
<span id="cb176-13"><a href="smoothing.html#cb176-13" tabindex="-1"></a>  k <span class="ot">&lt;-</span> Ks_demo[i]</span>
<span id="cb176-14"><a href="smoothing.html#cb176-14" tabindex="-1"></a>  pred <span class="ot">&lt;-</span> <span class="fu">fit_knn_grid</span>(st16, depth_grid, k)</span>
<span id="cb176-15"><a href="smoothing.html#cb176-15" tabindex="-1"></a>  <span class="fu">lines</span>(pred<span class="sc">$</span>depth, pred<span class="sc">$</span>fit, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> cols[i])</span>
<span id="cb176-16"><a href="smoothing.html#cb176-16" tabindex="-1"></a>}</span>
<span id="cb176-17"><a href="smoothing.html#cb176-17" tabindex="-1"></a></span>
<span id="cb176-18"><a href="smoothing.html#cb176-18" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="at">legend =</span> <span class="fu">paste</span>(<span class="st">&quot;k =&quot;</span>, Ks_demo),</span>
<span id="cb176-19"><a href="smoothing.html#cb176-19" tabindex="-1"></a>       <span class="at">col =</span> cols, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>)</span></code></pre></div>
<p><img src="05-Smoothing_files/figure-html/unnamed-chunk-2-1.png" width="720" style="display: block; margin: auto;" /></p>
<p>As <span class="math inline">\(k\)</span> increases, the trend becomes smoother.</p>
<p>To find the best <code>k</code>, we use cross-validation. Here, we evaluate a set of odd <code>k</code> values with 10-fold cross-validation and choose the <code>k</code> that minimizes out-of-fold SSE.</p>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb177-1"><a href="smoothing.html#cb177-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb177-2"><a href="smoothing.html#cb177-2" tabindex="-1"></a></span>
<span id="cb177-3"><a href="smoothing.html#cb177-3" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">nrow</span>(st16)</span>
<span id="cb177-4"><a href="smoothing.html#cb177-4" tabindex="-1"></a>Kfold <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb177-5"><a href="smoothing.html#cb177-5" tabindex="-1"></a>fold_id <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">rep</span>(<span class="dv">1</span><span class="sc">:</span>Kfold, <span class="at">length.out =</span> n))</span>
<span id="cb177-6"><a href="smoothing.html#cb177-6" tabindex="-1"></a></span>
<span id="cb177-7"><a href="smoothing.html#cb177-7" tabindex="-1"></a><span class="co"># Compute the minimum possible training size across folds</span></span>
<span id="cb177-8"><a href="smoothing.html#cb177-8" tabindex="-1"></a>fold_sizes <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">table</span>(fold_id))</span>
<span id="cb177-9"><a href="smoothing.html#cb177-9" tabindex="-1"></a>min_train_size <span class="ot">&lt;-</span> <span class="fu">min</span>(n <span class="sc">-</span> fold_sizes)  <span class="co"># worst-case training rows</span></span>
<span id="cb177-10"><a href="smoothing.html#cb177-10" tabindex="-1"></a></span>
<span id="cb177-11"><a href="smoothing.html#cb177-11" tabindex="-1"></a><span class="co"># Cap k by this minimum training size (and by 61 as before), and use odd k &gt;= 3</span></span>
<span id="cb177-12"><a href="smoothing.html#cb177-12" tabindex="-1"></a>max_k_allowed <span class="ot">&lt;-</span> <span class="fu">max</span>(<span class="dv">3</span>, <span class="fu">min</span>(<span class="dv">61</span>, min_train_size))</span>
<span id="cb177-13"><a href="smoothing.html#cb177-13" tabindex="-1"></a>Ks <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">3</span>, max_k_allowed, <span class="at">by =</span> <span class="dv">2</span>)</span>
<span id="cb177-14"><a href="smoothing.html#cb177-14" tabindex="-1"></a></span>
<span id="cb177-15"><a href="smoothing.html#cb177-15" tabindex="-1"></a>cv_mse <span class="ot">&lt;-</span> <span class="fu">numeric</span>(<span class="fu">length</span>(Ks))</span>
<span id="cb177-16"><a href="smoothing.html#cb177-16" tabindex="-1"></a><span class="fu">names</span>(cv_mse) <span class="ot">&lt;-</span> Ks</span>
<span id="cb177-17"><a href="smoothing.html#cb177-17" tabindex="-1"></a></span>
<span id="cb177-18"><a href="smoothing.html#cb177-18" tabindex="-1"></a><span class="cf">for</span> (j <span class="cf">in</span> <span class="fu">seq_along</span>(Ks)) {</span>
<span id="cb177-19"><a href="smoothing.html#cb177-19" tabindex="-1"></a>  k <span class="ot">&lt;-</span> Ks[j]</span>
<span id="cb177-20"><a href="smoothing.html#cb177-20" tabindex="-1"></a>  mse_fold <span class="ot">&lt;-</span> <span class="fu">numeric</span>(Kfold)</span>
<span id="cb177-21"><a href="smoothing.html#cb177-21" tabindex="-1"></a>  <span class="cf">for</span> (f <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>Kfold) {</span>
<span id="cb177-22"><a href="smoothing.html#cb177-22" tabindex="-1"></a>    train_df <span class="ot">&lt;-</span> st16[fold_id <span class="sc">!=</span> f, , drop <span class="ot">=</span> <span class="cn">FALSE</span>]</span>
<span id="cb177-23"><a href="smoothing.html#cb177-23" tabindex="-1"></a>    test_df  <span class="ot">&lt;-</span> st16[fold_id <span class="sc">==</span> f, , drop <span class="ot">=</span> <span class="cn">FALSE</span>]</span>
<span id="cb177-24"><a href="smoothing.html#cb177-24" tabindex="-1"></a>    <span class="cf">if</span> (<span class="fu">nrow</span>(test_df) <span class="sc">==</span> <span class="dv">0</span> <span class="sc">||</span> <span class="fu">nrow</span>(train_df) <span class="sc">&lt;</span> k) { </span>
<span id="cb177-25"><a href="smoothing.html#cb177-25" tabindex="-1"></a>      mse_fold[f] <span class="ot">&lt;-</span> <span class="cn">NA_real_</span>; </span>
<span id="cb177-26"><a href="smoothing.html#cb177-26" tabindex="-1"></a>      <span class="cf">next</span> </span>
<span id="cb177-27"><a href="smoothing.html#cb177-27" tabindex="-1"></a>    }</span>
<span id="cb177-28"><a href="smoothing.html#cb177-28" tabindex="-1"></a>    mod <span class="ot">&lt;-</span> kknn<span class="sc">::</span><span class="fu">kknn</span>(sources <span class="sc">~</span> depth, <span class="at">train =</span> train_df, <span class="at">test =</span> test_df,</span>
<span id="cb177-29"><a href="smoothing.html#cb177-29" tabindex="-1"></a>                      <span class="at">k =</span> k, <span class="at">kernel =</span> <span class="st">&quot;rectangular&quot;</span>)</span>
<span id="cb177-30"><a href="smoothing.html#cb177-30" tabindex="-1"></a>    mse_fold[f] <span class="ot">&lt;-</span> <span class="fu">mean</span>((test_df<span class="sc">$</span>sources <span class="sc">-</span> <span class="fu">as.numeric</span>(<span class="fu">fitted</span>(mod)))<span class="sc">^</span><span class="dv">2</span>, <span class="at">na.rm =</span> <span class="cn">TRUE</span>)</span>
<span id="cb177-31"><a href="smoothing.html#cb177-31" tabindex="-1"></a>  }</span>
<span id="cb177-32"><a href="smoothing.html#cb177-32" tabindex="-1"></a>  cv_mse[j] <span class="ot">&lt;-</span> <span class="fu">mean</span>(mse_fold, <span class="at">na.rm =</span> <span class="cn">TRUE</span>)</span>
<span id="cb177-33"><a href="smoothing.html#cb177-33" tabindex="-1"></a>}</span>
<span id="cb177-34"><a href="smoothing.html#cb177-34" tabindex="-1"></a></span>
<span id="cb177-35"><a href="smoothing.html#cb177-35" tabindex="-1"></a>best_k <span class="ot">&lt;-</span> <span class="fu">as.integer</span>(<span class="fu">names</span>(cv_mse)[<span class="fu">which.min</span>(cv_mse)])</span>
<span id="cb177-36"><a href="smoothing.html#cb177-36" tabindex="-1"></a>best_k</span></code></pre></div>
<pre><code>## [1] 3</code></pre>
<div class="sourceCode" id="cb179"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb179-1"><a href="smoothing.html#cb179-1" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">as.integer</span>(<span class="fu">names</span>(cv_mse)), cv_mse, <span class="at">type =</span> <span class="st">&quot;b&quot;</span>,</span>
<span id="cb179-2"><a href="smoothing.html#cb179-2" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Number of Neighbors (k)&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Out-of-fold MSE&quot;</span>,</span>
<span id="cb179-3"><a href="smoothing.html#cb179-3" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;10-fold CV to Choose k&quot;</span>)</span>
<span id="cb179-4"><a href="smoothing.html#cb179-4" tabindex="-1"></a><span class="fu">grid</span>()</span>
<span id="cb179-5"><a href="smoothing.html#cb179-5" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> best_k, <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb179-6"><a href="smoothing.html#cb179-6" tabindex="-1"></a><span class="fu">text</span>(best_k, <span class="fu">min</span>(cv_mse, <span class="at">na.rm =</span> <span class="cn">TRUE</span>), <span class="at">labels =</span> <span class="fu">paste</span>(<span class="st">&quot;best k =&quot;</span>, best_k),</span>
<span id="cb179-7"><a href="smoothing.html#cb179-7" tabindex="-1"></a>     <span class="at">pos =</span> <span class="dv">4</span>, <span class="at">cex =</span> <span class="fl">0.9</span>)</span></code></pre></div>
<p><img src="05-Smoothing_files/figure-html/cv-plot-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>In this case, cross-validations suggests we should set <span class="math inline">\(k=3\)</span>!. Here’s the final fit with <span class="math inline">\(k=3\)</span>.</p>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="smoothing.html#cb180-1" tabindex="-1"></a>pred_final <span class="ot">&lt;-</span> <span class="fu">fit_knn_grid</span>(st16, depth_grid, best_k)</span>
<span id="cb180-2"><a href="smoothing.html#cb180-2" tabindex="-1"></a></span>
<span id="cb180-3"><a href="smoothing.html#cb180-3" tabindex="-1"></a><span class="fu">plot</span>(st16<span class="sc">$</span>depth, st16<span class="sc">$</span>sources, <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">cex =</span> <span class="fl">0.7</span>,</span>
<span id="cb180-4"><a href="smoothing.html#cb180-4" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Depth&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Sources&quot;</span>,</span>
<span id="cb180-5"><a href="smoothing.html#cb180-5" tabindex="-1"></a>     <span class="at">main =</span> <span class="fu">paste</span>(<span class="st">&quot;k-NN Smoother with CV-selected k =&quot;</span>, best_k))</span>
<span id="cb180-6"><a href="smoothing.html#cb180-6" tabindex="-1"></a><span class="fu">lines</span>(pred_final<span class="sc">$</span>depth, pred_final<span class="sc">$</span>fit, <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="05-Smoothing_files/figure-html/final-fit-1.png" width="624" style="display: block; margin: auto;" /></p>
</div>
<div id="loess-smoothers" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> Loess smoothers<a href="smoothing.html#loess-smoothers" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A loess smoother takes the logic of <span class="math inline">\(k\)</span>-nearest neighbor fitting one step further. Now, instead of simply averaging the <span class="math inline">\(k\)</span> nearest neighbors, we fit a regression model to the nearest neighbors, and use the predicted value of the regression trend as our smooth. “Loess” is an acronym for [lo]cal regr[ess]ion. Nomenclature can be a bit frustrating with loess models. As we will see later, some versions of loess models use weighted least squares instead of ordinary least squares, and are called “lowess” models to emphasize the use of weighted least squares. However, the basic <code>R</code> routine for fitting lo(w)ess models is called <code>loess</code>, but uses the weighted least-squares fitting with its default factory settings.</p>
<p>Fit a loess smoother using the factory settings:</p>
<div class="sourceCode" id="cb181"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb181-1"><a href="smoothing.html#cb181-1" tabindex="-1"></a>st16.lo <span class="ot">&lt;-</span> <span class="fu">loess</span>(sources <span class="sc">~</span> depth, <span class="at">data =</span> st16)</span>
<span id="cb181-2"><a href="smoothing.html#cb181-2" tabindex="-1"></a><span class="fu">summary</span>(st16.lo)</span></code></pre></div>
<pre><code>## Call:
## loess(formula = sources ~ depth, data = st16)
## 
## Number of Observations: 51 
## Equivalent Number of Parameters: 4.33 
## Residual Standard Error: 4.18 
## Trace of smoother matrix: 4.73  (exact)
## 
## Control settings:
##   span     :  0.75 
##   degree   :  2 
##   family   :  gaussian
##   surface  :  interpolate      cell = 0.2
##   normalize:  TRUE
##  parametric:  FALSE
## drop.square:  FALSE</code></pre>
<p>Plot the fit, this takes a little work</p>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb183-1"><a href="smoothing.html#cb183-1" tabindex="-1"></a>depth.vals <span class="ot">&lt;-</span> <span class="fu">with</span>(st16, <span class="fu">seq</span>(<span class="at">from   =</span> <span class="fu">min</span>(depth), </span>
<span id="cb183-2"><a href="smoothing.html#cb183-2" tabindex="-1"></a>                             <span class="at">to     =</span> <span class="fu">max</span>(depth), </span>
<span id="cb183-3"><a href="smoothing.html#cb183-3" tabindex="-1"></a>                             <span class="at">length =</span> <span class="dv">100</span>))</span>
<span id="cb183-4"><a href="smoothing.html#cb183-4" tabindex="-1"></a></span>
<span id="cb183-5"><a href="smoothing.html#cb183-5" tabindex="-1"></a>st16.fit <span class="ot">&lt;-</span> <span class="fu">predict</span>(<span class="at">object  =</span> st16.lo,</span>
<span id="cb183-6"><a href="smoothing.html#cb183-6" tabindex="-1"></a>                    <span class="at">newdata =</span> depth.vals,</span>
<span id="cb183-7"><a href="smoothing.html#cb183-7" tabindex="-1"></a>                    <span class="at">se      =</span> <span class="cn">TRUE</span>)</span>
<span id="cb183-8"><a href="smoothing.html#cb183-8" tabindex="-1"></a></span>
<span id="cb183-9"><a href="smoothing.html#cb183-9" tabindex="-1"></a><span class="fu">with</span>(st16, <span class="fu">plot</span>(sources <span class="sc">~</span> depth))</span>
<span id="cb183-10"><a href="smoothing.html#cb183-10" tabindex="-1"></a><span class="fu">lines</span>(<span class="at">x =</span> depth.vals, <span class="at">y =</span> st16.fit<span class="sc">$</span>fit, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>)</span>
<span id="cb183-11"><a href="smoothing.html#cb183-11" tabindex="-1"></a></span>
<span id="cb183-12"><a href="smoothing.html#cb183-12" tabindex="-1"></a><span class="co"># add 95% error bars</span></span>
<span id="cb183-13"><a href="smoothing.html#cb183-13" tabindex="-1"></a><span class="fu">lines</span>(<span class="at">x   =</span> depth.vals, </span>
<span id="cb183-14"><a href="smoothing.html#cb183-14" tabindex="-1"></a>      <span class="at">y   =</span> st16.fit<span class="sc">$</span>fit <span class="sc">+</span> st16.fit<span class="sc">$</span>se.fit <span class="sc">*</span> <span class="fu">qt</span>(<span class="at">p =</span> .<span class="dv">975</span>, <span class="at">df =</span> st16.fit<span class="sc">$</span>df),</span>
<span id="cb183-15"><a href="smoothing.html#cb183-15" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>,</span>
<span id="cb183-16"><a href="smoothing.html#cb183-16" tabindex="-1"></a>      <span class="at">lty =</span> <span class="st">&quot;dashed&quot;</span>)</span>
<span id="cb183-17"><a href="smoothing.html#cb183-17" tabindex="-1"></a></span>
<span id="cb183-18"><a href="smoothing.html#cb183-18" tabindex="-1"></a><span class="fu">lines</span>(<span class="at">x   =</span> depth.vals, </span>
<span id="cb183-19"><a href="smoothing.html#cb183-19" tabindex="-1"></a>      <span class="at">y   =</span> st16.fit<span class="sc">$</span>fit <span class="sc">-</span> st16.fit<span class="sc">$</span>se.fit <span class="sc">*</span> <span class="fu">qt</span>(<span class="at">p =</span> .<span class="dv">975</span>, <span class="at">df =</span> st16.fit<span class="sc">$</span>df),</span>
<span id="cb183-20"><a href="smoothing.html#cb183-20" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>,</span>
<span id="cb183-21"><a href="smoothing.html#cb183-21" tabindex="-1"></a>      <span class="at">lty =</span> <span class="st">&quot;dashed&quot;</span>)</span></code></pre></div>
<p><img src="05-Smoothing_files/figure-html/unnamed-chunk-4-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Examine the residuals:</p>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb184-1"><a href="smoothing.html#cb184-1" tabindex="-1"></a><span class="do">## see what the fit returns; maybe the residuals are already there</span></span>
<span id="cb184-2"><a href="smoothing.html#cb184-2" tabindex="-1"></a></span>
<span id="cb184-3"><a href="smoothing.html#cb184-3" tabindex="-1"></a><span class="fu">names</span>(st16.lo)  <span class="co"># they are!</span></span></code></pre></div>
<pre><code>##  [1] &quot;n&quot;         &quot;fitted&quot;    &quot;residuals&quot; &quot;enp&quot;       &quot;s&quot;         &quot;one.delta&quot;
##  [7] &quot;two.delta&quot; &quot;trace.hat&quot; &quot;divisor&quot;   &quot;robust&quot;    &quot;pars&quot;      &quot;kd&quot;       
## [13] &quot;call&quot;      &quot;terms&quot;     &quot;xnames&quot;    &quot;x&quot;         &quot;y&quot;         &quot;weights&quot;</code></pre>
<div class="sourceCode" id="cb186"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb186-1"><a href="smoothing.html#cb186-1" tabindex="-1"></a><span class="fu">plot</span>(st16.lo<span class="sc">$</span>residuals <span class="sc">~</span> st16<span class="sc">$</span>depth)</span>
<span id="cb186-2"><a href="smoothing.html#cb186-2" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="dv">0</span>, <span class="at">lty =</span> <span class="st">&quot;dotted&quot;</span>)</span></code></pre></div>
<p><img src="05-Smoothing_files/figure-html/unnamed-chunk-5-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Let’s look at how changing the span changes the fit. We’ll write a custom function to fit a LOESS curve, and then call the function with various values for the span.</p>
<div class="sourceCode" id="cb187"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb187-1"><a href="smoothing.html#cb187-1" tabindex="-1"></a>PlotLoessFit <span class="ot">&lt;-</span> <span class="cf">function</span>(x, y, <span class="at">return.fit =</span> <span class="cn">FALSE</span>, ...){</span>
<span id="cb187-2"><a href="smoothing.html#cb187-2" tabindex="-1"></a>  </span>
<span id="cb187-3"><a href="smoothing.html#cb187-3" tabindex="-1"></a>  <span class="co"># Caluclates a loess fit with the &#39;loess&#39; function, and makes a plot</span></span>
<span id="cb187-4"><a href="smoothing.html#cb187-4" tabindex="-1"></a>  <span class="co">#</span></span>
<span id="cb187-5"><a href="smoothing.html#cb187-5" tabindex="-1"></a>  <span class="co"># Args:</span></span>
<span id="cb187-6"><a href="smoothing.html#cb187-6" tabindex="-1"></a>  <span class="co">#   x: predictor</span></span>
<span id="cb187-7"><a href="smoothing.html#cb187-7" tabindex="-1"></a>  <span class="co">#   y: response</span></span>
<span id="cb187-8"><a href="smoothing.html#cb187-8" tabindex="-1"></a>  <span class="co">#   return.fit: logical</span></span>
<span id="cb187-9"><a href="smoothing.html#cb187-9" tabindex="-1"></a>  <span class="co">#   ...: Optional arguments to loess</span></span>
<span id="cb187-10"><a href="smoothing.html#cb187-10" tabindex="-1"></a>  <span class="co">#</span></span>
<span id="cb187-11"><a href="smoothing.html#cb187-11" tabindex="-1"></a>  <span class="co"># Returns:</span></span>
<span id="cb187-12"><a href="smoothing.html#cb187-12" tabindex="-1"></a>  <span class="co">#   the loess fit</span></span>
<span id="cb187-13"><a href="smoothing.html#cb187-13" tabindex="-1"></a>  </span>
<span id="cb187-14"><a href="smoothing.html#cb187-14" tabindex="-1"></a>  my.lo <span class="ot">&lt;-</span> <span class="fu">loess</span>(y <span class="sc">~</span> x, ...)</span>
<span id="cb187-15"><a href="smoothing.html#cb187-15" tabindex="-1"></a>  </span>
<span id="cb187-16"><a href="smoothing.html#cb187-16" tabindex="-1"></a>  x.vals <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="fu">min</span>(x), <span class="at">to =</span> <span class="fu">max</span>(x), <span class="at">length =</span> <span class="dv">100</span>)</span>
<span id="cb187-17"><a href="smoothing.html#cb187-17" tabindex="-1"></a>  </span>
<span id="cb187-18"><a href="smoothing.html#cb187-18" tabindex="-1"></a>  my.fit <span class="ot">&lt;-</span> <span class="fu">predict</span>(<span class="at">object  =</span> my.lo,</span>
<span id="cb187-19"><a href="smoothing.html#cb187-19" tabindex="-1"></a>                    <span class="at">newdata =</span> x.vals,</span>
<span id="cb187-20"><a href="smoothing.html#cb187-20" tabindex="-1"></a>                    <span class="at">se      =</span> <span class="cn">TRUE</span>)</span>
<span id="cb187-21"><a href="smoothing.html#cb187-21" tabindex="-1"></a>  </span>
<span id="cb187-22"><a href="smoothing.html#cb187-22" tabindex="-1"></a>  <span class="fu">plot</span>(x, y)</span>
<span id="cb187-23"><a href="smoothing.html#cb187-23" tabindex="-1"></a>  <span class="fu">lines</span>(<span class="at">x =</span> x.vals, <span class="at">y =</span> my.fit<span class="sc">$</span>fit, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>)</span>
<span id="cb187-24"><a href="smoothing.html#cb187-24" tabindex="-1"></a>  </span>
<span id="cb187-25"><a href="smoothing.html#cb187-25" tabindex="-1"></a>  <span class="fu">lines</span>(<span class="at">x   =</span> x.vals, </span>
<span id="cb187-26"><a href="smoothing.html#cb187-26" tabindex="-1"></a>        <span class="at">y   =</span> my.fit<span class="sc">$</span>fit <span class="sc">+</span> my.fit<span class="sc">$</span>se.fit <span class="sc">*</span> <span class="fu">qt</span>(<span class="at">p =</span> .<span class="dv">975</span>, <span class="at">df =</span> my.fit<span class="sc">$</span>df),</span>
<span id="cb187-27"><a href="smoothing.html#cb187-27" tabindex="-1"></a>        <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>,</span>
<span id="cb187-28"><a href="smoothing.html#cb187-28" tabindex="-1"></a>        <span class="at">lty =</span> <span class="st">&quot;dashed&quot;</span>)</span>
<span id="cb187-29"><a href="smoothing.html#cb187-29" tabindex="-1"></a>  </span>
<span id="cb187-30"><a href="smoothing.html#cb187-30" tabindex="-1"></a>  <span class="fu">lines</span>(<span class="at">x   =</span> x.vals, </span>
<span id="cb187-31"><a href="smoothing.html#cb187-31" tabindex="-1"></a>        <span class="at">y   =</span> my.fit<span class="sc">$</span>fit <span class="sc">-</span> my.fit<span class="sc">$</span>se.fit <span class="sc">*</span> <span class="fu">qt</span>(<span class="at">p =</span> .<span class="dv">975</span>, <span class="at">df =</span> my.fit<span class="sc">$</span>df),</span>
<span id="cb187-32"><a href="smoothing.html#cb187-32" tabindex="-1"></a>        <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>,</span>
<span id="cb187-33"><a href="smoothing.html#cb187-33" tabindex="-1"></a>        <span class="at">lty =</span> <span class="st">&quot;dashed&quot;</span>)</span>
<span id="cb187-34"><a href="smoothing.html#cb187-34" tabindex="-1"></a>  </span>
<span id="cb187-35"><a href="smoothing.html#cb187-35" tabindex="-1"></a>  <span class="cf">if</span> (return.fit) {</span>
<span id="cb187-36"><a href="smoothing.html#cb187-36" tabindex="-1"></a>    <span class="fu">return</span>(my.lo)</span>
<span id="cb187-37"><a href="smoothing.html#cb187-37" tabindex="-1"></a>  }</span>
<span id="cb187-38"><a href="smoothing.html#cb187-38" tabindex="-1"></a>}</span></code></pre></div>
<p>Now we’ll call the function several times, each time chanigng the value of the <code>span</code> argument to the <code>loess</code> function:</p>
<div class="sourceCode" id="cb188"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb188-1"><a href="smoothing.html#cb188-1" tabindex="-1"></a><span class="fu">PlotLoessFit</span>(<span class="at">x =</span> st16<span class="sc">$</span>depth, <span class="at">y =</span> st16<span class="sc">$</span>sources, <span class="at">span =</span> <span class="fl">0.5</span>)</span></code></pre></div>
<p><img src="05-Smoothing_files/figure-html/unnamed-chunk-7-1.png" width="480" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb189"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb189-1"><a href="smoothing.html#cb189-1" tabindex="-1"></a><span class="fu">PlotLoessFit</span>(<span class="at">x =</span> st16<span class="sc">$</span>depth, <span class="at">y =</span> st16<span class="sc">$</span>sources, <span class="at">span =</span> <span class="fl">0.25</span>)</span></code></pre></div>
<p><img src="05-Smoothing_files/figure-html/unnamed-chunk-7-2.png" width="480" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb190"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb190-1"><a href="smoothing.html#cb190-1" tabindex="-1"></a><span class="fu">PlotLoessFit</span>(<span class="at">x =</span> st16<span class="sc">$</span>depth, <span class="at">y =</span> st16<span class="sc">$</span>sources, <span class="at">span =</span> <span class="fl">0.1</span>)</span></code></pre></div>
<p><img src="05-Smoothing_files/figure-html/unnamed-chunk-7-3.png" width="480" style="display: block; margin: auto;" /></p>
<p>Let’s try a loess fit with a locally linear regression:</p>
<div class="sourceCode" id="cb191"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb191-1"><a href="smoothing.html#cb191-1" tabindex="-1"></a><span class="fu">PlotLoessFit</span>(<span class="at">x =</span> st16<span class="sc">$</span>depth, <span class="at">y =</span> st16<span class="sc">$</span>sources, <span class="at">span =</span> <span class="fl">0.25</span>, <span class="at">degree =</span> <span class="dv">1</span>)</span></code></pre></div>
<p><img src="05-Smoothing_files/figure-html/unnamed-chunk-8-1.png" width="480" style="display: block; margin: auto;" /></p>
</div>
<div id="splines" class="section level2 hasAnchor" number="5.3">
<h2><span class="header-section-number">5.3</span> Splines<a href="smoothing.html#splines" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We’ll use the <code>gam</code> function in the <code>mgcv</code> package to fit splines and additive models. The name of the package is an acronym for “Mixed GAM Computation Vehicle”. GAM is an acronym for Generalized Additive Model. <strong>Warning</strong>. I do not understand much of the functionality of <code>mgcv::gam</code>. What follows is my best guess of how the procedure works.</p>
<p>The code below fits a regression spline to the bioluminescence data. Actually, the code fits an additive model with the spline as the only predictor. We will say more about additive models later. For now, it is sufficient to think about an additive model as a type of regression in which the linear effect of the predictor has been replaced by a spline. In other words, in terms of a word equation, the model can be represented as
<span class="math display">\[
\mbox{response = intercept + spline + error}
\]</span></p>
<p>The <code>s()</code> component of the model formula designates a spline, and specifies details about the particular type of spline to be fit. The <code>fx = TRUE</code> component of the formula indicates that the amount of smoothing is fixed. The default value for the <code>fx</code> argument is <code>fx = FALSE</code>, in which case the amount of smoothing is determined by (generalized) cross-validation. When <code>fx = TRUE</code>, the parameter <code>k</code> determines the dimensionality (degree of flexibility) of the spline. Larger values of <code>k</code> correspond to greater flexibility, and a less smooth fit. I think that the number of knots is <span class="math inline">\(k-4\)</span>, such that setting <span class="math inline">\(k=4\)</span> fits a familiar cubic polynomial with no knots. Setting <span class="math inline">\(k=5\)</span> then fits a regression spline with one knot, etc. I have not been able to figure out where the knots are placed.</p>
<p>In any case, we’ll fit a regression spline with two knots:</p>
<div class="sourceCode" id="cb192"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb192-1"><a href="smoothing.html#cb192-1" tabindex="-1"></a><span class="fu">library</span>(mgcv)</span></code></pre></div>
<pre><code>## Loading required package: nlme</code></pre>
<pre><code>## This is mgcv 1.9-3. For overview type &#39;help(&quot;mgcv-package&quot;)&#39;.</code></pre>
<div class="sourceCode" id="cb195"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb195-1"><a href="smoothing.html#cb195-1" tabindex="-1"></a>st16.rspline <span class="ot">&lt;-</span> mgcv<span class="sc">::</span><span class="fu">gam</span>(sources <span class="sc">~</span> <span class="fu">s</span>(depth, <span class="at">k =</span> <span class="dv">6</span>, <span class="at">fx =</span> <span class="cn">TRUE</span>), <span class="at">data =</span> st16)</span>
<span id="cb195-2"><a href="smoothing.html#cb195-2" tabindex="-1"></a><span class="fu">plot</span>(st16.rspline, <span class="at">se =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="05-Smoothing_files/figure-html/unnamed-chunk-9-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Note that the plot includes only the portion of the model attributable to the covariate effect. This is because we have actually fit an additive model (e.g., a GAM).</p>
<p>The plot shows only the spline component, which thus does not include the intercept. To visualize the fit, we’ll need to do a bit more work.</p>
<div class="sourceCode" id="cb196"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb196-1"><a href="smoothing.html#cb196-1" tabindex="-1"></a><span class="fu">with</span>(st16, <span class="fu">plot</span>(sources <span class="sc">~</span> depth))  </span>
<span id="cb196-2"><a href="smoothing.html#cb196-2" tabindex="-1"></a></span>
<span id="cb196-3"><a href="smoothing.html#cb196-3" tabindex="-1"></a>st16.fit <span class="ot">&lt;-</span> <span class="fu">predict</span>(st16.rspline, </span>
<span id="cb196-4"><a href="smoothing.html#cb196-4" tabindex="-1"></a>                    <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">depth =</span> depth.vals), </span>
<span id="cb196-5"><a href="smoothing.html#cb196-5" tabindex="-1"></a>                    <span class="at">se      =</span> <span class="cn">TRUE</span>)</span>
<span id="cb196-6"><a href="smoothing.html#cb196-6" tabindex="-1"></a></span>
<span id="cb196-7"><a href="smoothing.html#cb196-7" tabindex="-1"></a><span class="fu">lines</span>(<span class="at">x =</span> depth.vals, <span class="at">y =</span> st16.fit<span class="sc">$</span>fit)</span>
<span id="cb196-8"><a href="smoothing.html#cb196-8" tabindex="-1"></a></span>
<span id="cb196-9"><a href="smoothing.html#cb196-9" tabindex="-1"></a><span class="do">## add +/- 2 SE following Zuur; this is only approximate.</span></span>
<span id="cb196-10"><a href="smoothing.html#cb196-10" tabindex="-1"></a><span class="do">## should probably use a critical value from a t-dist with n - edf df, that is, 51 - 5 = 46 df</span></span>
<span id="cb196-11"><a href="smoothing.html#cb196-11" tabindex="-1"></a></span>
<span id="cb196-12"><a href="smoothing.html#cb196-12" tabindex="-1"></a><span class="fu">lines</span>(<span class="at">x =</span> depth.vals, <span class="at">y =</span> st16.fit<span class="sc">$</span>fit <span class="sc">+</span> <span class="dv">2</span> <span class="sc">*</span> st16.fit<span class="sc">$</span>se.fit, <span class="at">lty =</span> <span class="st">&quot;dashed&quot;</span>)</span>
<span id="cb196-13"><a href="smoothing.html#cb196-13" tabindex="-1"></a><span class="fu">lines</span>(<span class="at">x =</span> depth.vals, <span class="at">y =</span> st16.fit<span class="sc">$</span>fit <span class="sc">-</span> <span class="dv">2</span> <span class="sc">*</span> st16.fit<span class="sc">$</span>se.fit, <span class="at">lty =</span> <span class="st">&quot;dashed&quot;</span>)</span></code></pre></div>
<p><img src="05-Smoothing_files/figure-html/unnamed-chunk-10-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>We see that this particular fit is not flexible enough to capture the trend in luminescence at low depth.</p>
<p>Let’s take a look at the information produced by a call to <code>summary</code>:</p>
<div class="sourceCode" id="cb197"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb197-1"><a href="smoothing.html#cb197-1" tabindex="-1"></a><span class="fu">summary</span>(st16.rspline)</span></code></pre></div>
<pre><code>## 
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## sources ~ s(depth, k = 6, fx = TRUE)
## 
## Parametric coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  12.4771     0.5858    21.3   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Approximate significance of smooth terms:
##          edf Ref.df     F p-value    
## s(depth)   5      5 122.6  &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## R-sq.(adj) =  0.924   Deviance explained = 93.2%
## GCV = 19.837  Scale est. = 17.503    n = 51</code></pre>
<p>This summary requires a bit more explanation as well. In this GAM, the spline component of the model effectively creates a set of new predictor variables. A regression spline with <span class="math inline">\(x\)</span> knots requires <span class="math inline">\(x+3\)</span> new regression predictors to fit the spline. In this fit, there are two knots, so the spline requires 5 new predictor variables. Because the predictors are determined in advance with regression splines, we can use the usual theory of <span class="math inline">\(F\)</span>-tests from regression to assess the statistical significance of the spline terms. In the section of the output labeled “Approximate significance of smooth terms”, we see that these 5 predictors together provide a significantly better fit than a model that does not include the spline. I believe this test is actually exact. I think that it is labeled “approximate” because the default behavior of <code>mgcv::gam</code> is to fit a smoothing spline, for which the test is indeed only approximate. We’ll discuss this more when we study a smoothing spline fit.</p>
<p>Now we’ll fit and plot a smoothing spline. A smoothing spline differs from a regression spline by using generalized cross-validation to determine the appropriate smoothness.</p>
<div class="sourceCode" id="cb199"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb199-1"><a href="smoothing.html#cb199-1" tabindex="-1"></a>st16.spline <span class="ot">&lt;-</span> mgcv<span class="sc">::</span><span class="fu">gam</span>(sources <span class="sc">~</span> <span class="fu">s</span>(depth), <span class="at">data =</span> st16)</span>
<span id="cb199-2"><a href="smoothing.html#cb199-2" tabindex="-1"></a><span class="fu">plot</span>(st16.spline, <span class="at">se =</span> <span class="cn">TRUE</span>)  <span class="co"># note that the plot does not include the intercept</span></span></code></pre></div>
<p><img src="05-Smoothing_files/figure-html/unnamed-chunk-12-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Again, we make a plot that includes both the points and the fit</p>
<div class="sourceCode" id="cb200"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb200-1"><a href="smoothing.html#cb200-1" tabindex="-1"></a><span class="fu">with</span>(st16, <span class="fu">plot</span>(sources <span class="sc">~</span> depth))  </span>
<span id="cb200-2"><a href="smoothing.html#cb200-2" tabindex="-1"></a></span>
<span id="cb200-3"><a href="smoothing.html#cb200-3" tabindex="-1"></a>st16.fit <span class="ot">&lt;-</span> <span class="fu">predict</span>(st16.spline, </span>
<span id="cb200-4"><a href="smoothing.html#cb200-4" tabindex="-1"></a>                    <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">depth =</span> depth.vals), </span>
<span id="cb200-5"><a href="smoothing.html#cb200-5" tabindex="-1"></a>                    <span class="at">se      =</span> <span class="cn">TRUE</span>)</span>
<span id="cb200-6"><a href="smoothing.html#cb200-6" tabindex="-1"></a></span>
<span id="cb200-7"><a href="smoothing.html#cb200-7" tabindex="-1"></a><span class="fu">lines</span>(<span class="at">x =</span> depth.vals, <span class="at">y =</span> st16.fit<span class="sc">$</span>fit)</span>
<span id="cb200-8"><a href="smoothing.html#cb200-8" tabindex="-1"></a></span>
<span id="cb200-9"><a href="smoothing.html#cb200-9" tabindex="-1"></a><span class="do">## add +/- 2 SE following Zuur; this is only approximate.</span></span>
<span id="cb200-10"><a href="smoothing.html#cb200-10" tabindex="-1"></a><span class="do">## should probably use a critical value from a t-dist with n - edf df, that is, 51 - 9.81 = 41.19 df</span></span>
<span id="cb200-11"><a href="smoothing.html#cb200-11" tabindex="-1"></a></span>
<span id="cb200-12"><a href="smoothing.html#cb200-12" tabindex="-1"></a><span class="fu">lines</span>(<span class="at">x =</span> depth.vals, <span class="at">y =</span> st16.fit<span class="sc">$</span>fit <span class="sc">+</span> <span class="dv">2</span> <span class="sc">*</span> st16.fit<span class="sc">$</span>se.fit, <span class="at">lty =</span> <span class="st">&quot;dashed&quot;</span>)</span>
<span id="cb200-13"><a href="smoothing.html#cb200-13" tabindex="-1"></a><span class="fu">lines</span>(<span class="at">x =</span> depth.vals, <span class="at">y =</span> st16.fit<span class="sc">$</span>fit <span class="sc">-</span> <span class="dv">2</span> <span class="sc">*</span> st16.fit<span class="sc">$</span>se.fit, <span class="at">lty =</span> <span class="st">&quot;dashed&quot;</span>)</span></code></pre></div>
<p><img src="05-Smoothing_files/figure-html/unnamed-chunk-13-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Let’s ask for a summary:</p>
<div class="sourceCode" id="cb201"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb201-1"><a href="smoothing.html#cb201-1" tabindex="-1"></a><span class="fu">summary</span>(st16.spline)</span></code></pre></div>
<pre><code>## 
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## sources ~ s(depth)
## 
## Parametric coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  12.4771     0.3921   31.82   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Approximate significance of smooth terms:
##            edf Ref.df     F p-value    
## s(depth) 8.813   8.99 158.2  &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## R-sq.(adj) =  0.966   Deviance explained = 97.2%
## GCV = 9.7081  Scale est. = 7.8402    n = 51</code></pre>
<p>Note especially the <code>edf</code> component in the “Approximate significance of smooth terms” section. The label <code>edf</code> stands for effective degrees of freedom. We can think of the edf as the effective number of new predictors that have been added to the model to accommodate the spline. For a smoothing spline, the number and values of the newly created predictors are determined by fitting the model to the data. Because the predictors are calculated in this way, the usual theory of <span class="math inline">\(F\)</span>-testing does not apply. This is why the <span class="math inline">\(F\)</span>-test shown for the smoothing spline is labeled as “approximate”.</p>
<p>Find the AIC for the smoothing spline fit:</p>
<div class="sourceCode" id="cb203"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb203-1"><a href="smoothing.html#cb203-1" tabindex="-1"></a><span class="fu">AIC</span>(st16.spline)</span></code></pre></div>
<pre><code>## [1] 260.4811</code></pre>
<p>Here’s a small detail. Notice that the syntax of the call to <code>predict</code> is slightly different when making a prediction for a <code>loess</code> object vs. making a prediction for a <code>gam</code> object (which the spline fit is). For a call to <code>predict</code> with a <code>loess</code> object, the new predictor values can be provided in the form of a vector. So, we were able to use</p>
<div class="sourceCode" id="cb205"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb205-1"><a href="smoothing.html#cb205-1" tabindex="-1"></a>depth.vals <span class="ot">&lt;-</span> <span class="fu">with</span>(st16, <span class="fu">seq</span>(<span class="at">from   =</span> <span class="fu">min</span>(depth), </span>
<span id="cb205-2"><a href="smoothing.html#cb205-2" tabindex="-1"></a>                             <span class="at">to     =</span> <span class="fu">max</span>(depth), </span>
<span id="cb205-3"><a href="smoothing.html#cb205-3" tabindex="-1"></a>                             <span class="at">length =</span> <span class="dv">100</span>))</span>
<span id="cb205-4"><a href="smoothing.html#cb205-4" tabindex="-1"></a></span>
<span id="cb205-5"><a href="smoothing.html#cb205-5" tabindex="-1"></a>st16.fit <span class="ot">&lt;-</span> <span class="fu">predict</span>(<span class="at">object  =</span> st16.lo,</span>
<span id="cb205-6"><a href="smoothing.html#cb205-6" tabindex="-1"></a>                    <span class="at">newdata =</span> depth.vals,</span>
<span id="cb205-7"><a href="smoothing.html#cb205-7" tabindex="-1"></a>                    <span class="at">se      =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p>However, for a call to <code>predict</code> with a <code>gam</code> object, the new predictor values must be provided in the form of a new data frame, with variable names that match the variables in the <code>gam</code> model. So, to get predicted values for the spline fit, we needed to use the more cumbersome</p>
<div class="sourceCode" id="cb206"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb206-1"><a href="smoothing.html#cb206-1" tabindex="-1"></a>depth.vals <span class="ot">&lt;-</span> <span class="fu">with</span>(st16, <span class="fu">seq</span>(<span class="at">from   =</span> <span class="fu">min</span>(depth), </span>
<span id="cb206-2"><a href="smoothing.html#cb206-2" tabindex="-1"></a>                             <span class="at">to     =</span> <span class="fu">max</span>(depth), </span>
<span id="cb206-3"><a href="smoothing.html#cb206-3" tabindex="-1"></a>                             <span class="at">length =</span> <span class="dv">100</span>))</span>
<span id="cb206-4"><a href="smoothing.html#cb206-4" tabindex="-1"></a></span>
<span id="cb206-5"><a href="smoothing.html#cb206-5" tabindex="-1"></a>st16.fit <span class="ot">&lt;-</span> <span class="fu">predict</span>(st16.spline, </span>
<span id="cb206-6"><a href="smoothing.html#cb206-6" tabindex="-1"></a>                    <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">depth =</span> depth.vals), </span>
<span id="cb206-7"><a href="smoothing.html#cb206-7" tabindex="-1"></a>                    <span class="at">se      =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
</div>
<div id="generalized-additive-models-gams" class="section level2 hasAnchor" number="5.4">
<h2><span class="header-section-number">5.4</span> Generalized additive models (GAMs)<a href="smoothing.html#generalized-additive-models-gams" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Generalized additive models replace the usual linear terms that appear in multiple regression models with splines. That is, suppose we seek to model the relationship between a response <span class="math inline">\(y\)</span> and two predictors, <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>. A standard regression model without polynomial effects or interactions would be written as
<span class="math display">\[
y = \beta_0 + \beta_1 x_1 +\beta_2 x_2 + \varepsilon
\]</span>
where <span class="math inline">\(\varepsilon\)</span> is assumed to be an iid Gaussian random variate with variance <span class="math inline">\(\sigma^2_\varepsilon\)</span>. This is an additive model, in the sense that the combined effects of the two predictors equal the sum of their individual effects.</p>
<p>A generalized additive model (GAM) replaces the individual regression terms with splines. Continuing with the generic example, a GAM would instead model the effects of the two predictors as
<span class="math display">\[
y = \beta_0 + s(x_1) +s(x_2) + \varepsilon
\]</span>
where <span class="math inline">\(s(\cdot)\)</span> represents a spline. We continue to assume that, conditional on the covariate effects, the responses are normally distributed with constant variance <span class="math inline">\(\sigma^2_\varepsilon\)</span>.</p>
<p>We will illustrate additive modeling using the bird data found in Appendix A of <span class="citation">Zuur et al. (<a href="#ref-zuur2009mixed">2009</a>)</span>. Zuur et al. report that these data originally appeared in Loyn (1987) and were featured in Quinn &amp; Keough (2002)’s text. Zuur et al. describe these data in the following way:</p>
<blockquote>
<p>Forest bird densities were measured in 56 forest patches in south-eastern Victoria, Australia. The aim of the study was to relate bird densities to six habitat variables; size of the forest patch, distance to the nearest patch, distance to the nearest larger patch, mean altitude of the patch, year of isolation by clearing, and an index of stock grazing history (1 = light, 5 = intensive).</p>
</blockquote>
<p>We first read the data and perform some light exploratory analysis and housekeeping.</p>
<div class="sourceCode" id="cb207"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb207-1"><a href="smoothing.html#cb207-1" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>())</span>
<span id="cb207-2"><a href="smoothing.html#cb207-2" tabindex="-1"></a><span class="fu">require</span>(mgcv)</span>
<span id="cb207-3"><a href="smoothing.html#cb207-3" tabindex="-1"></a></span>
<span id="cb207-4"><a href="smoothing.html#cb207-4" tabindex="-1"></a>bird <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="st">&quot;data/Loyn.txt&quot;</span>, <span class="at">head =</span> T)</span>
<span id="cb207-5"><a href="smoothing.html#cb207-5" tabindex="-1"></a></span>
<span id="cb207-6"><a href="smoothing.html#cb207-6" tabindex="-1"></a><span class="fu">summary</span>(bird)</span></code></pre></div>
<pre><code>##       Site           ABUND            AREA              DIST       
##  Min.   : 1.00   Min.   : 1.50   Min.   :   0.10   Min.   :  26.0  
##  1st Qu.:14.75   1st Qu.:12.40   1st Qu.:   2.00   1st Qu.:  93.0  
##  Median :28.50   Median :21.05   Median :   7.50   Median : 234.0  
##  Mean   :28.50   Mean   :19.51   Mean   :  69.27   Mean   : 240.4  
##  3rd Qu.:42.25   3rd Qu.:28.30   3rd Qu.:  29.75   3rd Qu.: 333.2  
##  Max.   :56.00   Max.   :39.60   Max.   :1771.00   Max.   :1427.0  
##      LDIST           YR.ISOL         GRAZE            ALT       
##  Min.   :  26.0   Min.   :1890   Min.   :1.000   Min.   : 60.0  
##  1st Qu.: 158.2   1st Qu.:1928   1st Qu.:2.000   1st Qu.:120.0  
##  Median : 338.5   Median :1962   Median :3.000   Median :140.0  
##  Mean   : 733.3   Mean   :1950   Mean   :2.982   Mean   :146.2  
##  3rd Qu.: 913.8   3rd Qu.:1966   3rd Qu.:4.000   3rd Qu.:182.5  
##  Max.   :4426.0   Max.   :1976   Max.   :5.000   Max.   :260.0</code></pre>
<div class="sourceCode" id="cb209"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb209-1"><a href="smoothing.html#cb209-1" tabindex="-1"></a><span class="co"># get rid of the &#39;Site&#39; variable; it is redundant with the row label</span></span>
<span id="cb209-2"><a href="smoothing.html#cb209-2" tabindex="-1"></a></span>
<span id="cb209-3"><a href="smoothing.html#cb209-3" tabindex="-1"></a>bird <span class="ot">&lt;-</span> bird[, <span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb209-4"><a href="smoothing.html#cb209-4" tabindex="-1"></a></span>
<span id="cb209-5"><a href="smoothing.html#cb209-5" tabindex="-1"></a><span class="co"># log-transform area, distance, ldistance, to remove right-skew</span></span>
<span id="cb209-6"><a href="smoothing.html#cb209-6" tabindex="-1"></a></span>
<span id="cb209-7"><a href="smoothing.html#cb209-7" tabindex="-1"></a>bird<span class="sc">$</span>L.AREA <span class="ot">&lt;-</span> <span class="fu">log</span>(bird<span class="sc">$</span>AREA)</span>
<span id="cb209-8"><a href="smoothing.html#cb209-8" tabindex="-1"></a>bird<span class="sc">$</span>L.DIST <span class="ot">&lt;-</span> <span class="fu">log</span>(bird<span class="sc">$</span>DIST)</span>
<span id="cb209-9"><a href="smoothing.html#cb209-9" tabindex="-1"></a>bird<span class="sc">$</span>L.LDIST <span class="ot">&lt;-</span> <span class="fu">log</span>(bird<span class="sc">$</span>LDIST)</span>
<span id="cb209-10"><a href="smoothing.html#cb209-10" tabindex="-1"></a></span>
<span id="cb209-11"><a href="smoothing.html#cb209-11" tabindex="-1"></a><span class="co"># change YR.ISOL to years since isolation (study was published in 1987)</span></span>
<span id="cb209-12"><a href="smoothing.html#cb209-12" tabindex="-1"></a></span>
<span id="cb209-13"><a href="smoothing.html#cb209-13" tabindex="-1"></a>bird<span class="sc">$</span>YR.ISOL <span class="ot">&lt;-</span> <span class="dv">1987</span> <span class="sc">-</span> bird<span class="sc">$</span>YR.ISOL</span>
<span id="cb209-14"><a href="smoothing.html#cb209-14" tabindex="-1"></a></span>
<span id="cb209-15"><a href="smoothing.html#cb209-15" tabindex="-1"></a><span class="co"># keep the only the variables we want</span></span>
<span id="cb209-16"><a href="smoothing.html#cb209-16" tabindex="-1"></a></span>
<span id="cb209-17"><a href="smoothing.html#cb209-17" tabindex="-1"></a>bird <span class="ot">&lt;-</span> bird[, <span class="fu">c</span>(<span class="st">&quot;ABUND&quot;</span>, <span class="st">&quot;L.AREA&quot;</span>, <span class="st">&quot;L.DIST&quot;</span>, <span class="st">&quot;L.LDIST&quot;</span>, <span class="st">&quot;YR.ISOL&quot;</span>, <span class="st">&quot;ALT&quot;</span>, <span class="st">&quot;GRAZE&quot;</span>)]</span>
<span id="cb209-18"><a href="smoothing.html#cb209-18" tabindex="-1"></a><span class="fu">summary</span>(bird)</span></code></pre></div>
<pre><code>##      ABUND           L.AREA            L.DIST         L.LDIST     
##  Min.   : 1.50   Min.   :-2.3026   Min.   :3.258   Min.   :3.258  
##  1st Qu.:12.40   1st Qu.: 0.6931   1st Qu.:4.533   1st Qu.:5.064  
##  Median :21.05   Median : 2.0127   Median :5.455   Median :5.824  
##  Mean   :19.51   Mean   : 2.1459   Mean   :5.102   Mean   :5.859  
##  3rd Qu.:28.30   3rd Qu.: 3.3919   3rd Qu.:5.809   3rd Qu.:6.816  
##  Max.   :39.60   Max.   : 7.4793   Max.   :7.263   Max.   :8.395  
##     YR.ISOL           ALT            GRAZE      
##  Min.   :11.00   Min.   : 60.0   Min.   :1.000  
##  1st Qu.:21.00   1st Qu.:120.0   1st Qu.:2.000  
##  Median :24.50   Median :140.0   Median :3.000  
##  Mean   :37.25   Mean   :146.2   Mean   :2.982  
##  3rd Qu.:59.50   3rd Qu.:182.5   3rd Qu.:4.000  
##  Max.   :97.00   Max.   :260.0   Max.   :5.000</code></pre>
<p>Our first attempt at a GAM will entertain smoothing splines for all of the continuous predictors in the model. We will use a linear term for GRAZE because there are too few unique values to support a smooth term:</p>
<div class="sourceCode" id="cb211"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb211-1"><a href="smoothing.html#cb211-1" tabindex="-1"></a>bird.gam1 <span class="ot">&lt;-</span> mgcv<span class="sc">::</span><span class="fu">gam</span>(ABUND <span class="sc">~</span> <span class="fu">s</span>(L.AREA) <span class="sc">+</span> <span class="fu">s</span>(L.DIST) <span class="sc">+</span> <span class="fu">s</span>(L.LDIST) <span class="sc">+</span> <span class="fu">s</span>(YR.ISOL) <span class="sc">+</span> GRAZE <span class="sc">+</span> <span class="fu">s</span>(ALT), <span class="at">data =</span> bird)</span>
<span id="cb211-2"><a href="smoothing.html#cb211-2" tabindex="-1"></a></span>
<span id="cb211-3"><a href="smoothing.html#cb211-3" tabindex="-1"></a><span class="fu">summary</span>(bird.gam1)</span></code></pre></div>
<pre><code>## 
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## ABUND ~ s(L.AREA) + s(L.DIST) + s(L.LDIST) + s(YR.ISOL) + GRAZE + 
##     s(ALT)
## 
## Parametric coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  25.4443     2.7798   9.153 9.42e-12 ***
## GRAZE        -1.9885     0.8968  -2.217   0.0318 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Approximate significance of smooth terms:
##              edf Ref.df      F  p-value    
## s(L.AREA)  2.446  3.089 12.635 3.98e-06 ***
## s(L.DIST)  3.693  4.559  0.855    0.461    
## s(L.LDIST) 1.000  1.000  0.386    0.538    
## s(YR.ISOL) 1.814  2.238  1.231    0.262    
## s(ALT)     1.000  1.000  0.629    0.432    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## R-sq.(adj) =   0.72   Deviance explained = 77.6%
## GCV = 40.987  Scale est. = 32.238    n = 56</code></pre>
<p>The output reports the partial regression coefficient for the lone quantitative predictor GRAZE, and approximate significance tests for the smooth terms for each of the other predictors. We can visualize these smooth terms with a call to <code>plot</code>:</p>
<div class="sourceCode" id="cb213"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb213-1"><a href="smoothing.html#cb213-1" tabindex="-1"></a><span class="fu">plot</span>(bird.gam1)</span></code></pre></div>
<p><img src="05-Smoothing_files/figure-html/unnamed-chunk-20-1.png" width="480" style="display: block; margin: auto;" /><img src="05-Smoothing_files/figure-html/unnamed-chunk-20-2.png" width="480" style="display: block; margin: auto;" /><img src="05-Smoothing_files/figure-html/unnamed-chunk-20-3.png" width="480" style="display: block; margin: auto;" /><img src="05-Smoothing_files/figure-html/unnamed-chunk-20-4.png" width="480" style="display: block; margin: auto;" /><img src="05-Smoothing_files/figure-html/unnamed-chunk-20-5.png" width="480" style="display: block; margin: auto;" /></p>
<p>In the interest of time, we take a casual approach to variable selection here. We’ll drop smooth terms that are clearly not significant to obtain:</p>
<div class="sourceCode" id="cb214"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb214-1"><a href="smoothing.html#cb214-1" tabindex="-1"></a>bird.gam2 <span class="ot">&lt;-</span> mgcv<span class="sc">::</span><span class="fu">gam</span>(ABUND <span class="sc">~</span> <span class="fu">s</span>(L.AREA) <span class="sc">+</span> GRAZE, <span class="at">data =</span> bird)</span>
<span id="cb214-2"><a href="smoothing.html#cb214-2" tabindex="-1"></a><span class="fu">summary</span>(bird.gam2)</span></code></pre></div>
<pre><code>## 
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## ABUND ~ s(L.AREA) + GRAZE
## 
## Parametric coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   28.400      2.201  12.903  &lt; 2e-16 ***
## GRAZE         -2.980      0.686  -4.344 6.56e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Approximate significance of smooth terms:
##             edf Ref.df     F p-value    
## s(L.AREA) 2.284  2.903 13.18 3.4e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## R-sq.(adj) =   0.68   Deviance explained = 69.9%
## GCV = 39.992  Scale est. = 36.932    n = 56</code></pre>
<div class="sourceCode" id="cb216"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb216-1"><a href="smoothing.html#cb216-1" tabindex="-1"></a><span class="fu">plot</span>(bird.gam2)</span></code></pre></div>
<p><img src="05-Smoothing_files/figure-html/unnamed-chunk-21-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Note that the GRAZE variable is currently treated as a numerical predictor. We’ll try fitting a model with GRAZE as a factor. First we’ll create a new variable that treats GRAZE as a factor. We’ll use the <code>summary</code> command to confirm that the new variable fGRAZE is indeed a factor.</p>
<div class="sourceCode" id="cb217"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb217-1"><a href="smoothing.html#cb217-1" tabindex="-1"></a>bird<span class="sc">$</span>fGRAZE <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(bird<span class="sc">$</span>GRAZE)</span>
<span id="cb217-2"><a href="smoothing.html#cb217-2" tabindex="-1"></a><span class="fu">summary</span>(bird)</span></code></pre></div>
<pre><code>##      ABUND           L.AREA            L.DIST         L.LDIST     
##  Min.   : 1.50   Min.   :-2.3026   Min.   :3.258   Min.   :3.258  
##  1st Qu.:12.40   1st Qu.: 0.6931   1st Qu.:4.533   1st Qu.:5.064  
##  Median :21.05   Median : 2.0127   Median :5.455   Median :5.824  
##  Mean   :19.51   Mean   : 2.1459   Mean   :5.102   Mean   :5.859  
##  3rd Qu.:28.30   3rd Qu.: 3.3919   3rd Qu.:5.809   3rd Qu.:6.816  
##  Max.   :39.60   Max.   : 7.4793   Max.   :7.263   Max.   :8.395  
##     YR.ISOL           ALT            GRAZE       fGRAZE
##  Min.   :11.00   Min.   : 60.0   Min.   :1.000   1:13  
##  1st Qu.:21.00   1st Qu.:120.0   1st Qu.:2.000   2: 8  
##  Median :24.50   Median :140.0   Median :3.000   3:15  
##  Mean   :37.25   Mean   :146.2   Mean   :2.982   4: 7  
##  3rd Qu.:59.50   3rd Qu.:182.5   3rd Qu.:4.000   5:13  
##  Max.   :97.00   Max.   :260.0   Max.   :5.000</code></pre>
<p>Now we’ll proceed to fit the model</p>
<div class="sourceCode" id="cb219"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb219-1"><a href="smoothing.html#cb219-1" tabindex="-1"></a>bird.gam3 <span class="ot">&lt;-</span> <span class="fu">gam</span>(ABUND <span class="sc">~</span> <span class="fu">s</span>(L.AREA) <span class="sc">+</span> fGRAZE, <span class="at">data =</span> bird)</span>
<span id="cb219-2"><a href="smoothing.html#cb219-2" tabindex="-1"></a><span class="fu">plot</span>(bird.gam3)</span></code></pre></div>
<p><img src="05-Smoothing_files/figure-html/unnamed-chunk-23-1.png" width="480" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb220"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb220-1"><a href="smoothing.html#cb220-1" tabindex="-1"></a><span class="fu">summary</span>(bird.gam3)</span></code></pre></div>
<pre><code>## 
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## ABUND ~ s(L.AREA) + fGRAZE
## 
## Parametric coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  22.727275   1.944080  11.691 1.11e-15 ***
## fGRAZE2       0.006623   2.845343   0.002 0.998152    
## fGRAZE3      -0.660124   2.585878  -0.255 0.799592    
## fGRAZE4      -2.170994   3.050736  -0.712 0.480122    
## fGRAZE5     -11.913966   2.872911  -4.147 0.000136 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Approximate significance of smooth terms:
##             edf Ref.df     F  p-value    
## s(L.AREA) 2.761  3.478 11.67 4.71e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## R-sq.(adj) =  0.723   Deviance explained = 75.7%
## GCV = 37.013  Scale est. = 31.883    n = 56</code></pre>
<p>To formally compare the models with GRAZE as a numerical vs. categorical predictor, we’ll have to use AIC. We can’t use an <span class="math inline">\(F\)</span>-test here because we have used smoothing splines to capture the effect of L.AREA. Thus, the models are not nested. (If we had used regression splines for L.AREA, then the models would have been nested.) We can extract the AICs for these models by a simple call to the <code>AIC</code> function.</p>
<div class="sourceCode" id="cb222"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb222-1"><a href="smoothing.html#cb222-1" tabindex="-1"></a><span class="fu">AIC</span>(bird.gam2)</span></code></pre></div>
<pre><code>## [1] 367.1413</code></pre>
<div class="sourceCode" id="cb224"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb224-1"><a href="smoothing.html#cb224-1" tabindex="-1"></a><span class="fu">AIC</span>(bird.gam3)</span></code></pre></div>
<pre><code>## [1] 361.9655</code></pre>
<!-- Compare the design matrices for these two models (only the first few rows of each matrix are shown in this transcript): -->
<!-- ```{r} -->
<!-- head(model.matrix(bird.gam3)) -->
<!-- head(model.matrix(bird.gam4)) -->
<!-- ``` -->
<p>We can see the contrasts used to incorporate the factor fGRAZE in the model by a call to <code>contrasts</code>:</p>
<div class="sourceCode" id="cb226"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb226-1"><a href="smoothing.html#cb226-1" tabindex="-1"></a><span class="fu">with</span>(bird, <span class="fu">contrasts</span>(fGRAZE))</span></code></pre></div>
<pre><code>##   2 3 4 5
## 1 0 0 0 0
## 2 1 0 0 0
## 3 0 1 0 0
## 4 0 0 1 0
## 5 0 0 0 1</code></pre>
<p>The output here is somewhat opaque because the levels of fGRAZE are 1, 2, <span class="math inline">\(\ldots\)</span>, 5. The output of the call to <code>contrasts</code> shows each of the newly created indicator variables as a column. For example, the first column shows that the predictor named <code>fGRAZE2</code> takes the value of 1 when the variable fGRAZE equals 2, and is 0 otherwise.</p>
<p>Fit an additive model with only a smooth effect of L.AREA, in order to show residuals vs. GRAZE:</p>
<div class="sourceCode" id="cb228"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb228-1"><a href="smoothing.html#cb228-1" tabindex="-1"></a>bird.gam4 <span class="ot">&lt;-</span> <span class="fu">gam</span>(ABUND <span class="sc">~</span> <span class="fu">s</span>(L.AREA), <span class="at">data =</span> bird)</span>
<span id="cb228-2"><a href="smoothing.html#cb228-2" tabindex="-1"></a></span>
<span id="cb228-3"><a href="smoothing.html#cb228-3" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> bird<span class="sc">$</span>GRAZE, <span class="at">y =</span> bird.gam4<span class="sc">$</span>residuals)</span>
<span id="cb228-4"><a href="smoothing.html#cb228-4" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="dv">0</span>, <span class="at">lty =</span> <span class="st">&quot;dashed&quot;</span>)</span></code></pre></div>
<p><img src="05-Smoothing_files/figure-html/unnamed-chunk-26-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Both the plot and the model output suggest that the effect of grazing is primarily due to lower bird abundance in the most heavily grazed category.</p>
<p>To conclude, we’ll conduct a formal test of whether the model with GRAZE as a factor provides a significantly better fit than the model with a linear effect of GRAZE. In this case, we have to use regression splines for the smooth effect of L.AREA. We’ll use regression “splines” without any internal knots, (which are actually not splines at all, just a cubic trend) because the effect of log area seems to be reasonably well captured by a cubic trend anyway:</p>
<div class="sourceCode" id="cb229"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb229-1"><a href="smoothing.html#cb229-1" tabindex="-1"></a>bird.gam5 <span class="ot">&lt;-</span> <span class="fu">gam</span>(ABUND <span class="sc">~</span> <span class="fu">s</span>(L.AREA, <span class="at">k =</span> <span class="dv">4</span>, <span class="at">fx =</span> <span class="cn">TRUE</span>) <span class="sc">+</span> GRAZE, <span class="at">data =</span> bird)</span>
<span id="cb229-2"><a href="smoothing.html#cb229-2" tabindex="-1"></a>bird.gam6 <span class="ot">&lt;-</span> <span class="fu">gam</span>(ABUND <span class="sc">~</span> <span class="fu">s</span>(L.AREA, <span class="at">k =</span> <span class="dv">4</span>, <span class="at">fx =</span> <span class="cn">TRUE</span>) <span class="sc">+</span> fGRAZE, <span class="at">data =</span> bird)</span>
<span id="cb229-3"><a href="smoothing.html#cb229-3" tabindex="-1"></a></span>
<span id="cb229-4"><a href="smoothing.html#cb229-4" tabindex="-1"></a><span class="fu">anova</span>(bird.gam5, bird.gam6, <span class="at">test =</span> <span class="st">&quot;F&quot;</span>)  </span></code></pre></div>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: ABUND ~ s(L.AREA, k = 4, fx = TRUE) + GRAZE
## Model 2: ABUND ~ s(L.AREA, k = 4, fx = TRUE) + fGRAZE
##   Resid. Df Resid. Dev Df Deviance      F  Pr(&gt;F)  
## 1        51     1869.0                             
## 2        48     1543.1  3   325.93 3.3796 0.02565 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Both AIC and the <span class="math inline">\(F\)</span>-test suggest that the model with GRAZE as a factor provides a significantly better fit than the model with a linear effect of GRAZE (<span class="math inline">\(F_{3,48} = 3.38, p = 0.026\)</span>).</p>
<p>As a final note, Zuur et al. (p.550) observe that “the non-linear L.AREA effect is mainly due to two large patches. It would be useful to sample more of this type of patch in the future.” (Note the rug plots in any of the plots of the area effect above.)</p>

</div>
</div>



<h3>Bibliography<a href="bibliography.html#bibliography" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-gillibrand2007deep" class="csl-entry">
Gillibrand, EJV, P Bagley, A Jamieson, PJ Herring, JC Partridge, MA Collins, R Milne, and Imants George Priede. 2007. <span>“Deep Sea Benthic Bioluminescence at Artificial Food Falls, 1,000–4,800 m Depth, in the Porcupine Seabight and Abyssal Plain, North East Atlantic Ocean.”</span> <em>Marine Biology</em> 150 (6): 1053–60.
</div>
<div id="ref-zuur2009mixed" class="csl-entry">
Zuur, Alain F, Elena N Ieno, Neil J Walker, Anatoly A Saveliev, Graham M Smith, et al. 2009. <em>Mixed Effects Models and Extensions in Ecology with <span>R</span></em>. New York: Springer.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="generalized-linear-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="one-factor-anova.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "serif",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "section"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
