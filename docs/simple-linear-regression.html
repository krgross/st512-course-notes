<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 1 Simple linear regression | ST 512 course notes</title>
  <meta name="description" content="Course notes for ST 512, Statistical Methods for Researchers II." />
  <meta name="generator" content="bookdown 0.40 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 1 Simple linear regression | ST 512 course notes" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Course notes for ST 512, Statistical Methods for Researchers II." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 Simple linear regression | ST 512 course notes" />
  
  <meta name="twitter:description" content="Course notes for ST 512, Statistical Methods for Researchers II." />
  

<meta name="author" content="Kevin Gross" />


<meta name="date" content="2024-09-18" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="multiple-regression.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#philosophy"><i class="fa fa-check"></i>Philosophy</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#scope-and-coverage"><i class="fa fa-check"></i>Scope and coverage</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#mathematical-level"><i class="fa fa-check"></i>Mathematical level</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#computing"><i class="fa fa-check"></i>Computing</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#format-of-the-notes"><i class="fa fa-check"></i>Format of the notes</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgments-and-license"><i class="fa fa-check"></i>Acknowledgments and license</a></li>
</ul></li>
<li class="part"><span><b>Part I: Regression modeling</b></span></li>
<li class="chapter" data-level="1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>1</b> Simple linear regression</a>
<ul>
<li class="chapter" data-level="1.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#the-basics-of-slr"><i class="fa fa-check"></i><b>1.1</b> The basics of SLR</a></li>
<li class="chapter" data-level="1.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#least-squares-estimation"><i class="fa fa-check"></i><b>1.2</b> Least-squares estimation</a></li>
<li class="chapter" data-level="1.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#inference-for-the-slope"><i class="fa fa-check"></i><b>1.3</b> Inference for the slope</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#standard-errors"><i class="fa fa-check"></i><b>1.3.1</b> Standard errors</a></li>
<li class="chapter" data-level="1.3.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#confidence-intervals"><i class="fa fa-check"></i><b>1.3.2</b> Confidence intervals</a></li>
<li class="chapter" data-level="1.3.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#statistical-hypothesis-tests"><i class="fa fa-check"></i><b>1.3.3</b> Statistical hypothesis tests</a></li>
<li class="chapter" data-level="1.3.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#inference-for-the-intercept"><i class="fa fa-check"></i><b>1.3.4</b> Inference for the intercept</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#sums-of-squares-decomposition-and-r2"><i class="fa fa-check"></i><b>1.4</b> Sums of squares decomposition and <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="1.5" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#diagnostic-plots"><i class="fa fa-check"></i><b>1.5</b> Diagnostic plots</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#residuals-vs.-fitted-values"><i class="fa fa-check"></i><b>1.5.1</b> Residuals vs. fitted values</a></li>
<li class="chapter" data-level="1.5.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#residuals-vs.-predictors"><i class="fa fa-check"></i><b>1.5.2</b> Residuals vs. predictor(s)</a></li>
<li class="chapter" data-level="1.5.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#residuals-vs.-other-variables"><i class="fa fa-check"></i><b>1.5.3</b> Residuals vs. other variables</a></li>
<li class="chapter" data-level="1.5.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#normal-probability-plot"><i class="fa fa-check"></i><b>1.5.4</b> Normal probability plot</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#consequences-of-violating-model-assumptions-and-possible-fixes"><i class="fa fa-check"></i><b>1.6</b> Consequences of violating model assumptions, and possible fixes</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#linearity"><i class="fa fa-check"></i><b>1.6.1</b> Linearity</a></li>
<li class="chapter" data-level="1.6.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#independence"><i class="fa fa-check"></i><b>1.6.2</b> Independence</a></li>
<li class="chapter" data-level="1.6.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#constant-variance"><i class="fa fa-check"></i><b>1.6.3</b> Constant variance</a></li>
<li class="chapter" data-level="1.6.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#normality"><i class="fa fa-check"></i><b>1.6.4</b> Normality</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#prediction-with-regression-models"><i class="fa fa-check"></i><b>1.7</b> Prediction with regression models</a></li>
<li class="chapter" data-level="1.8" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#regression-design"><i class="fa fa-check"></i><b>1.8</b> Regression design</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#choice-of-predictor-values"><i class="fa fa-check"></i><b>1.8.1</b> Choice of predictor values</a></li>
<li class="chapter" data-level="1.8.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#powerSLR"><i class="fa fa-check"></i><b>1.8.2</b> Power</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#centering-the-predictor"><i class="fa fa-check"></i><b>1.9</b> <span class="math inline">\(^\star\)</span>Centering the predictor</a></li>
<li class="chapter" data-level="" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#appendix-a-fitting-the-slr-model-in-r"><i class="fa fa-check"></i>Appendix A: Fitting the SLR model in R</a></li>
<li class="chapter" data-level="" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#appendix-b-regression-models-in-sas-proc-reg"><i class="fa fa-check"></i>Appendix B: Regression models in SAS PROC REG</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="multiple-regression.html"><a href="multiple-regression.html"><i class="fa fa-check"></i><b>2</b> Multiple regression</a>
<ul>
<li class="chapter" data-level="2.1" data-path="multiple-regression.html"><a href="multiple-regression.html#multiple-regression-basics"><i class="fa fa-check"></i><b>2.1</b> Multiple regression basics</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="multiple-regression.html"><a href="multiple-regression.html#the-multiple-regression-model"><i class="fa fa-check"></i><b>2.1.1</b> The multiple regression model</a></li>
<li class="chapter" data-level="2.1.2" data-path="multiple-regression.html"><a href="multiple-regression.html#interpreting-partial-regression-coefficients."><i class="fa fa-check"></i><b>2.1.2</b> Interpreting partial regression coefficients.</a></li>
<li class="chapter" data-level="2.1.3" data-path="multiple-regression.html"><a href="multiple-regression.html#visualizing-a-multiple-regression-model"><i class="fa fa-check"></i><b>2.1.3</b> Visualizing a multiple regression model</a></li>
<li class="chapter" data-level="2.1.4" data-path="multiple-regression.html"><a href="multiple-regression.html#statistical-inference-for-partial-regression-coefficients"><i class="fa fa-check"></i><b>2.1.4</b> Statistical inference for partial regression coefficients</a></li>
<li class="chapter" data-level="2.1.5" data-path="multiple-regression.html"><a href="multiple-regression.html#prediction"><i class="fa fa-check"></i><b>2.1.5</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="multiple-regression.html"><a href="multiple-regression.html#F-test"><i class="fa fa-check"></i><b>2.2</b> <span class="math inline">\(F\)</span>-tests for several regression coefficients</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="multiple-regression.html"><a href="multiple-regression.html#basic-machinery"><i class="fa fa-check"></i><b>2.2.1</b> Basic machinery</a></li>
<li class="chapter" data-level="2.2.2" data-path="multiple-regression.html"><a href="multiple-regression.html#model-utility-test-model-utility-test"><i class="fa fa-check"></i><b>2.2.2</b> Model utility test {#model utility test}</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="multiple-regression.html"><a href="multiple-regression.html#categorical-predictors"><i class="fa fa-check"></i><b>2.3</b> Categorical predictors</a></li>
<li class="chapter" data-level="2.4" data-path="multiple-regression.html"><a href="multiple-regression.html#regression-interactions"><i class="fa fa-check"></i><b>2.4</b> Interactions between predictors</a></li>
<li class="chapter" data-level="2.5" data-path="multiple-regression.html"><a href="multiple-regression.html#collinearity"><i class="fa fa-check"></i><b>2.5</b> (Multi-)Collinearity</a></li>
<li class="chapter" data-level="2.6" data-path="multiple-regression.html"><a href="multiple-regression.html#variable-selection-choosing-the-best-model"><i class="fa fa-check"></i><b>2.6</b> Variable selection: Choosing the best model</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="multiple-regression.html"><a href="multiple-regression.html#model-selection-and-inference"><i class="fa fa-check"></i><b>2.6.1</b> Model selection and inference</a></li>
<li class="chapter" data-level="2.6.2" data-path="multiple-regression.html"><a href="multiple-regression.html#ranking-methods"><i class="fa fa-check"></i><b>2.6.2</b> Ranking methods</a></li>
<li class="chapter" data-level="2.6.3" data-path="multiple-regression.html"><a href="multiple-regression.html#cross-validation"><i class="fa fa-check"></i><b>2.6.3</b> Cross-validation</a></li>
<li class="chapter" data-level="2.6.4" data-path="multiple-regression.html"><a href="multiple-regression.html#sequential-methods"><i class="fa fa-check"></i><b>2.6.4</b> Sequential methods</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="multiple-regression.html"><a href="multiple-regression.html#leverage-influential-points-and-standardized-residuals"><i class="fa fa-check"></i><b>2.7</b> Leverage, influential points, and standardized residuals</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="multiple-regression.html"><a href="multiple-regression.html#leverage"><i class="fa fa-check"></i><b>2.7.1</b> Leverage</a></li>
<li class="chapter" data-level="2.7.2" data-path="multiple-regression.html"><a href="multiple-regression.html#standardized-residuals"><i class="fa fa-check"></i><b>2.7.2</b> Standardized residuals</a></li>
<li class="chapter" data-level="2.7.3" data-path="multiple-regression.html"><a href="multiple-regression.html#cooks-distance"><i class="fa fa-check"></i><b>2.7.3</b> Cook’s distance</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="multiple-regression.html"><a href="multiple-regression.html#appendix-regression-as-a-linear-algebra-problem"><i class="fa fa-check"></i>Appendix: Regression as a linear algebra problem</a>
<ul>
<li class="chapter" data-level="" data-path="multiple-regression.html"><a href="multiple-regression.html#singular-or-pathological-design-matrices"><i class="fa fa-check"></i>Singular, or pathological, design matrices</a></li>
<li class="chapter" data-level="" data-path="multiple-regression.html"><a href="multiple-regression.html#additional-results"><i class="fa fa-check"></i>Additional results</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="non-linear-regression-models.html"><a href="non-linear-regression-models.html"><i class="fa fa-check"></i><b>3</b> Non-linear regression models</a>
<ul>
<li class="chapter" data-level="3.1" data-path="non-linear-regression-models.html"><a href="non-linear-regression-models.html#polynomial-regression"><i class="fa fa-check"></i><b>3.1</b> Polynomial regression</a></li>
<li class="chapter" data-level="3.2" data-path="non-linear-regression-models.html"><a href="non-linear-regression-models.html#nls"><i class="fa fa-check"></i><b>3.2</b> Non-linear least squares</a></li>
<li class="chapter" data-level="3.3" data-path="non-linear-regression-models.html"><a href="non-linear-regression-models.html#starsmoothing-methods"><i class="fa fa-check"></i><b>3.3</b> <em><span class="math inline">\(^\star\)</span>Smoothing methods</em></a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="non-linear-regression-models.html"><a href="non-linear-regression-models.html#loess-smoothers"><i class="fa fa-check"></i><b>3.3.1</b> Loess smoothers</a></li>
<li class="chapter" data-level="3.3.2" data-path="non-linear-regression-models.html"><a href="non-linear-regression-models.html#splines"><i class="fa fa-check"></i><b>3.3.2</b> Splines</a></li>
<li class="chapter" data-level="3.3.3" data-path="non-linear-regression-models.html"><a href="non-linear-regression-models.html#generalized-additive-models-gams"><i class="fa fa-check"></i><b>3.3.3</b> Generalized additive models (GAMs)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>4</b> Generalized linear models</a>
<ul>
<li class="chapter" data-level="4.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#poisson-regression"><i class="fa fa-check"></i><b>4.1</b> Poisson regression</a></li>
<li class="chapter" data-level="4.2" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#binary-responses"><i class="fa fa-check"></i><b>4.2</b> Binary responses</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#individual-binary-responses-tb-in-boar"><i class="fa fa-check"></i><b>4.2.1</b> Individual binary responses: TB in boar</a></li>
<li class="chapter" data-level="4.2.2" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#grouped-binary-data-industrial-melanism"><i class="fa fa-check"></i><b>4.2.2</b> Grouped binary data: Industrial melanism</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#implementation-in-sas"><i class="fa fa-check"></i><b>4.3</b> Implementation in SAS</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#complete-separation"><i class="fa fa-check"></i><b>4.3.1</b> Complete separation</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Part II: Designed experiments</b></span></li>
<li class="chapter" data-level="5" data-path="one-factor-anova.html"><a href="one-factor-anova.html"><i class="fa fa-check"></i><b>5</b> One-factor ANOVA</a>
<ul>
<li class="chapter" data-level="5.1" data-path="one-factor-anova.html"><a href="one-factor-anova.html#grouped-data-and-the-design-of-experiments-doe-an-overview"><i class="fa fa-check"></i><b>5.1</b> Grouped data and the design of experiments (DoE): an overview</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="one-factor-anova.html"><a href="one-factor-anova.html#a-vocabulary-for-describing-designed-experiments"><i class="fa fa-check"></i><b>5.1.1</b> A vocabulary for describing designed experiments</a></li>
<li class="chapter" data-level="5.1.2" data-path="one-factor-anova.html"><a href="one-factor-anova.html#roadmap"><i class="fa fa-check"></i><b>5.1.2</b> Roadmap</a></li>
<li class="chapter" data-level="5.1.3" data-path="one-factor-anova.html"><a href="one-factor-anova.html#the-simplest-experiment"><i class="fa fa-check"></i><b>5.1.3</b> The simplest experiment</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="one-factor-anova.html"><a href="one-factor-anova.html#one-factor-anova-the-basics"><i class="fa fa-check"></i><b>5.2</b> One-factor ANOVA: The basics</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="one-factor-anova.html"><a href="one-factor-anova.html#connections-between-one-factor-anova-and-other-statistical-procedures"><i class="fa fa-check"></i><b>5.2.1</b> Connections between one-factor ANOVA and other statistical procedures</a></li>
<li class="chapter" data-level="5.2.2" data-path="one-factor-anova.html"><a href="one-factor-anova.html#assumptions-in-anova"><i class="fa fa-check"></i><b>5.2.2</b> Assumptions in ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="one-factor-anova.html"><a href="one-factor-anova.html#linear-contrasts-of-group-means"><i class="fa fa-check"></i><b>5.3</b> Linear contrasts of group means</a></li>
<li class="chapter" data-level="5.4" data-path="one-factor-anova.html"><a href="one-factor-anova.html#using-sas-the-effects-parameterization-of-the-one-factor-anova"><i class="fa fa-check"></i><b>5.4</b> Using SAS: The effects parameterization of the one-factor ANOVA</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="one-factor-anova.html"><a href="one-factor-anova.html#effects-model-parameterization-of-the-one-factor-anova-model"><i class="fa fa-check"></i><b>5.4.1</b> Effects-model parameterization of the one-factor ANOVA model</a></li>
<li class="chapter" data-level="5.4.2" data-path="one-factor-anova.html"><a href="one-factor-anova.html#sas-implementation-of-the-one-factor-anova-model-in-proc-glm"><i class="fa fa-check"></i><b>5.4.2</b> SAS implementation of the one-factor ANOVA model in PROC GLM</a></li>
<li class="chapter" data-level="5.4.3" data-path="one-factor-anova.html"><a href="one-factor-anova.html#using-the-estimate-and-contrast-statements-for-linear-contrasts-in-proc-glm"><i class="fa fa-check"></i><b>5.4.3</b> Using the ESTIMATE and CONTRAST statements for linear contrasts in PROC GLM</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="one-factor-anova.html"><a href="one-factor-anova.html#linear-contrasts-revisited-testing-multiple-simultaneous-contrasts"><i class="fa fa-check"></i><b>5.5</b> Linear contrasts revisited: Testing multiple simultaneous contrasts</a></li>
<li class="chapter" data-level="5.6" data-path="one-factor-anova.html"><a href="one-factor-anova.html#multiple-comparisons"><i class="fa fa-check"></i><b>5.6</b> Multiple comparisons</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="one-factor-anova.html"><a href="one-factor-anova.html#multiple-testing-in-general"><i class="fa fa-check"></i><b>5.6.1</b> Multiple testing in general</a></li>
<li class="chapter" data-level="5.6.2" data-path="one-factor-anova.html"><a href="one-factor-anova.html#bonferroni-and-bonferroni-like-procedures"><i class="fa fa-check"></i><b>5.6.2</b> Bonferroni and Bonferroni-like procedures</a></li>
<li class="chapter" data-level="5.6.3" data-path="one-factor-anova.html"><a href="one-factor-anova.html#multiple-comparisons-in-anova"><i class="fa fa-check"></i><b>5.6.3</b> Multiple comparisons in ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="one-factor-anova.html"><a href="one-factor-anova.html#general-strategy-for-analyzing-data-from-a-crd-with-a-one-factor-treatment-structure"><i class="fa fa-check"></i><b>5.7</b> General strategy for analyzing data from a CRD with a one-factor treatment structure</a></li>
<li class="chapter" data-level="5.8" data-path="one-factor-anova.html"><a href="one-factor-anova.html#starpower-and-sample-size-determination-in-anova"><i class="fa fa-check"></i><b>5.8</b> <span class="math inline">\(^\star\)</span>Power and sample-size determination in ANOVA</a></li>
<li class="chapter" data-level="5.9" data-path="one-factor-anova.html"><a href="one-factor-anova.html#starorthogonal-contrasts"><i class="fa fa-check"></i><b>5.9</b> <span class="math inline">\(^\star\)</span>Orthogonal contrasts</a></li>
<li class="chapter" data-level="5.10" data-path="one-factor-anova.html"><a href="one-factor-anova.html#starpolynomial-trends"><i class="fa fa-check"></i><b>5.10</b> <span class="math inline">\(^\star\)</span>Polynomial trends</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="factorial-experiments.html"><a href="factorial-experiments.html"><i class="fa fa-check"></i><b>6</b> Factorial experiments</a>
<ul>
<li class="chapter" data-level="6.1" data-path="factorial-experiments.html"><a href="factorial-experiments.html#crossed-vs.-nested-designs"><i class="fa fa-check"></i><b>6.1</b> Crossed vs. nested designs</a></li>
<li class="chapter" data-level="6.2" data-path="factorial-experiments.html"><a href="factorial-experiments.html#simple-effects-main-effects-and-interaction-effects"><i class="fa fa-check"></i><b>6.2</b> Simple effects, main effects, and interaction effects</a></li>
<li class="chapter" data-level="6.3" data-path="factorial-experiments.html"><a href="factorial-experiments.html#analysis-of-a-balanced-2-times-2-factorial-experiment"><i class="fa fa-check"></i><b>6.3</b> Analysis of a balanced 2 <span class="math inline">\(\times\)</span> 2 factorial experiment</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="factorial-experiments.html"><a href="factorial-experiments.html#example-weight-gain-in-rats"><i class="fa fa-check"></i><b>6.3.1</b> Example: Weight gain in rats</a></li>
<li class="chapter" data-level="6.3.2" data-path="factorial-experiments.html"><a href="factorial-experiments.html#analysis-using-proc-glm-in-sas"><i class="fa fa-check"></i><b>6.3.2</b> Analysis using PROC GLM in SAS</a></li>
<li class="chapter" data-level="6.3.3" data-path="factorial-experiments.html"><a href="factorial-experiments.html#effects-notation-for-the-two-factor-anova"><i class="fa fa-check"></i><b>6.3.3</b> Effects notation for the two-factor ANOVA</a></li>
<li class="chapter" data-level="6.3.4" data-path="factorial-experiments.html"><a href="factorial-experiments.html#a-second-example"><i class="fa fa-check"></i><b>6.3.4</b> A second example</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="factorial-experiments.html"><a href="factorial-experiments.html#a-times-b-factorial-designs"><i class="fa fa-check"></i><b>6.4</b> <span class="math inline">\(a \times b\)</span> factorial designs</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="factorial-experiments.html"><a href="factorial-experiments.html#example-without-a-significant-interaction"><i class="fa fa-check"></i><b>6.4.1</b> Example without a significant interaction</a></li>
<li class="chapter" data-level="6.4.2" data-path="factorial-experiments.html"><a href="factorial-experiments.html#example-with-a-significant-interaction"><i class="fa fa-check"></i><b>6.4.2</b> Example with a significant interaction</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="factorial-experiments.html"><a href="factorial-experiments.html#unreplicated-factorial-designs"><i class="fa fa-check"></i><b>6.5</b> Unreplicated factorial designs</a></li>
<li class="chapter" data-level="6.6" data-path="factorial-experiments.html"><a href="factorial-experiments.html#missing-cells"><i class="fa fa-check"></i><b>6.6</b> Missing cells</a></li>
<li class="chapter" data-level="6.7" data-path="factorial-experiments.html"><a href="factorial-experiments.html#more-than-two-factors"><i class="fa fa-check"></i><b>6.7</b> More than two factors</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ancova.html"><a href="ancova.html"><i class="fa fa-check"></i><b>7</b> ANCOVA</a></li>
<li class="chapter" data-level="8" data-path="random-effects.html"><a href="random-effects.html"><i class="fa fa-check"></i><b>8</b> Random effects</a>
<ul>
<li class="chapter" data-level="8.1" data-path="random-effects.html"><a href="random-effects.html#fixed-vs.-random-effects-the-big-picture"><i class="fa fa-check"></i><b>8.1</b> Fixed vs. random effects: the big picture</a></li>
<li class="chapter" data-level="8.2" data-path="random-effects.html"><a href="random-effects.html#random-effects-models"><i class="fa fa-check"></i><b>8.2</b> Random-effects models</a></li>
<li class="chapter" data-level="8.3" data-path="random-effects.html"><a href="random-effects.html#subsampling"><i class="fa fa-check"></i><b>8.3</b> Subsampling</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="random-effects.html"><a href="random-effects.html#equal-subsamples-per-eu"><i class="fa fa-check"></i><b>8.3.1</b> Equal subsamples per EU</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="random-effects.html"><a href="random-effects.html#starmathematical-foundations"><i class="fa fa-check"></i><b>8.4</b> <span class="math inline">\(^\star\)</span>Mathematical foundations</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="random-effects.html"><a href="random-effects.html#probability-refresher"><i class="fa fa-check"></i><b>8.4.1</b> Probability refresher</a></li>
<li class="chapter" data-level="8.4.2" data-path="random-effects.html"><a href="random-effects.html#application-to-models-with-random-effects"><i class="fa fa-check"></i><b>8.4.2</b> Application to models with random effects</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="blocked-designs.html"><a href="blocked-designs.html"><i class="fa fa-check"></i><b>9</b> Blocked designs</a>
<ul>
<li class="chapter" data-level="9.1" data-path="blocked-designs.html"><a href="blocked-designs.html#randomized-complete-block-designs"><i class="fa fa-check"></i><b>9.1</b> Randomized complete block designs</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="blocked-designs.html"><a href="blocked-designs.html#should-a-blocking-factor-be-a-fixed-or-random-effect"><i class="fa fa-check"></i><b>9.1.1</b> *Should a blocking factor be a fixed or random effect?</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="blocked-designs.html"><a href="blocked-designs.html#latin-squares-designs"><i class="fa fa-check"></i><b>9.2</b> Latin-squares designs</a></li>
<li class="chapter" data-level="9.3" data-path="blocked-designs.html"><a href="blocked-designs.html#split-plot-designs"><i class="fa fa-check"></i><b>9.3</b> Split-plot designs</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="blocked-designs.html"><a href="blocked-designs.html#denominator-degrees-of-freedom-in-split-plot-designs-and-the-satterthwaite-approximation"><i class="fa fa-check"></i><b>9.3.1</b> Denominator degrees of freedom in split-plot designs and the Satterthwaite approximation</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="blocked-designs.html"><a href="blocked-designs.html#repeated-measures"><i class="fa fa-check"></i><b>9.4</b> Repeated measures</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i>Bibliography</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">ST 512 course notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="simple-linear-regression" class="section level1 hasAnchor" number="1">
<h1><span class="header-section-number">Chapter 1</span> Simple linear regression<a href="simple-linear-regression.html#simple-linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>In statistics, regression models relate the distribution of an output variable to the value(s) of one or several input variables. Characterizing the relationships among input and output variables is central to much of science, and regression methods form the foundation for much of data analysis. We’ll have a lot to say about regression, but we’ll begin with so-called simple linear regression (SLR). SLR models are “simple” in the sense that they contain only one predictor.</p>
<p>Because these notes are meant for the intermediate analyst, I’ll assume that you’ve seen SLR before. The purpose of our study here is twofold. First, we’ll use SLR as a familiar venue to review many of the foundational concepts of (frequentist) statistical inference. These ideas are often elusive, so it’s worth reviewing them again to solidify our understanding. Along the way, we’ll encounter some new (!) ideas for interpreting the outcomes of statistical hypothesis test that may improve upon the traditional convoluted definitions.</p>
<p>Second, we’ll also introduce some more advanced regression ideas. These ideas will carry over into our study of regression models with several predictors, so it is helpful to study them here in a less complicated setting.</p>
<hr />
<p><span style="color: gray;"> For such a fundamental technique, the name “regression” seems a bit odd. Why do we give this most central of tasks such an obscure moniker? The name traces back to Francis Galton’s late 19th century study of the relationship between the heights of individuals and their parents’ heights (<span class="citation">Galton (<a href="#ref-galton1886regression">1886</a>)</span>). Galton observed that while the children of taller-than-average or shorter-than-average parents also tend to be taller than average or shorter than average, respectively, the children’s heights tend to be closer to the average height than those of their parents. Galton termed this phenomenon “regression to mediocrity”; today, we don’t like to equate average-ness with mediocrity, so we now refer to the phenomenon as “regression to the mean”. In any case, to characterize this relationship statistically, Galton wrote down equations that were the precursors of the statistical model that we now know as regression. So, the statistical model of regression was first used to describe the empirical phenomenon of regression to the mean, even though statistical regression models are now used in a much broader variety of contexts.</span></p>
<p><span style="color: gray;"> All that said, regression to the mean doesn’t just apply to people’s heights; instead, it appears in all sorts of everyday contexts. For example, it helps explains why students who do particularly well on a first exam tend not to do quite so well on a subsequent exam, or why repeating as a league champion is so rare in sports. For more coverage, see e.g. Ch. 17 of <span class="citation">Kahneman (<a href="#ref-kahneman2011thinking">2011</a>)</span>.</span></p>
<hr />
<div id="the-basics-of-slr" class="section level2 hasAnchor" number="1.1">
<h2><span class="header-section-number">1.1</span> The basics of SLR<a href="simple-linear-regression.html#the-basics-of-slr" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Simple linear regression characterizes the relationship between two variables: a predictor variable and a response variable. We will begin with a simple example for context.</p>
<em>Example</em>: Individuals in this study consumed a certain number of beers, and their blood alcohol content (BAC) was measured. Data were obtained for <span class="math inline">\(n=16\)</span> individuals.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a> Here is a scatter plot of the data:
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-2"></span>
<img src="index_files/figure-html/unnamed-chunk-2-1.png" alt="BAC vs. beers consumed." width="384" />
<p class="caption">
Figure 1.1: BAC vs. beers consumed.
</p>
</div>
<p>To begin, let’s observe that the two variables that a regression model associates are not on equal footing. One variable is designated as the “predictor” and the other variable is designated as the “response”. The predictor variable is denoted by the symbol <span class="math inline">\(x\)</span>, and the response variable is denoted by <span class="math inline">\(y\)</span>. In plotting, we almost always show the predictor on the horizontal axis and the response on the vertical axis.<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a> The predictor is also called the “independent” variable because, in a designed experiment, its values are determined by the investigator. The response is also called the “dependent” variable because its distribution depends on the value of the predictor variable, in a way that is determined by nature. For the BAC data, we will identify the number of beers consumed as the predictor and BAC as the response.</p>
<p>The regression model associates each value of the predictor variable with a distribution for the response variable. Indeed, the fact that the output of the model is a distribution is what makes this a statistical model, as opposed to some other flavor of mathematical model. A <em>simple linear regression</em> (SLR) is a simple statistical model in which the association between the value of the predictor and the distribution of the response takes a specific form. In particular, in a SLR, the distribution of the response variable is Gaussian (or normal) with a mean that depends linearly on the value of the predictor and a variance that is independent of the value of the predictor. When we plot the fit of a regression model, we typically only plot the regression line. However, the line merely shows how the average of the distribution of the response depends on the predictor. The model has more structure than a plot of the regression line suggests.</p>
<p>In terms of an equation, we can write the model using the regression equation
<span class="math display" id="eq:slr">\[\begin{equation}
y_i =\beta_0 +\beta_1 x_i +\varepsilon_i \tag{1.1}.
\end{equation}\]</span>
In words, we might re-write the equation as
<span class="math display">\[
\mbox{response = intercept + slope} \times \mbox{predictor + error}.
\]</span>
In the mathematical equation above, the <em>i</em> subscript distinguishes individual data points. For example, <span class="math inline">\(y_1\)</span> is the value of the response associated with the first observation in the data set. Usually, we use the notation <span class="math inline">\(n\)</span> for the total number of data points, and so to be precise we might also write <span class="math inline">\(i = 1, \ldots, n\)</span>. In words, we say that “<span class="math inline">\(i\)</span> varies from 1 to <span class="math inline">\(n\)</span>” or “<span class="math inline">\(i\)</span> ranges from 1 to <span class="math inline">\(n\)</span>”. We’ll suppress the <span class="math inline">\(i\)</span> subscript when we don’t need it.</p>
<p>In the SLR model, the equation <span class="math inline">\(\beta_0 + \beta_1 x\)</span> shows how the average of the response depends on the predictor value. The parameter <span class="math inline">\(\beta_0\)</span> is called the intercept, and it gives the value of the regression line when the predictor <span class="math inline">\(x = 0\)</span>. As we will see, the value of the regression line at <span class="math inline">\(x=0\)</span> often isn’t a scientifically meaningful quantity, even though we need to know the value to specify the model fully. The parameter <span class="math inline">\(\beta_1\)</span> is the slope. In SLR, the slope is a parameter tells us by how much regression line rises or falls as the predictor changes. Positive values of the slope indicate that the regression line increases as the predictor increases, and negative values of the slope indicate that the regression line decreases as the predictor increases.</p>
<p>The regression line alone is not sufficient to fully specify the entire regression model. To the regression line we add a normally distributed error, denoted by <span class="math inline">\(\varepsilon\)</span>. The error term is a catch-all that subsumes all the other factors that might influence the response that are not included in the predictors. In the context of the BAC example, these might include body weight, metabolism, and/or alcohol content of the beer (if it differed among subjects).</p>
<p>Although they look similar, it is important to realize that <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, and <span class="math inline">\(\varepsilon\)</span> are different beasts. The quantities <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are parameters. Recall that in statistics, <em>parameters</em> are quantities that characterize a population. We assume that true values of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> exist; those values are just unknown to us. We will estimate these parameters and draw inferences about their values on the basis of data.</p>
<p>In contrast, the error term <span class="math inline">\(\varepsilon\)</span> is a random variable. It does not have one single value, but instead takes a different value for every member of a population. We describe the distribution of the errors across the members of the population using a probability distribution. In simple linear regression, we assume that the random errors have a Gaussian (or normal, or bell-shaped) distribution with mean 0 and variance <span class="math inline">\(\sigma_{\varepsilon}^{2}\)</span>. We also assume that the random errors are independent among individuals in our sample. A succinct way of stating this is to state that the errors are Gaussian and “independent and identically distributed” (abbreviated “iid”). In notation, we write <span class="math inline">\(\varepsilon_{i} \stackrel{\text{iid}}{\sim} \mathcal{N}\left(0, \sigma_{\varepsilon }^2 \right)\)</span>, a statement which we would read as “the errors have a normal (or Gaussian) distribution with mean 0 and variance <span class="math inline">\(\sigma^2_\varepsilon\)</span>”. The error variance <span class="math inline">\(\sigma_{\varepsilon }^2\)</span> is a parameter, and it measure of the variability in the response that is not explained by the predictor. We will also discuss how to estimate <span class="math inline">\(\sigma_{\varepsilon }^2\)</span>. (It is also possible to draw statistical inferences for <span class="math inline">\(\sigma_{\varepsilon }^2\)</span>, although we will not discuss how to do so in these notes.)</p>
<p>Before moving on to discussing how to estimate the model parameters, let’s reflect a bit on the slope, <span class="math inline">\(\beta_1\)</span>, because this is the parameter that captures the linear association between the two variables. A particularly nice way to interpret the slope is due to <span class="citation">Gelman, Hill, and Vehtari (<a href="#ref-gelman2020regression">2020</a>)</span>. Their interpretation works like this. Consider two values of the response <span class="math inline">\(y_1\)</span> and <span class="math inline">\(y_2\)</span>, associated respectively with two values of the predictor <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>. The regression model says that, on average, the difference <span class="math inline">\(y_1 - y_2\)</span> will equal <span class="math inline">\(\beta_1 \times (x_1 - x_2)\)</span>. The “on average” part of this interpretation is important because we realize that any two actual observations will also include their respective errors, and so we don’t expect these two observations to differ by exactly <span class="math inline">\(\beta_1 \times (x_1 - x_2)\)</span>. Second, this interpretation also makes it clear that the regression model predicts that the average difference between two responses will increase or decrease linearly as the difference between their two associated predictor values grows or shrinks. Thus, if the SLR model is appropriate for the BAC data (something we have yet to verify), then the model suggests that the average BAC difference between two individuals who have consumed 1 vs. 2 beers is the same as the average BAC difference between two individuals who have consumed 4 vs. 5 beers, and that both of these differences are one-half as big as the average BAC difference between two individuals who have drank 2.5 vs. 4.5 beers.</p>
<hr />
<p><span style="color: gray;"> Our assumption of normally distributed errors has a deeper justification than may meet the eye. If you’ve studied probability, you may have encountered an important result called the Central Limit Theorem. For our purposes, the Central Limit Theorem tells us that if the error results from the combined effect of many small factors added together, then the error’s distribution will be approximately normal. (We will see that regression models are not sensitive to moderate departures from normality, so approximately normal errors are good enough.) This result provides a strong justification for expecting normally distributed errors in many cases. The normality assumption begins to break down when the errors are dominated by only a few factors, or when the factors that contribute to the error combine multiplicitavely. This latter scenario — errors that result from the product of many small influences as opposed to their sum — frequently arises in biology when the response measures some form of population size. Populations grow or shrink multiplicitavely, and so population sizes tend to have right-skewed distributions. </span></p>
<p><span style="color: gray;">It’s also worth noting that we can write the regression model as the sum of the regression line (<span class="math inline">\(\beta_0 + \beta_1 x\)</span>) and an error term with mean zero (<span class="math inline">\(\varepsilon\)</span>) because we have assumed that the errors have a normal distribution. A normal distribution has the special property that we can take a normally distributed quantity, add a constant to it, and the sum will still have a normal distribution. Most statistical distributions do not have this property; for example, a Poisson random variate plus a non-zero constant does not yield a Poisson distributed sum. Some authors find it more natural to write the SLR model as <span class="math inline">\(y \sim \mathcal{N}(\beta_0 + \beta_1 x, \sigma^2)\)</span>, to emphasize that the response has a Gaussian distribution and that the predictor only affects the mean of this distribution. We will use the style of eq. <a href="simple-linear-regression.html#eq:slr">(1.1)</a>, because this style lends itself more readily to mixed-effects models with multiple variance terms. However, the two styles of notation denote the same model. Feel free to use whichever style makes the most sense to you.</span></p>
<hr />
</div>
<div id="least-squares-estimation" class="section level2 hasAnchor" number="1.2">
<h2><span class="header-section-number">1.2</span> Least-squares estimation<a href="simple-linear-regression.html#least-squares-estimation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The parameters of an SLR model are estimated by the method of least-squares. That is, we find the values of the parameters that minimize the sum of the squared differences between the data points themselves and the line. The estimates are denoted by “hats”, i.e., <span class="math inline">\(\hat{\beta}_0\)</span> is the estimate of <span class="math inline">\(\beta_0\)</span>. Other authors use <span class="math inline">\(b\)</span>’s instead of <span class="math inline">\(\hat{\beta}\)</span>’s for parameter estimates in regression. Both types of notation commonly appear in the scientific literature.</p>
<p>If we were inventing SLR from scratch, we might imagine many possible criteria that we could use to determine the parameter values that provide the best fit of the SLR model. For example, we might contemplate fitting the line that minimized the average absolute difference between the data points and the line. The reason why we favor the least-squares criterion is a direct consequence of the assumption that the errors take a Gaussian distribution.<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a></p>
<p>In an introductory statistics course, you may have derived formulas for calculating the least-squares estimates <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span> by hand. Here, we will rely on software for the necessary computations, although one might note that one could derive the formulas for <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span> by using basic calculus tools to minimize the error sum-of squares. Using R, we obtain the least-squares fit of the regression model to the BAC data below.<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a></p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="simple-linear-regression.html#cb2-1" tabindex="-1"></a>fm1 <span class="ot">&lt;-</span> <span class="fu">with</span>(beer, <span class="fu">lm</span>(BAC <span class="sc">~</span> Beers))</span>
<span id="cb2-2"><a href="simple-linear-regression.html#cb2-2" tabindex="-1"></a><span class="fu">summary</span>(fm1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = BAC ~ Beers)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.027118 -0.017350  0.001773  0.008623  0.041027 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -0.012701   0.012638  -1.005    0.332    
## Beers        0.017964   0.002402   7.480 2.97e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.02044 on 14 degrees of freedom
## Multiple R-squared:  0.7998, Adjusted R-squared:  0.7855 
## F-statistic: 55.94 on 1 and 14 DF,  p-value: 2.969e-06</code></pre>
<p>The least-squares estimates of the intercept and slope for the BAC data are <span class="math inline">\(\hat{\beta}_0 = -0.013\)</span> and <span class="math inline">\(\hat{\beta}_1 = 0.018\)</span>, respectively. Here’s a picture of the scatter-plot with the least-squares line:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="simple-linear-regression.html#cb4-1" tabindex="-1"></a><span class="fu">with</span>(beer, <span class="fu">plot</span>(BAC <span class="sc">~</span> Beers, <span class="at">xlab =</span> <span class="st">&quot;beers consumed&quot;</span>))</span>
<span id="cb4-2"><a href="simple-linear-regression.html#cb4-2" tabindex="-1"></a><span class="fu">abline</span>(fm1)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-4"></span>
<img src="index_files/figure-html/unnamed-chunk-4-1.png" alt="SLR fit of BAC vs. beers consumed." width="384" />
<p class="caption">
Figure 1.2: SLR fit of BAC vs. beers consumed.
</p>
</div>
<p>The best fitting line shows a positive relationship between BAC and beers consumed. Using the interpretation that we introduced in the previous section, we would say that if we measure the BAC of two people, one of whom has consumed one more beer than the other, on average the BAC of the person who drank more beers will be 0.018 higher than the BAC of the persion who drank fewer beers. Similarly, if we compare the BAC of two people, one of whom drank four more beers than the other, on average the BAC of the person who drank more beers will be <span class="math inline">\(0.4 \times 0.018 = 0.072\)</span> higher than the person who drank fewer beers, and so on.</p>
<p>In a perfect world, we would always include units along with our parameter estimates. In the BAC data, the units of the predictor are perfectly clear (the units are the number of beers), but the units of the response are a bit trickier. The units of BAC are percent by volume, which is often just shortened to percent. So, in the BAC regression model, the units of the intercept are <span class="math inline">\(\hat{\beta}_0 = -0.013\%\)</span>, and the units of the slope are <span class="math inline">\(\hat{\beta}_1 = 0.018\)</span> percent per beer consumed. Quoting units can get a bit repetitive, so we’ll omit them on occasion, but identifying the units of parameters in your own analysis is a good way to deepen your understanding of what the numbers in the analysis mean.</p>
<p>Evaluating the fitted regression line for a given value of the predictor generates a <em>fitted value</em> for each data point. Fitted values are denoted <span class="math inline">\(\hat{y}_i\)</span>. In notation, <span class="math inline">\(\hat{y}_i = \hat{\beta}_0 + \hat{\beta}_1 x_i\)</span>. (What are the units of fitted values? And why did the error term vanish in the equation for <span class="math inline">\(\hat{y}_i\)</span>?)</p>
<p>The <em>residual</em> for observation <span class="math inline">\(i\)</span>, denoted <span class="math inline">\(e_i\)</span>, is the difference between the actual observation and the fitted value. In notation, we write <span class="math inline">\(e_i = y_i -\hat{y}_i\)</span>. (What are the units of residuals?) In terms of the data plot, the residuals can be thought of as the vertical differences between the actual data points and the fitted line. In the figure below, the vertical line represents the residual for the individual who consumed 9 beers.</p>
<p><img src="index_files/figure-html/unnamed-chunk-5-1.png" width="384" style="display: block; margin: auto;" /></p>
<p><em>Example</em>: The first individual in the data set drank <span class="math inline">\(x_1 = 5\)</span> beers and had a BAC of <span class="math inline">\(y_1 = 0.1\%\)</span>. Find the fitted value and residual for this data point. Answer: <span class="math inline">\(\hat{y}_1 = 0.077\%\)</span>, <span class="math inline">\(e_1 = 0.023\%\)</span>.</p>
<p>The <em>error sum of squares</em> (SSE) is the sum of the squared residuals. Written as a formula, we would write
<span class="math display">\[
SSE = \sum_{i=1}^{n} e_i^{2} = \sum_{i=1}^{n} \left(y_{i} - \hat{y}_i \right)^{2}.
\]</span>
The SSE is a measure of the unexplained variability in the response. The least squares estimates, <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span>, are called the least squares estimates because they minimize the SSE.</p>
<p>We can use the SSE to find an estimate of the error variance parameter by using the formula
<span class="math display">\[
s_\varepsilon^2 = \dfrac{SSE}{n-2} = MSE
\]</span>
We divide by <span class="math inline">\(n - 2\)</span> because there are <span class="math inline">\(n - 2\)</span> degrees of freedom (df) associated with the SSE. When we divide an error sum-of-squares by its degrees of freedom, the resulting quotient is called the “mean-squared error” (MSE). For the BAC data, the SSE is 0.0058, yielding a MSE of <span class="math inline">\(0.0058/(16-2) \approx 0.0004\)</span>. See the gray text at the end of this section for an explanation of why the number of degrees of freedom is <span class="math inline">\(n-2\)</span>.</p>
<p>Variances are difficult to understand because they are on a squared scale. Thus, the units of the error variance are the units of the response, squared. To place this estimate on a more meaningful scale, we take the square root to obtain the estimate of the residual standard deviation <span class="math inline">\(s_{\varepsilon}\)</span>:
<span class="math display">\[
s_{\varepsilon} =\sqrt{\dfrac{SSE}{n-2}} = \sqrt{MSE}
\]</span>
For the BAC data, <span class="math inline">\(s_{\varepsilon} = \sqrt{0.0004} = 0.020\)</span>. This is a more useful number, as it suggests that a typical deviation between an observed BAC and the corresponding fitted value is 0.020%. (Take a look again at the magnitude of the residuals in the scatterplot of the BAC data, and convince yourself that 0.020% is a reasonable guide to the magnitude of a typical residual.) In the R <code>summary</code> of our model fit, the value of <span class="math inline">\(s_{\varepsilon}\)</span> is given by the portion of the output labeled “Residual standard error”.<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a></p>
<hr />
<p><span style="color: gray;"> Degrees of freedom appear frequently in statistical modeling. We will spend quite a bit of effort in these notes keeping track of degrees of freedom, so it’s helpful to understand this concept well. We’ll look carefully at df in the simple case of SLR to build intuition that will carry over into more complicated models.</span></p>
<p><span style="color: gray;">Most error terms, like the SLR error variance <span class="math inline">\(\sigma_\varepsilon^2\)</span>, are estimated by sums of squares. The concept of degrees of freedom quantifies how many “free differences” are available to compute a sum of squares.</span></p>
<p><span style="color: gray;">Consider the following thought experiment. Suppose that, bizarrely, we knew the values of the parameters <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> in an SLR, and only needed to estimate the error variance <span class="math inline">\(\sigma_\varepsilon^2\)</span>. We could do so using the sum of squares <span class="math inline">\(\sum_{i=1}^{n}\left(y_{i} -\left[\beta_0 +\beta_1 x_i \right]\right)^2\)</span>. In this case, each of our <span class="math inline">\(n\)</span> data points would contribute a “free difference” to the summation above, and so there would be <span class="math inline">\(n\)</span> free differences with which we could estimate the error variance <span class="math inline">\(\sigma_\varepsilon^2\)</span>.</span></p>
<p><span style="color: gray;">However, we never know the values of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> in advance. Instead, we have to use the data to estimate both <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>. Now, because we have to estimate both <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, there are only <span class="math inline">\(n - 2\)</span> free differences in the sum of squares <span class="math inline">\(\sum_{i=1}^{n}\left(y_{i} -\left[\hat{\beta}_0 +\hat{\beta}_1 x_i \right]\right)^{2}\)</span>. One way to visualize this is to imagine fitting a line to a data set with only <span class="math inline">\(n = 2\)</span> data points (with different <span class="math inline">\(x\)</span> values). The line would be guaranteed to pass through both points, and consequently both residuals would equal 0. Because both residuals equal 0, the SSE would also equal 0. However, the SSE doesn’t equal 0 because the actual value of <span class="math inline">\(\sigma_\varepsilon^2\)</span> equals 0. Instead, the SSE equals 0 because there is no information remaining to estimate the residual variance.</span></p>
<p><span style="color: gray;">In general, when we have to use the same data set to estimate the parameters that determine the average value of the response and to estimate the residual variance, then each parameter that we have to estimate in the mean component of the model eliminates a free difference from the sum of squares <span class="math inline">\(\sum_{i=1}^{n}\left(y_{i} -\hat{y}_{i} \right)^{2}\)</span>. To convert the sum of squares into an estimate of an error variance, we need to count the number of free differences (or degrees of freedom) correctly, and divide the sum of squares by the appropriate number of df to make sure we get a good estimate of the variance. </span></p>
<hr />
</div>
<div id="inference-for-the-slope" class="section level2 hasAnchor" number="1.3">
<h2><span class="header-section-number">1.3</span> Inference for the slope<a href="simple-linear-regression.html#inference-for-the-slope" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>To draw statistical inferences about the slope parameter <span class="math inline">\(\beta_1\)</span>, we make the following assumptions:</p>
<ol style="list-style-type: decimal">
<li><p>Linearity: The average value of the response is a linear function of the predictor.</p></li>
<li><p>Equal variance (“homoscedasticity”): The variance of the error terms (the <span class="math inline">\(\varepsilon_i\)</span>’s) is the same for all observations.</p></li>
<li><p>Independence: The error terms are independent of one another.</p></li>
<li><p>Normality. The errors have a normal (i.e., bell-shaped, or Gaussian) distribution.</p></li>
</ol>
<p>Note that assumption number 1 deals with the mean component of the model, while assumptions 2–4 deal with the error component of the model.</p>
<div id="standard-errors" class="section level3 hasAnchor" number="1.3.1">
<h3><span class="header-section-number">1.3.1</span> Standard errors<a href="simple-linear-regression.html#standard-errors" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>As intelligent scientists, we realize that estimates are not exactly equal to the parameters that they seek to estimate. We can characterize the uncertainty in parameter estimates in different ways. One tool that we have for quantifying uncertainty in parameter estimates is to calculate a standard error. In general, a <em>standard error</em> quantifies the variability in an estimate that is attributable to random sampling. Most parameter estimates that we will encounter have known formulas for their standard errors. In most cases, these formulas are complicated, and we will rely on computers to calculate standard errors for us. However, the formula for the standard error of the slope parameter in SLR is interesting to examine because it contains a valuable insight that we can use when collecting data for a regression study. The standard error of <span class="math inline">\(\hat{\beta}_1\)</span>, denoted <span class="math inline">\(s_{\hat{\beta}_1}\)</span>, is given by the formula
<span class="math display" id="eq:se-slope">\[\begin{equation}
s_{\hat{\beta}_1} = \dfrac{s_{\varepsilon}}{\sqrt{S_{xx} } }
\tag{1.2}
\end{equation}\]</span>
where <span class="math inline">\(S_{xx} =\sum_{i}\left(x_{i} -\bar{x}\right)^2\)</span> quantifies the dispersion in the predictor variables.</p>
<p>Although this formula looks a bit daunting, there’s some intuition to be gained here, and a lesson for experimental design. Suppose we had designed a regression experiment in which all of the individuals were assigned similar values of the predictor. In this case, <span class="math inline">\(S_{xx}\)</span> would be small, and consequently the standard error <span class="math inline">\(s_{\hat{\beta}_1}\)</span> would be large. Conversely, if the values of the predictor were very different among individuals in the study, then <span class="math inline">\(S_{xx}\)</span> would be large and the standard error <span class="math inline">\(s_{\hat{\beta}_1}\)</span> would be small. Thus, if we want a precise estimate of the slope, we should choose predictor values that span the range over which we want to learn.</p>
<p>Thought question: Following this line of reasoning, is it a good idea to design a study so that half the individuals are assigned a very large value of the predictor, and the other half are assigned a very small value? Why or why not?</p>
<p>For the BAC example, <span class="math inline">\(s_{\hat{\beta}_1} = 0.0024\)</span>. (The units are the same units as the slope, or percent per beer consumed for the BAC data.) This tells us that, over many hypothetical repetitions of this same experiment, a typical difference between our estimate of the slope and its true value is 0.0024. This information sharpens our understanding of the precision of the estimate.<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a></p>
</div>
<div id="confidence-intervals" class="section level3 hasAnchor" number="1.3.2">
<h3><span class="header-section-number">1.3.2</span> Confidence intervals<a href="simple-linear-regression.html#confidence-intervals" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A second way in which we can measure the uncertainty in a parameter estimate is to calculate a confidence interval (CI). Recall that the general formula for a confidence interval associated with a statistic is:
<span class="math display">\[
\mathrm{estimate} \pm  \mathrm{critical\ value} \times \mathrm{standard\ error}
\]</span>
Critical values are found either by consulting a table (and re-living the good old days) or using the internet or a computer program. Critical values depend on the <em>confidence level</em> that you want to associate with the CI. Although it seems a bit backwards, we typically denote the confidence level of a CI as <span class="math inline">\(100 \times \left(1-\alpha \right)\%\)</span>. Thus, for a 95% confidence interval (a common choice), <span class="math inline">\(\alpha = 0.05\)</span>. Alternatively, we might seek a 99% CI, in which case <span class="math inline">\(\alpha = 0.01\)</span>.</p>
<p>To construct a CI for <span class="math inline">\(\beta_1\)</span> , we find the appropriate critical values from a <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n - 2\)</span> df. For a <span class="math inline">\(100\times \left(1-\alpha \right)\%\)</span> CI, the critical value is the value that “cuts-off” an upper tail of <span class="math inline">\(\alpha / 2\)</span> %. For example, to calculate a 99% CI for <span class="math inline">\(\beta_{1}\)</span>, we need to find the critical value of a <span class="math inline">\(t\)</span>-distribution with 14 df that cuts-off an upper 0.5%-tail. Using an online calculator, or another tool, we find that this critical value is 2.977. Thus, a 99% CI is 0.018 <span class="math inline">\(\pm\)</span> 2.977 <span class="math inline">\(\times\)</span> 0.0024 = (0.011, 0.025).</p>
<p>Recall that the appropriate interpretation of the confidence level a CI is fairly tricky. A proper interpretation is that, if we were to repeat this experiment a large number of times, and calculate a 99% CI for each experiment, in the long run 99% of those CIs would contain the true value of <span class="math inline">\(\beta_1\)</span>. Of course, in real life, we’ll only do the experiment once, and we don’t know if our experiment is one of the 99% in which the CI contains the true parameter value or not. It is often tempting to abbreviate this interpretation by saying that ``there is a 99% chance that <span class="math inline">\(\beta_1\)</span> is in the CI’’, although technically this interpretation is incorrect (because any single CI either contains the parameter or it doesn’t).<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a></p>
<p>Note also that there is a trade-off between the confidence level and the width of the interval. If we wanted greater confidence that our interval contained the true parameter value, we could increase the confidence level. However, increasing the confidence level increases the width of the interval, and thus provides less information about the true parameter value in some sense. If we follow this argument to its (il)logical extreme, a 100% CI for <span class="math inline">\(\beta_1\)</span> covers the entire number line. Now we are fully confident that our interval contains <span class="math inline">\(\beta_1\)</span>, but at the cost of having no information whatsoever about the actual value of <span class="math inline">\(\beta_1\)</span>.</p>
</div>
<div id="statistical-hypothesis-tests" class="section level3 hasAnchor" number="1.3.3">
<h3><span class="header-section-number">1.3.3</span> Statistical hypothesis tests<a href="simple-linear-regression.html#statistical-hypothesis-tests" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Finally, a third way to characterize the statistical uncertainty in <span class="math inline">\(\hat{\beta}_1\)</span> is to conduct a statistical hypothesis test. Recall that statistical hypotheses are statements about the values of unknown parameters, and a statistical hypothesis test is a way to measure the strength of evidence against a “null hypothesis”. In the context of SLR, we are almost always interested in testing the null hypothesis that the true value of the slope parameter is equal to zero. In notation, we write this as <span class="math inline">\(H_0: \beta_1 = 0\)</span>. Evidence against this null hypothesis is taken as evidence that the predictor is linearly related to the response.</p>
<p>Recall that in statistical hypothesis testing, we must also specify an alternative hypothesis. In SLR, we are almost always interested in testing <span class="math inline">\(H_0: \beta_1 = 0\)</span> vs. the two-sided alternative <span class="math inline">\(H_a: \beta_1 \ne 0\)</span>. We conduct a statistical hypothesis test by first calculating a test statistic. In general, formulas for test statistics take the form:
<span class="math display">\[
\mbox{test statistic} = \dfrac{\mbox{parameter estimate} - \mbox{value of parameter under }H_0} {\mbox{standard error}}
\]</span></p>
<p>Test statistics have the property that if the null hypothesis is true, then the test statistic has a known sampling distribution. In the case of testing <span class="math inline">\(H_0: \beta_1 = 0\)</span> vs. <span class="math inline">\(H_a: \beta_1 \ne 0\)</span> in SLR, if the null hypothesis is true, then the test statistic will have a <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-2\)</span> df. In notation, the test statistic is
<span class="math display">\[
t=\frac{\hat{\beta}_{1} -0}{s_{\hat{\beta }_{1} } } =\frac{\hat{\beta }_{1} }{s_{\hat{\beta }_{1} } }
\]</span>
In SLR, this test is so common that the value of the <span class="math inline">\(t\)</span>-statistic is provided automatically by most statistical software packages, including R. For the BAC data, the <span class="math inline">\(t\)</span>-statistic associated with the test of <span class="math inline">\(H_0: \beta_1 = 0\)</span> vs. <span class="math inline">\(H_a: \beta_1 \ne 0\)</span> is <span class="math inline">\(t = 7.48\)</span>.</p>
<p>Values of the test statistic by themselves are not terribly enlightening. Instead, we use the test statistic to find a <span class="math inline">\(p\)</span>-value. <span class="math inline">\(P\)</span>-values are famously difficult to interpret, and those difficulties in interpretation have impeded their proper use. In 2016, a blue-ribbon panel of experts were convened by the American Statistical Association (the leading professional organization for statisticians in the US) to take the remarkable step of issuing a policy statement regarding the use of <span class="math inline">\(p\)</span>-values. That statement (<span class="citation">Wasserstein and Lazar (<a href="#ref-wasserstein2016asa">2016</a>)</span>) defines a <span class="math inline">\(p\)</span>-value as follows:</p>
<blockquote>
<p>Informally, a <span class="math inline">\(p\)</span>-value is the probability under a specified statistical model that a statistical summary of the data (e.g., the sample mean difference between two compared groups) would be equal to or more extreme than its observed value.</p>
</blockquote>
<p>(Bear in mind that this definition is the work of two dozen of the world’s leading statisticians.)</p>
<p>In the context of the test of <span class="math inline">\(H_0: \beta_1 = 0\)</span> vs. <span class="math inline">\(H_a: \beta_1 \ne 0\)</span> in SLR, this means finding the probability that a <span class="math inline">\(t\)</span>-statistic with <span class="math inline">\(n-2\)</span> df is at least as different from zero as the value observed. For a two-sided alternative hypothesis, we say “different from zero’ because the sign (positive vs. negative) of the <span class="math inline">\(t\)</span>-statistic is irrelevant. Be careful, though: for a one-sided alternative hypothesis, the sign of the observed <span class="math inline">\(t\)</span>-statistic is critical!</p>
<p>For the BAC data, we find the area under the tail of a <span class="math inline">\(t\)</span>-distribution with 14 df that is greater than 7.48, and then (because the <span class="math inline">\(t\)</span>-distribution is symmetric) multiply by 2. That is,
<span class="math display">\[\begin{align*}
p &amp; = \mathrm{Pr}\!\left\{ t_{14} &lt; -7.48\right\} +\mathrm{Pr}\!\left\{ t_{14} &gt; 7.48\right\}  \\
  &amp; = 2 \times \mathrm{Pr}\!\left\{ t_{14} &gt;7.48  \right\} \\
  &amp; = 3\times 10^{-6}  
\end{align*}\]</span>
Thus, there is exceedingly strong evidence that BAC is related to the number of beers consumed.</p>
<hr />
<p><span style="color: gray;"> My NCSU colleague Ryan Martin suggests that we interpret the <span class="math inline">\(p\)</span>-value as the <em>plausibility</em> of the null hypothesis (<span class="citation">Martin (<a href="#ref-martin2017statistical">2017</a>)</span>). Thus, small <span class="math inline">\(p\)</span> values correspond to null hypotheses that are not plausible in light of the data, and large <span class="math inline">\(p\)</span> values (those nearer to 1) indicate that null hypothesis is plausible in light of the data. The good news here is that “plausibility” in this context has a rigorous mathematical meaning, and that meaning is more or less exactly what the everyday definition of “plausibility” suggests. The less good news is that understanding this meaning exactly requires the mathematics imprecise probability, which is beyond the scope of this and most statistics courses today. Nevertheless, it strikes me as the best available option for interpreting <span class="math inline">\(p\)</span>-values.</span></p>
<p><span style="color: gray;"> Continuing in this vein, we can plot the <span class="math inline">\(p\)</span>-value associated with the test of <span class="math inline">\(H_0: \beta_1 = \beta_{1,0}\)</span> vs. <span class="math inline">\(H_a: \beta_1 \ne \beta_{1,0}\)</span> for any parameter value <span class="math inline">\(\beta_{1,0}\)</span> that we might assume under the null. This plot shows the <span class="math inline">\(p\)</span>-value function, or, following along the lines of the interpretation above, what we might call the plausibility function. Here is a look at the plausibility function for <span class="math inline">\(\beta_1\)</span> for the BAC data:</span></p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="simple-linear-regression.html#cb5-1" tabindex="-1"></a>b1.hat <span class="ot">&lt;-</span> <span class="fl">0.017964</span></span>
<span id="cb5-2"><a href="simple-linear-regression.html#cb5-2" tabindex="-1"></a>b1.se  <span class="ot">&lt;-</span> <span class="fl">0.002402</span></span>
<span id="cb5-3"><a href="simple-linear-regression.html#cb5-3" tabindex="-1"></a></span>
<span id="cb5-4"><a href="simple-linear-regression.html#cb5-4" tabindex="-1"></a>p_val <span class="ot">&lt;-</span> <span class="cf">function</span>(b1) {</span>
<span id="cb5-5"><a href="simple-linear-regression.html#cb5-5" tabindex="-1"></a></span>
<span id="cb5-6"><a href="simple-linear-regression.html#cb5-6" tabindex="-1"></a>  t.stat <span class="ot">&lt;-</span> (b1.hat <span class="sc">-</span> b1) <span class="sc">/</span> b1.se</span>
<span id="cb5-7"><a href="simple-linear-regression.html#cb5-7" tabindex="-1"></a>  </span>
<span id="cb5-8"><a href="simple-linear-regression.html#cb5-8" tabindex="-1"></a>  <span class="fu">pt</span>(<span class="sc">-</span><span class="fu">abs</span>(t.stat), <span class="at">df =</span> <span class="dv">14</span>, <span class="at">lower.tail =</span> <span class="cn">TRUE</span>) <span class="sc">+</span></span>
<span id="cb5-9"><a href="simple-linear-regression.html#cb5-9" tabindex="-1"></a>     <span class="fu">pt</span>(<span class="fu">abs</span>(t.stat), <span class="at">df =</span> <span class="dv">14</span>, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span>
<span id="cb5-10"><a href="simple-linear-regression.html#cb5-10" tabindex="-1"></a>}</span>
<span id="cb5-11"><a href="simple-linear-regression.html#cb5-11" tabindex="-1"></a></span>
<span id="cb5-12"><a href="simple-linear-regression.html#cb5-12" tabindex="-1"></a><span class="fu">curve</span>(p_val, <span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="fl">0.03</span>, <span class="at">xlab =</span> <span class="fu">expression</span>(beta[<span class="dv">1</span>]), <span class="at">ylab =</span> <span class="st">&quot;plausibility&quot;</span>,</span>
<span id="cb5-13"><a href="simple-linear-regression.html#cb5-13" tabindex="-1"></a>      <span class="at">yaxt =</span> <span class="st">&quot;n&quot;</span>)</span>
<span id="cb5-14"><a href="simple-linear-regression.html#cb5-14" tabindex="-1"></a><span class="fu">axis</span>(<span class="dv">2</span>, <span class="at">at =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.5</span>, <span class="dv">1</span>), <span class="at">las =</span> <span class="dv">1</span>)</span>
<span id="cb5-15"><a href="simple-linear-regression.html#cb5-15" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> b1.hat, <span class="at">lty =</span> <span class="st">&quot;dotted&quot;</span>)</span>
<span id="cb5-16"><a href="simple-linear-regression.html#cb5-16" tabindex="-1"></a><span class="fu">axis</span>(<span class="dv">3</span>, <span class="at">at =</span> b1.hat, <span class="at">lab =</span> <span class="fu">expression</span>(<span class="fu">hat</span>(beta)[<span class="dv">1</span>]))</span></code></pre></div>
<p><img src="index_files/figure-html/p-value-function-1.png" width="384" style="display: block; margin: auto;" /></p>
<p><span style="color: gray;"> Another nice feature of the <span class="math inline">\(p\)</span>-value function is that we can find a <span class="math inline">\(100 \times (1 - \alpha)\%\)</span> confidence interval (or, more generally, a confidence region) by taking all those parameter values that are individually at least <span class="math inline">\(\alpha\%\)</span> plausible. So, for example, a 90% confidence interval consists of all those parameter values that are at least 10% plausible. For the BAC data, we can show this confidence interval as:</span></p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="simple-linear-regression.html#cb6-1" tabindex="-1"></a><span class="fu">curve</span>(p_val, <span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="fl">0.03</span>, <span class="at">xlab =</span> <span class="fu">expression</span>(beta[<span class="dv">1</span>]), <span class="at">ylab =</span> <span class="st">&quot;plausibility&quot;</span>,</span>
<span id="cb6-2"><a href="simple-linear-regression.html#cb6-2" tabindex="-1"></a>      <span class="at">yaxt =</span> <span class="st">&quot;n&quot;</span>)</span>
<span id="cb6-3"><a href="simple-linear-regression.html#cb6-3" tabindex="-1"></a><span class="fu">axis</span>(<span class="dv">2</span>, <span class="at">at =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.5</span>, <span class="dv">1</span>), <span class="at">las =</span> <span class="dv">1</span>)</span>
<span id="cb6-4"><a href="simple-linear-regression.html#cb6-4" tabindex="-1"></a><span class="fu">axis</span>(<span class="dv">2</span>, <span class="at">at =</span> <span class="fl">0.1</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>, <span class="at">las =</span> <span class="dv">1</span>)</span>
<span id="cb6-5"><a href="simple-linear-regression.html#cb6-5" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="fl">0.1</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>, <span class="at">lty =</span> <span class="st">&quot;dashed&quot;</span>)</span>
<span id="cb6-6"><a href="simple-linear-regression.html#cb6-6" tabindex="-1"></a>(conf.limits <span class="ot">&lt;-</span> <span class="fu">confint</span>(fm1, <span class="at">level =</span> <span class="fl">0.9</span>))</span></code></pre></div>
<pre><code>##                     5 %        95 %
## (Intercept) -0.03495916 0.009557957
## Beers        0.01373362 0.022193906</code></pre>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="simple-linear-regression.html#cb8-1" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> conf.limits[<span class="dv">2</span>, ], <span class="at">col =</span> <span class="st">&quot;red&quot;</span>, <span class="at">lty =</span> <span class="st">&quot;dotted&quot;</span>)</span></code></pre></div>
<p><img src="index_files/figure-html/p-value-ci-1.png" width="384" style="display: block; margin: auto;" /></p>
<p><span style="color: gray;"> This graph nicely illustrates the tight connection between confidence intervals and hypothesis tests. For example, a 90% confidence interval consists of all those parameter values that we would fail to reject at the 10% significance level.</span></p>
<p><span style="color: gray;">While <span class="math inline">\(p\)</span>-value curves have been around a long time, statisticians have never agreed on what to do with them. For that reason, they don’t appear commonly in statistics texts.</span></p>
<hr />
<p>The values above could be found by consulting a table, or by using statistical software such as R. Because the test of <span class="math inline">\(H_0: \beta_1 = 0\)</span> vs. <span class="math inline">\(H_a: \beta_1 \ne 0\)</span> is sufficiently common in SLR, most computer packages will do this calculation for us.</p>
<p>We’ll sweep a lot of acrimonious debate about statistical hypothesis testing under the rug and simply say that some scientists like to make a decision about whether or not to “reject” the null hypothesis. In contemporary practice, most scientists make these “reject” or “do not reject” decisions by comparing the <span class="math inline">\(p\)</span>-value to the test’s <em>significance level</em>, which is usually denoted by <span class="math inline">\(\alpha\)</span>. The significance level (or size) of a test is the frequency with which one would erroneously reject a true null hypothesis; you might also think of it as the allowable Type I (or false-positive) error rate. Consequently, tests with more exacting thresholds for statistical signficance require more evidence against the null to reject it. Most scientists conventionally make reject / do not reject decisions with a significance level of <span class="math inline">\(\alpha = .05\)</span>, but you are free to use whatever significance level you deem appropriate. If <span class="math inline">\(p \le \alpha\)</span>, we reject the null hypothesis; otherwise, we fail to reject it. (Remember that we never `accept’ the null hypothesis. We only fail to reject it.)</p>
<p>Of course, the Type I (false positive) error rate is only one side of the coin. In a perfect world, we want to balance the Type I error rate against the so-called Type II error rate, which is the probability of rejecting a false null hypothesis. More informally, we might think of the Type II error rate as the ``false negative’’ error rate, if the null hypothesis corresponds to a statement of no effect as it usually does. In practice, it is usually easiest to strike this balance by specifying the Type I error rate and letting the Type II error rate fall where it may. This is because specifying the TyPe I error rate is as easy as choosing it. Determining the Type II error rate, on the other hand, entails a more involved calculation that usually depends on quantities that we don’t even know. For more on the Type II error rate, see the subsequent discussion on <a href="simple-linear-regression.html#powerSLR">statistical power</a>.</p>
<p>Although it is rare, we can also entertain so-called ‘one-sided’ alternative hypotheses. For example, suppose that we were uninterested in the (somewhat nonsensical) possibility that the numbers of beers consumed decreased BAC, and only were interested in measuring the evidence that the numbers of beers consumed increases BAC. To do so, we might test the same null hypothesis <span class="math inline">\(H_0: \beta_1 \leq 0\)</span> vs. the one-sided alternative <span class="math inline">\(H_a: \beta_1 &gt; 0\)</span>. To conduct this test, the test statistic is still
<span class="math display">\[
t=\dfrac{\hat{\beta }_{1} -0}{s_{\hat{\beta }_{1} } } =\dfrac{0.0180}{0.0024} =7.48.
\]</span>
However, because the alternative hypothesis is one-sided, to calculate a <span class="math inline">\(p\)</span>-value, we interpret “equal to or more extreme than its observed value” as the probability of observing a test statistic greater than 7.48, i.e.,
<span class="math display">\[
p=\mathrm{Pr}\!\left\{ t_{14} &gt;7.48\right\} =1.5\times 10^{-6}
\]</span>
We would then reject <span class="math inline">\(H_0: \beta_1 \leq 0\)</span> in favor of the one-sided alternative <span class="math inline">\(H_a: \beta_1 &gt; 0\)</span> at the <span class="math inline">\(\alpha = .05\)</span> significance level.</p>
<p>Finally, although it doesn’t make much sense in terms of what we know about alcohol, we could consider testing <span class="math inline">\(H_0: \beta_1 \geq 0\)</span> vs. the one-sided alternative <span class="math inline">\(H_a: \beta_1 &lt; 0\)</span>. Again, the test statistic is the same (<span class="math inline">\(t\)</span> = 7.48), but now evidence against the null and in favor of the alternative is provided by negative values of the test statistic, so the p-value is the probability of observing a test statistic <em>less</em> than 7.48, i.e.,<br />
<span class="math display">\[
p=\mathrm{Pr}\!\left\{ t_{14} &lt; 7.48\right\} = 1 - \mathrm{Pr}\!\left\{ t_{14} &gt; 7.48\right\} \approx 0.9999.
\]</span>
Thus, there is no evidence that would allow us to reject <span class="math inline">\(H_0: \beta_1 \geq 0\)</span> in favor of the one-sided alternative <span class="math inline">\(H_a: \beta_1 &lt; 0\)</span>.</p>
<p>One final note: Although it is rarely done, there is no reason why we must restrict ourselves to testing <span class="math inline">\(H_0: \beta_1 = 0\)</span>. We could in fact test any null hypothesis. For example, suppose conventional wisdom held that each additional beer consumed increased BAC by 0.02, and we were interested in asking if these data contain evidence that the conventional wisdom is false. Then we could test <span class="math inline">\(H_0: \beta_1 = 0.02\)</span> vs. <span class="math inline">\(H_a: \beta_1 \ne 0.02\)</span>, although we have to calculate the test statistic and <span class="math inline">\(p\)</span>-value manually instead of relying on computer output:
<span class="math display">\[\begin{align*}
t &amp; = \dfrac{\hat{\beta}_1 -0.02}{s_{\hat{\beta}_1 }} \\
&amp; = \dfrac{0.0180-0.02}{0.0024} \\
&amp; =-0.83 \\ \\
p &amp; =  \mathrm{Pr}\!\left\{t_{14} &lt;-0.83\right\} +\mathrm{Pr}\!\left\{t_{14} &gt;0.83\right\} \\
&amp; = 2 \times \mathrm{Pr}\!\left\{ t_{14} &gt;0.83\right\}\\
&amp; =  0.421.
\end{align*}\]</span>
Thus, <span class="math inline">\(H_0: \beta_1 = 0.02\)</span> is reasonably plausible in light of these data.</p>
<p>Do be mindful of the distinction between a statistical hypothesis and a scientific hypothesis. The following excerpt from an article by B. Dennis and M.L. Taper (<span class="citation">Dennis and Taper (<a href="#ref-dennis1994density">1994</a>)</span>) puts it nicely:</p>
<blockquote>
<p>A statistical hypothesis is an assumption about the form of a probability model, and a statistical hypothesis test is the use of data to make a decision between two probability models. A scientific hypothesis, on the other hand, is an explanatory assertion about some aspect of nature.</p>
</blockquote>
<p>Thus, while a statistical hypothesis can often embody a scientific hypothesis, a scientific hypothesis does not always boil down to a statistical hypothesis.</p>
<hr />
<p><span style="color: gray;"> When the ideas of hypothesis testing were first being developed, there was stark disagreement about what the output of a hypothesis test should be. R.A. Fisher argued that a hypothesis test should quantify how compatible the data are with the null hypothesis, relative to the universe of alternatives contained in the alternative hypothesis. Fisher argued that the appropriate tool for this purpose was the <span class="math inline">\(p\)</span>-value. In contrast, Jerzy Neyman and Egon Pearson argued that the result of a hypothesis test should be a decision about whether or not to reject the null. Of course, the two approaches can often be combined by specifying the rejection region (the set of outcomes that would cause the analyst to “reject” the null) in terms of the <span class="math inline">\(p\)</span>-value. While Fisher, Neyman, and Pearson argued vehemently, contemporary practice typically reports both a <span class="math inline">\(p\)</span>-value and a reject / fail-to-reject decision, even if it may be difficult to articulate an entirely coherent rationale for doing so.</span></p>
<hr />
</div>
<div id="inference-for-the-intercept" class="section level3 hasAnchor" number="1.3.4">
<h3><span class="header-section-number">1.3.4</span> Inference for the intercept<a href="simple-linear-regression.html#inference-for-the-intercept" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Most statistical packages automatically provide the standard errors for the intercept, <span class="math inline">\(s_{\hat{\beta}_0}\)</span>, as well as a test of <span class="math inline">\(H_0: \beta_0 = 0\)</span> vs. <span class="math inline">\(H_a: \beta_0 \ne 0\)</span>. Sometimes this is a meaningful test, but usually it isn’t. The scientific context of the problem will determine whether or not it makes sense to pay attention to this test.</p>
<p>There is a special type of regression called ``regression through the origin’’ that is appropriate when we can assume <span class="math inline">\(\beta_0 = 0\)</span> automatically. Should we use regression through the origin for the BAC example?</p>
</div>
</div>
<div id="sums-of-squares-decomposition-and-r2" class="section level2 hasAnchor" number="1.4">
<h2><span class="header-section-number">1.4</span> Sums of squares decomposition and <span class="math inline">\(R^2\)</span><a href="simple-linear-regression.html#sums-of-squares-decomposition-and-r2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We have already seen that the SSE measures the unexplained variability in the response.<br />
<span class="math display">\[
{\rm SSE}=\sum _{i=1}^{n}e_{i}^{2} = \sum _{i=1}^{n}\left(y_{i} -\hat{y}_{i} \right)^{2}  
\]</span>
We can also define the <em>total sum of squares</em>, SS(Total):
<span class="math display">\[
{\rm SS(Total)}=\sum _{i=1}^{n}\left(y_{i} -\bar{y}\right)^{2}
\]</span>
SS(Total) is a measure of the total variability in the response. Finally, we can define the <em>regression sum of squares</em>, SS(Regression), as
<span class="math display">\[
{\rm SS(Regression)}=\sum _{i=1}^{n}\left(\hat{y}_{i} -\bar{y}\right)^{2}  
\]</span>
SS(Regression) measures the variability in the response that is explained by the regression. The regression sum of squares is also called the model sum of squares, or SS(Model).</p>
<p>By a small miracle (actually, by the Pythagorean Theorem), it happens to be true that:
<span class="math display">\[
{\rm SS(Total)=SS(Regression)+SSE}
\]</span>
The <em>coefficient of determination</em>, or <span class="math inline">\(R^2\)</span>, is the proportion of the variability in the response explained by the regression model. The formula for <span class="math inline">\(R^2\)</span> is
<span class="math display">\[
R^2 = \dfrac{{\rm SS(Regression)}}{{\rm SS(Total)}} = 1-\frac{{\rm SSE}}{{\rm SS(Total)}} .
\]</span>
<span class="math inline">\(R^2\)</span> is a nice metric because it quantifies how much of the variability in the response is explained by the predictor. Values of <span class="math inline">\(R^2\)</span> close to 1 indicate that the regression model explains much of the variability in the response, while values of <span class="math inline">\(R^2\)</span> close to 0 suggest the regression model explains little of the variability in the response. We’ll also see that <span class="math inline">\(R^2\)</span> is not limited to SLR and in fact has the same interpretation for more complicated regression models that we will examine later. For the BAC example, <span class="math inline">\(R^2\)</span> = 0.80, suggesting that variation in beers consumed explains roughly 80% of the variation in BAC.</p>
<p>Mathematically, <span class="math inline">\(R^2\)</span> can also be computed as square of the (sample) correlation coefficient between the fitted values and the response. In SLR, the fitted values and the predictor are perfectly correlated with one another, so <span class="math inline">\(R^2\)</span> is also the square of the sample correlation coefficient between the predictor and the response.</p>
</div>
<div id="diagnostic-plots" class="section level2 hasAnchor" number="1.5">
<h2><span class="header-section-number">1.5</span> Diagnostic plots<a href="simple-linear-regression.html#diagnostic-plots" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We have seen that, in order to draw statistical inferences from a simple linear regression, we need to make several assumptions. Although in everyday life assumptions can get a bad rap, assumptions in statistics are necessary and appropriate. The statistician Don Rubin puts it nicely (<span class="citation">Rubin (<a href="#ref-rubin2005causal">2005</a>)</span>):</p>
<blockquote>
<p>Nothing is wrong with making assumptions … they are the strands that link statistics to science. It is the scientific quality of the assumptions, not their existence, that is critical.</p>
</blockquote>
<p>In regression, we can use <em>diagnostic plots</em> to investigate the scientific quality of our assumptions. The main idea of diagnostic plots is that if the assumptions are appropriate, then residuals should be independent draws from a normal distribution with constant variance (what some might more colorfully describe as “white noise”). Any structure in the residuals indicates a violation of at least one assumption.</p>
<p>We list commonly used diagnostic plots below. Although some types of plots are more useful for examining some assumptions than others, there isn’t a strict correspondence between plot types and assumptions. Any plot can reveal a departure from any one of our assumptions. Examples of each for the BAC data and the R code used to generate the plots are provided as examples.</p>
<div id="residuals-vs.-fitted-values" class="section level3 hasAnchor" number="1.5.1">
<h3><span class="header-section-number">1.5.1</span> Residuals vs. fitted values<a href="simple-linear-regression.html#residuals-vs.-fitted-values" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Check for non-constant variance (trumpeting). The BAC data shown here don’t show an obvious increase or decrease in variance as the fitted values increase, although the fact that the largest residual is associated with the largest fitted value is notable. We might want to go back and check that data point out.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="simple-linear-regression.html#cb9-1" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">resid</span>(fm1) <span class="sc">~</span> <span class="fu">fitted</span>(fm1), <span class="at">xlab =</span> <span class="st">&quot;Fitted Values&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Residuals&quot;</span>)</span>
<span id="cb9-2"><a href="simple-linear-regression.html#cb9-2" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="dv">0</span>, <span class="at">lty =</span> <span class="st">&quot;dotted&quot;</span>)</span></code></pre></div>
<p><img src="index_files/figure-html/unnamed-chunk-6-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>Perhaps the most common violation of the regression assumption occurs when the variance of a response increases as the fitted values increase. The tell-tale signature of this violation is a “trumpeting” pattern in the plot of the residuals vs. the fitted values. Indeed, an increasing variance is perhaps more the rule than the exception in some sciences, especially the life sciences. To illustrate, here is a data set that we will study more closely when we study <a href="ancova.html#ancova">ANCOVA</a>. For now, it suffices to say that this is a data set in which the response is the lifespan of a fruitfly, and there are several predictors. Here is a residual plot of the ANCOVA model:</p>
<p><img src="index_files/figure-html/unnamed-chunk-7-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>Fruitflies that live longer clearly have more variable lifespans.</p>
<hr />
<p><span style="color: gray;"> Recall that the Central Limit Theorem gives us a good reason to expect normally distributed residuals when the many small influences that comprise the residual error add together. There’s a related explanation for why increasing variance is so common. When the many small influences that comprise the residual error multiply together instead of adding together, then we tend to observe more variance in the response when the fitted value is larger. Indeed, this is the usual explanation offered for why increasing variance is common in the life sciences, where many processes involve some form of multiplicative growth or decay. This explanation also helps us understand why a log transformation is usually helpful as a remedy for increasing variance, because when we take a log of the response we are converting a multiplicative process into an additive one.</span></p>
<hr />
</div>
<div id="residuals-vs.-predictors" class="section level3 hasAnchor" number="1.5.2">
<h3><span class="header-section-number">1.5.2</span> Residuals vs. predictor(s)<a href="simple-linear-regression.html#residuals-vs.-predictors" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We can use this plot to check for non-linear trends. If we see a non-linear trend, like a hump-shaped pattern, it might suggest that the true relationship between predictor and response is actually non-linear.</p>
<p>For the BAC data, you’ll note that the plot below looks exactly like the plot of residuals vs. fitted values above. This isn’t just coincidence; in fact, residuals vs. fitted values and residuals vs. predictor will always generate exactly the same patterns in SLR. (The reason is because in SLR the fitted value is just a linear function of the predictor.) We want to get in the habit of checking both types of plots, however, because when we start entertaining multiple predictor variables in multiple regression, the plots will no longer be identical.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="simple-linear-regression.html#cb10-1" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">resid</span>(fm1) <span class="sc">~</span> beer<span class="sc">$</span>Beers, <span class="at">xlab =</span> <span class="st">&quot;Beers&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Residuals&quot;</span>)</span>
<span id="cb10-2"><a href="simple-linear-regression.html#cb10-2" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="dv">0</span>, <span class="at">lty =</span> <span class="st">&quot;dotted&quot;</span>)</span></code></pre></div>
<p><img src="index_files/figure-html/unnamed-chunk-8-1.png" width="384" style="display: block; margin: auto;" /></p>
</div>
<div id="residuals-vs.-other-variables" class="section level3 hasAnchor" number="1.5.3">
<h3><span class="header-section-number">1.5.3</span> Residuals vs. other variables<a href="simple-linear-regression.html#residuals-vs.-other-variables" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Plot the residuals against variables that are not in the model, e.g., other predictors, observer, order of observation, spatial coordinates. In the BAC data, the only other variable we have (for now at least) is the order in which the observations appear in the data set. Without knowing how the data were collected or recorded, it’s impossible to say whether this variable is meaningful. However, the plot suggests a distinctive downward trend – data points that appear early in the data set are associated with positive residuals, and data points that appear later in the data set are associated with negative residuals. What do you think might have caused this trend?</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="simple-linear-regression.html#cb11-1" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">resid</span>(fm1), <span class="at">xlab =</span> <span class="st">&quot;Order&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Residuals&quot;</span>)</span>
<span id="cb11-2"><a href="simple-linear-regression.html#cb11-2" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="dv">0</span>, <span class="at">lty =</span> <span class="st">&quot;dotted&quot;</span>)</span></code></pre></div>
<p><img src="index_files/figure-html/unnamed-chunk-9-1.png" width="384" style="display: block; margin: auto;" /></p>
</div>
<div id="normal-probability-plot" class="section level3 hasAnchor" number="1.5.4">
<h3><span class="header-section-number">1.5.4</span> Normal probability plot<a href="simple-linear-regression.html#normal-probability-plot" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>An obvious way to check the normality assumption is to plot a histogram of the residuals. While this is a straightforward idea, it suffers from the fact that the shape of the histogram depends strongly on how the residuals are grouped into bins. Note how the two histograms below of the BAC residuals provide different impressions about the suitability of the normality assumption.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="simple-linear-regression.html#cb12-1" tabindex="-1"></a><span class="fu">hist</span>(<span class="fu">resid</span>(fm1), <span class="at">main =</span> <span class="st">&quot;Bin width = 0.01&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;Residuals&quot;</span>)</span></code></pre></div>
<p><img src="index_files/figure-html/unnamed-chunk-10-1.png" width="384" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="simple-linear-regression.html#cb13-1" tabindex="-1"></a><span class="fu">hist</span>(<span class="fu">resid</span>(fm1), <span class="at">main =</span> <span class="st">&quot;Bin width = 0.02&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;Residuals&quot;</span>, <span class="at">breaks =</span> <span class="dv">4</span>)</span></code></pre></div>
<p><img src="index_files/figure-html/unnamed-chunk-10-2.png" width="384" style="display: block; margin: auto;" />
An alternative to histograms is a normal probability plot of residuals, also known as a quantile-quantile, or Q-Q, plot. Q-Q plots calculate the empirical quantile of each residual and compare this to the theoretical quantile from a normal distribution. If the normality assumption is appropriate, the empirical and theoretical quantiles will change at the same rate, so they’ll fall on a line when plotted against one another. If the normality assumption is not appropriate, the plot of empirical vs. theoretical quantiles will bend.</p>
<p>As we’ll see below, the normality assumption is the critical of the assumptions in regression. Thus, unless the Q-Q plot shows big and dramatic bends, we won’t concern ourselves with small bumps and wiggles. The Q-Q plot for the BAC data below doesn’t seem terribly problematic.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="simple-linear-regression.html#cb14-1" tabindex="-1"></a><span class="fu">qqnorm</span>(<span class="fu">resid</span>(fm1))</span>
<span id="cb14-2"><a href="simple-linear-regression.html#cb14-2" tabindex="-1"></a><span class="fu">qqline</span>(<span class="fu">resid</span>(fm1))</span></code></pre></div>
<p><img src="index_files/figure-html/unnamed-chunk-11-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>Here is an example of some Q-Q plots that do show strong departures from normality.<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a>
<img src="index_files/figure-html/qqexamples-1.png" width="528" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="consequences-of-violating-model-assumptions-and-possible-fixes" class="section level2 hasAnchor" number="1.6">
<h2><span class="header-section-number">1.6</span> Consequences of violating model assumptions, and possible fixes<a href="simple-linear-regression.html#consequences-of-violating-model-assumptions-and-possible-fixes" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="linearity" class="section level3 hasAnchor" number="1.6.1">
<h3><span class="header-section-number">1.6.1</span> Linearity<a href="simple-linear-regression.html#linearity" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>When the linearity assumption is violated, the model has little worth. What’s the point of fitting a linear model to data when the relationship between predictor and response is clearly not linear?</p>
<p>The best fix is to fit a non-linear model using non-linear regression. (We will discuss non-linear regression later.) A second-best option is to transform the predictor and / or the response to make the relationship linear.</p>
</div>
<div id="independence" class="section level3 hasAnchor" number="1.6.2">
<h3><span class="header-section-number">1.6.2</span> Independence<a href="simple-linear-regression.html#independence" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Inference about regression parameters using naive standard errors is not trustworthy when errors are correlated (there is more uncertainty in the estimates than the naive standard errors suggest).</p>
<p>The most common sources of non-independence is either temporal or spatial structure in the data, or if the data are grouped in some way that has been accounted for in the analysis. Arguably, we have seen this with the BAC data, where one way to think about the downward trend of residuals vs. the order of observation is that residuals close together in time tend to be positively correlated. The best, and easiest, way to accommodate this type of dependence is to include (an)other predictor(s) in the model for time or space, or to account for a group structure. A second-best solution is to use specific methods for time-series data or spatial data, which doable, but is fairly involved, and will require considerable additional study.</p>
</div>
<div id="constant-variance" class="section level3 hasAnchor" number="1.6.3">
<h3><span class="header-section-number">1.6.3</span> Constant variance<a href="simple-linear-regression.html#constant-variance" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Like violations of the independence assumption, violations of the constant-variance assumption cause inference about regression parameters is not trustworthy. Non-constant variance causes there to be more uncertainty in the parameters estimates than the default CIs or <span class="math inline">\(t\)</span>-tests suggest.</p>
<p>There are two possible fixes for non-constant variance. If the non-constant variance arises because the response variable has a known, non-normal distribution, then one can use generalized linear models (such as logistic regression for binary data, or Poisson regression for count data). We will touch on generalized linear models briefly at the end of ST 512. Alternatively, if there is no obvious alternative distribution for the response, the usual approach is to transform the response variable to “stabilize” the variance.</p>
<p>For better or worse, there used to be a bit of a cottage industry in statistics in developing variance-stabilizing transformations. Remember that transformations come with a cost of diminished interpretability, and be wary of exotic transformations. It is not uncommon to observe data where the variance increases as the mean response increases. Good transformations for this situation are either a log transformation or a square-root transformation.<a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a> Another common non-constant variance problem arises when the response is a percentage or a proportion. In this case, the standard and appropriate transformation is the arcsin-square root transformation, i.e., if the observed response is 10%, the transformed response is <span class="math inline">\(\sin^{-1}(\sqrt{.1})=0.322\)</span>.</p>
</div>
<div id="normality" class="section level3 hasAnchor" number="1.6.4">
<h3><span class="header-section-number">1.6.4</span> Normality<a href="simple-linear-regression.html#normality" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Perhaps surprisingly, the consequences of violating the normality assumption are minimal, unless departures from normality are severe (e.g., binary data).<a href="#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a> When one encounters decidedly non-normal data, the usual remedy is to entertain a so-called generalized linear models, i.e., logistic regression for binary data; Poisson regression for count data.</p>
<p>Here’s an example of another data set with residuals that are a bit more problematic. These data give the box office take (in millions of US$) vs. a composite rating score from critics’ reviews:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="simple-linear-regression.html#cb15-1" tabindex="-1"></a>movie <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="st">&quot;data/movie.txt&quot;</span>, <span class="at">head =</span> T, <span class="at">stringsAsFactors =</span> T)</span>
<span id="cb15-2"><a href="simple-linear-regression.html#cb15-2" tabindex="-1"></a></span>
<span id="cb15-3"><a href="simple-linear-regression.html#cb15-3" tabindex="-1"></a><span class="fu">with</span>(movie, <span class="fu">plot</span>(BoxOffice <span class="sc">~</span> Score, <span class="at">xlab =</span> <span class="st">&quot;Average rating&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Box office take&quot;</span>))</span>
<span id="cb15-4"><a href="simple-linear-regression.html#cb15-4" tabindex="-1"></a>fm1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(BoxOffice <span class="sc">~</span> Score, <span class="at">data =</span> movie)</span>
<span id="cb15-5"><a href="simple-linear-regression.html#cb15-5" tabindex="-1"></a><span class="fu">abline</span>(fm1)</span></code></pre></div>
<p><img src="index_files/figure-html/unnamed-chunk-12-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>The plots of residuals vs. fitted value show clear evidence of non-constant variance. The Q-Q plot indicates right-skew. Taking a square-root transformation of the response stabilizes the variance nicely:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="simple-linear-regression.html#cb16-1" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">resid</span>(fm1) <span class="sc">~</span> <span class="fu">fitted</span>(fm1), <span class="at">xlab =</span> <span class="st">&quot;Fitted value&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Residual&quot;</span>)</span>
<span id="cb16-2"><a href="simple-linear-regression.html#cb16-2" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="dv">0</span>,<span class="at">lty =</span> <span class="st">&quot;dashed&quot;</span>)</span></code></pre></div>
<p><img src="index_files/figure-html/unnamed-chunk-13-1.png" width="384" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="simple-linear-regression.html#cb17-1" tabindex="-1"></a><span class="fu">qqnorm</span>(<span class="fu">resid</span>(fm1),<span class="at">main =</span> <span class="st">&quot;QQ plot, movie data&quot;</span>)</span>
<span id="cb17-2"><a href="simple-linear-regression.html#cb17-2" tabindex="-1"></a><span class="fu">qqline</span>(<span class="fu">resid</span>(fm1))</span></code></pre></div>
<p><img src="index_files/figure-html/unnamed-chunk-13-2.png" width="384" style="display: block; margin: auto;" /></p>
<p>Let’s try a square-root transformation of the response:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="simple-linear-regression.html#cb18-1" tabindex="-1"></a>fm2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="fu">sqrt</span>(BoxOffice) <span class="sc">~</span> Score, <span class="at">data =</span> movie)</span>
<span id="cb18-2"><a href="simple-linear-regression.html#cb18-2" tabindex="-1"></a><span class="fu">summary</span>(fm2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = sqrt(BoxOffice) ~ Score, data = movie)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.60533 -0.17889 -0.07339  0.17983  0.92065 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 0.114102   0.106000   1.076    0.284    
## Score       0.010497   0.001834   5.722 6.27e-08 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.3109 on 138 degrees of freedom
## Multiple R-squared:  0.1918, Adjusted R-squared:  0.1859 
## F-statistic: 32.74 on 1 and 138 DF,  p-value: 6.272e-08</code></pre>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="simple-linear-regression.html#cb20-1" tabindex="-1"></a><span class="fu">plot</span>(fm2)</span></code></pre></div>
<p><img src="index_files/figure-html/unnamed-chunk-14-1.png" width="384" style="display: block; margin: auto;" /><img src="index_files/figure-html/unnamed-chunk-14-2.png" width="384" style="display: block; margin: auto;" /><img src="index_files/figure-html/unnamed-chunk-14-3.png" width="384" style="display: block; margin: auto;" /><img src="index_files/figure-html/unnamed-chunk-14-4.png" width="384" style="display: block; margin: auto;" />
Another commonly used transformation for right-skewed data is the log transformation. Here are residual plots and model output for log-transformed data:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="simple-linear-regression.html#cb21-1" tabindex="-1"></a>fm3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="fu">log</span>(BoxOffice) <span class="sc">~</span> Score, <span class="at">data =</span> movie)</span>
<span id="cb21-2"><a href="simple-linear-regression.html#cb21-2" tabindex="-1"></a><span class="fu">summary</span>(fm3)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log(BoxOffice) ~ Score, data = movie)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.99268 -0.43135  0.00783  0.67263  1.81413 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -2.634451   0.323390  -8.146 2.01e-13 ***
## Score        0.029984   0.005596   5.358 3.44e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9484 on 138 degrees of freedom
## Multiple R-squared:  0.1722, Adjusted R-squared:  0.1662 
## F-statistic: 28.71 on 1 and 138 DF,  p-value: 3.438e-07</code></pre>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="simple-linear-regression.html#cb23-1" tabindex="-1"></a><span class="fu">plot</span>(fm3)</span></code></pre></div>
<p><img src="index_files/figure-html/unnamed-chunk-15-1.png" width="384" style="display: block; margin: auto;" /><img src="index_files/figure-html/unnamed-chunk-15-2.png" width="384" style="display: block; margin: auto;" /><img src="index_files/figure-html/unnamed-chunk-15-3.png" width="384" style="display: block; margin: auto;" /><img src="index_files/figure-html/unnamed-chunk-15-4.png" width="384" style="display: block; margin: auto;" /></p>
<p>Which transformation do you think is more appropriate? Do the different transformations lead to different qualitative conclusions regarding the statistical significance of the relationship between reviewer rating and box office take?</p>
<p>Here’s a second example using a data set that gives the highway fuel efficiency (in mpg) and vehicle weight of 1999 model cars:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="simple-linear-regression.html#cb24-1" tabindex="-1"></a>cars <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="st">&quot;data/cars.txt&quot;</span>, <span class="at">head =</span> T)</span>
<span id="cb24-2"><a href="simple-linear-regression.html#cb24-2" tabindex="-1"></a></span>
<span id="cb24-3"><a href="simple-linear-regression.html#cb24-3" tabindex="-1"></a><span class="fu">with</span>(cars, <span class="fu">plot</span>(mpghw <span class="sc">~</span> weight, <span class="at">xlab =</span> <span class="st">&quot;Vehicle weight (lbs)&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Highway mpg&quot;</span>))</span>
<span id="cb24-4"><a href="simple-linear-regression.html#cb24-4" tabindex="-1"></a>fm1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(mpghw <span class="sc">~</span> weight, <span class="at">data =</span> cars)</span>
<span id="cb24-5"><a href="simple-linear-regression.html#cb24-5" tabindex="-1"></a><span class="fu">abline</span>(fm1)</span></code></pre></div>
<p><img src="index_files/figure-html/unnamed-chunk-16-1.png" width="384" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="simple-linear-regression.html#cb25-1" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">resid</span>(fm1) <span class="sc">~</span> <span class="fu">fitted</span>(fm1), <span class="at">xlab =</span> <span class="st">&quot;Fitted value&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Residual&quot;</span>)</span>
<span id="cb25-2"><a href="simple-linear-regression.html#cb25-2" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="dv">0</span>,<span class="at">lty =</span> <span class="st">&quot;dashed&quot;</span>)</span></code></pre></div>
<p><img src="index_files/figure-html/unnamed-chunk-16-2.png" width="384" style="display: block; margin: auto;" /></p>
<p>The relationship between highway mpg and vehicle weight is clearly non-linear, although that is seen most clearly from the plot of residuals vs. fitted values. We will discuss modeling non-linear relationships later.</p>
<p>Here are some additional comments:</p>
<ol style="list-style-type: decimal">
<li><p>What about outliers? The famous statistician George Box was fond of saying that outliers can be the most informative points in the data set. If you have an outlier, try to figure out why that point is an outlier. Discard outliers only if a good reason exists for doing so – resist the temptation to ``scrub’’ your data. Doing so is tantamount to cheating. If you absolutely must remove an outlier, at least report the model fits both with and without the outliers included.</p></li>
<li><p>Be particularly wary of data points associated with extreme <span class="math inline">\(x\)</span>-values. These points can be unduly influential. (See discussion in the multiple-regression installment of the notes on leverage, standardized residuals, and Cook’s distance.)</p></li>
<li><p>What about transforming the <span class="math inline">\(x\)</span>-variable? Remember that there are no assumptions about the distribution of the <span class="math inline">\(x\)</span>-variable. However, transformations of the <span class="math inline">\(x\)</span>-variable can also make non-linear relationships into linear ones. Remember though that transformations tend to lessen interpretability.</p></li>
<li><p>Don’t extrapolate the regression line beyond the range of the <span class="math inline">\(x\)</span>-variable observed in the data. Remember that statistical models are only valid to the extent that data exist to support them.</p></li>
<li><p>Although it’s often overlooked, remember that the standard regression model also assumes that the predictor is measured without error. If there’s error in the predictor as well as the response, then the estimated slope will be biased towards 0. If the error in the predictor is comparable to the error in the response, then consider a regression model that allows for variability in the predictor. These models go by multiple names, but they are most often called ``major-axis regression’’.</p></li>
</ol>
<!-- {\em Example of an outlier with large influence on the regression relationship} -->
<!-- The data below are from a 1981 British government survey relating household spending on tobacco products to household spending on alcoholic beverages, both in pounds per week.  One data point is shown for each of the 11 regions of the UK.  -->
<!-- \begin{center} -->
<!--    \includegraphics*[height=2.5in]{figures/sin} -->
<!-- \end{center}  -->
<!-- Clearly, there is one data point that does not fit the pattern, and has considerably less spending on alcohol.  Inspection of the data shows that this data point corresponds to Northern Ireland, while all other data points are from the island of Great Britain.  Eliminating the data point that corresponds to Northern Ireland from the regression model gives the linear fit shown with the dashed line.   -->
</div>
</div>
<div id="prediction-with-regression-models" class="section level2 hasAnchor" number="1.7">
<h2><span class="header-section-number">1.7</span> Prediction with regression models<a href="simple-linear-regression.html#prediction-with-regression-models" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Regression models are regularly used for prediction. Consider a new value of the predictor <span class="math inline">\(x^\star\)</span>. There are two different types of predictions we could make:</p>
<ol style="list-style-type: decimal">
<li><p>What is the average response of the population at <span class="math inline">\(x^\star\)</span>?</p></li>
<li><p>What is the value of a single future observation at <span class="math inline">\(x^\star\)</span>?</p></li>
</ol>
<p>Point estimates (i.e., single best guesses) are the same for both predictions. They are found by simply plugging <span class="math inline">\(x^\star\)</span> into the fitted regression equation.</p>
<p><em>Example</em>. Suppose every grad student at NCSU drinks 2.5 beers. What do we predict the average BAC of this population to be?
<span class="math display">\[\begin{align*}
    \hat{y}^\star &amp; =  \hat{\beta }_{0} +\hat{\beta }_{1} x^\star  \\
    &amp; =  -0.013 + 0.018 \times 2.5\\
    &amp; =  0.032
\end{align*}\]</span></p>
<p>Suppose Danny drinks 2.5 beers. What do we predict Danny’s BAC to be?
<span class="math display">\[
\hat{y}^\star = 0.032
\]</span></p>
<p>However, the uncertainty in these two predictions is different. Predictions of single future observations are more uncertain than predictions of population averages (why?).</p>
<p>We quantify the uncertainty in prediction 1 with a confidence interval. We quantify the uncertainty in prediction 2 with a prediction interval. A prediction interval (PI) is just like a confidence interval in the sense that you get to choose the coverage level. i.e., a 95% prediction interval will contain a single new prediction 95% of the time, while a 99% prediction interval will contain a single new prediction 99% of the time. All else being equal, a 99% prediction interval will be wider than a 95% prediction interval.</p>
<p>Both confidence intervals and prediction intervals follow the same general prescription of
<span class="math display">\[
\mbox{estimate} \pm \mbox{critical value} \times \mbox{standard error}
\]</span>
Both also use the same point estimate, <span class="math inline">\(\hat{y}^\star\)</span>, and the same critical value (taken from a <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-2\)</span> df). However, the standard errors differ depending on whether we are predicting an average response or a single future observation. If you find formulas helpful, you might derive some insight from the formulas for these two standard errors. For an average population response, the standard error is
<span class="math display">\[
s_{\varepsilon} \sqrt{\frac{1}{n} +\frac{\left(x^\star -\bar{x}\right)^{2} }{S_{xx} } }
\]</span>
while for a single future observation, the standard error is
<span class="math display">\[
s_{\varepsilon} \sqrt{1+\frac{1}{n} +\frac{\left(x^\star -\bar{x}\right)^{2} }{S_{xx} } }
\]</span></p>
<p>Thus, the width of a CI or PI depends on the following:</p>
<ul>
<li><p>The type of interval (all else being equal, a PI is wider than a CI; note the extra ‘1’ in the formula for the standard error of a single future observation).</p></li>
<li><p>The coverage level (all else being equal, higher coverage requires a wider interval).</p></li>
<li><p>The unexplained variability in the data (all else being equal, larger MSEs yield wider intervals).</p></li>
<li><p>The distance between <span class="math inline">\(x^\star\)</span> and the average predictor value, <span class="math inline">\(\bar{x}\)</span> (all else being equal, predictions are more uncertain further away from <span class="math inline">\(\bar{x}\)</span>).</p></li>
</ul>
<p>The function <code>predict</code> can be used to calculate these intervals in R:</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="simple-linear-regression.html#cb26-1" tabindex="-1"></a>fm1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(BAC <span class="sc">~</span> Beers, <span class="at">data =</span> beer)</span>
<span id="cb26-2"><a href="simple-linear-regression.html#cb26-2" tabindex="-1"></a>new.data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">Beers =</span> <span class="fl">2.5</span>)</span>
<span id="cb26-3"><a href="simple-linear-regression.html#cb26-3" tabindex="-1"></a><span class="fu">predict</span>(fm1, <span class="at">interval =</span> <span class="st">&quot;confidence&quot;</span>, <span class="at">newdata =</span> new.data)</span></code></pre></div>
<pre><code>##         fit        lwr        upr
## 1 0.0322088 0.01602159 0.04839601</code></pre>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="simple-linear-regression.html#cb28-1" tabindex="-1"></a><span class="fu">predict</span>(fm1, <span class="at">interval =</span> <span class="st">&quot;prediction&quot;</span>, <span class="at">newdata =</span> new.data)</span></code></pre></div>
<pre><code>##         fit         lwr        upr
## 1 0.0322088 -0.01452557 0.07894317</code></pre>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="simple-linear-regression.html#cb30-1" tabindex="-1"></a><span class="fu">predict</span>(fm1, <span class="at">interval =</span> <span class="st">&quot;prediction&quot;</span>, <span class="at">newdata =</span> new.data, <span class="at">level =</span> <span class="fl">0.90</span>)</span></code></pre></div>
<pre><code>##         fit          lwr        upr
## 1 0.0322088 -0.006169709 0.07058731</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-18-1.png" width="384" style="display: block; margin: auto;" />
Regression (solid line), 95% confidence intervals (dashed lines), and 95% prediction intervals (dotted lines) for the beer data. Note that both confidence and prediction intervals widen near the edges of the range of the predictor.</p>
</div>
<div id="regression-design" class="section level2 hasAnchor" number="1.8">
<h2><span class="header-section-number">1.8</span> Regression design<a href="simple-linear-regression.html#regression-design" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="choice-of-predictor-values" class="section level3 hasAnchor" number="1.8.1">
<h3><span class="header-section-number">1.8.1</span> Choice of predictor values<a href="simple-linear-regression.html#choice-of-predictor-values" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Regression models can be used both for observational and experimental data. In some experiments, the experimenter has control over the values of the predictor included in the experiment. <span class="citation">Gotelli, Ellison, et al. (<a href="#ref-gotelli2004primer">2004</a>)</span> (pp. 167-9) give the following guidelines for a regression design with a single predictor:</p>
<ol style="list-style-type: decimal">
<li><p>Ensure that the range of values sampled for the predictor variable is large enough to capture the full range of responses by the response variable.</p></li>
<li><p>Ensure that the distribution of predictor values is approximately uniform within the sampled range.</p></li>
</ol>
<p>Once the values of the predictor to be included in the experiment have been chosen, these values should be randomly assigned to the experimental units. Note that randomization does <em>not</em> require randomly choosing the values of the predictor to be included in the experiment!</p>
</div>
<div id="powerSLR" class="section level3 hasAnchor" number="1.8.2">
<h3><span class="header-section-number">1.8.2</span> Power<a href="simple-linear-regression.html#powerSLR" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In statistical hypothesis testing, <em>power</em> refers to the probability of rejecting a false null hypothesis. It is equal to one minus the Type II (false negative) error rate. For example, if the type II error rate is 40%, then the power is <span class="math inline">\(100\% - 40\% = 60\%\)</span>. All else equal, we favor designs with more power as opposed to less.</p>
<p>Power calculations are typically used to provide a rough sense of the appropriate sample size for a regression study. Unfortunately, power depends on several factors, many of which are unknown prior to conducting an experiment. Thus, when calculating power, usually the best that one can do is to make educated guesses about the values of the inputs on which the power depends. For this reason, power calculations are better regarded as rough guides to sample size.</p>
<p>For the usual SLR test of <span class="math inline">\(H_0: \beta_1 = 0\)</span> vs. <span class="math inline">\(H_a: \beta_1 \ne 0\)</span>, power depends on all of the following:</p>
<ul>
<li>the sample size, <span class="math inline">\(n\)</span>. Larger sample sizes give greater power.</li>
<li>the size of the true slope <span class="math inline">\(\beta_1\)</span>. Values of <span class="math inline">\(\beta_1\)</span> further away from zero (that is, larger values of <span class="math inline">\(|\beta_1|\)</span>) give greater power.<br />
</li>
<li>the magnitude of the residual variance, <span class="math inline">\(\sigma^2_\varepsilon\)</span>. Larger values of <span class="math inline">\(\sigma^2_\varepsilon\)</span> give less power.</li>
<li>the acceptable Type I (false positive) error rate, <span class="math inline">\(\alpha\)</span>. Greater tolerance for Type I errors gives greater power (why?).</li>
</ul>
<p>Typically, a power calculation for SLR involves specifying best guesses for <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\sigma^2_\varepsilon\)</span>, determining the allowable type I error rate <span class="math inline">\(\alpha\)</span>, and then finding the sample size needed to achieve a minimal acceptable power. The internet contains a variety of power calculators for simple regression. Here’s an example using the <code>pwrss.f.reg</code> function found in the <code>pwrss</code> package in <code>R</code>. The code here uses the fact that in SLR the usual test of <span class="math inline">\(H_0: \beta_1 = 0\)</span> vs. <span class="math inline">\(H_a: \beta_1 \ne 0\)</span> is equivalent to a test of <span class="math inline">\(H_0: R^2 = 0\)</span> vs. <span class="math inline">\(H_a: R^2 &gt; 0\)</span>. Conveniently, when we specify the test in terms of <span class="math inline">\(R^2\)</span>, we don’t need to specify both <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\sigma^2_\varepsilon\)</span>; instead, we only need to specify out best guess for <span class="math inline">\(R^2\)</span>. The calculation below shows the sample size needed to achieve 80% power in a SLR when <span class="math inline">\(R^2=0.3\)</span> and <span class="math inline">\(\alpha=0.05\)</span>.</p>
<p>Note that the function <code>pwrss.f.reg</code> is built for multiple regression models that can include several predictor variables. The argument <code>k</code> in the function call indicates the number of predictor variables; in SLR, <span class="math inline">\(k=1\)</span> because there is a single predictor.<a href="#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a></p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="simple-linear-regression.html#cb32-1" tabindex="-1"></a>pwrss<span class="sc">::</span><span class="fu">pwrss.f.reg</span>(<span class="at">r2 =</span> <span class="fl">0.3</span>, <span class="at">k =</span> <span class="dv">1</span>, <span class="at">power =</span> <span class="fl">0.8</span>, <span class="at">alpha =</span> <span class="fl">0.05</span>)</span></code></pre></div>
<pre><code>##  Linear Regression (F test) 
##  R-squared Deviation from 0 (zero) 
##  H0: r2 = 0 
##  HA: r2 &gt; 0 
##  ------------------------------ 
##   Statistical power = 0.8 
##   n = 21 
##  ------------------------------ 
##  Numerator degrees of freedom = 1 
##  Denominator degrees of freedom = 18.425 
##  Non-centrality parameter = 8.754 
##  Type I error rate = 0.05 
##  Type II error rate = 0.2</code></pre>
<p>We see that we would need a sample size of <span class="math inline">\(n=21\)</span> to achieve the desired power.</p>
<p>The graph below shows how the power is related to sample size when <span class="math inline">\(R^2 = 30\%\)</span> and when <span class="math inline">\(R^2 = 60\%\)</span>.</p>
<p><img src="index_files/figure-html/power%20curves-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>The plot below shows the power as a function of <span class="math inline">\(R^2\)</span> for several sample sizes.</p>
<p><img src="index_files/figure-html/more%20power%20curves-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>Why do all three curves intersect at the same point when <span class="math inline">\(R^2 = 0\)</span>? What is this value?</p>
</div>
</div>
<div id="centering-the-predictor" class="section level2 hasAnchor" number="1.9">
<h2><span class="header-section-number">1.9</span> <span class="math inline">\(^\star\)</span>Centering the predictor<a href="simple-linear-regression.html#centering-the-predictor" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>While it isn’t essential, it can be useful to redefine the predictor in a regression as the difference between the observed value and the average value of the predictor. For example, in the BAC data, we can define a centered version of the number of beers consumed by
<span class="math display">\[
x^{ctr} =x -\bar{x}
\]</span>
Let’s try regressing the response against the centered version of the predictor:</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="simple-linear-regression.html#cb34-1" tabindex="-1"></a>beer<span class="sc">$</span>beers.c <span class="ot">&lt;-</span> beer<span class="sc">$</span>Beers <span class="sc">-</span> <span class="fu">mean</span>(beer<span class="sc">$</span>Beers)</span>
<span id="cb34-2"><a href="simple-linear-regression.html#cb34-2" tabindex="-1"></a><span class="fu">head</span>(beer)</span></code></pre></div>
<pre><code>##   Beers   BAC beers.c
## 1     5 0.100  0.1875
## 2     2 0.030 -2.8125
## 3     9 0.190  4.1875
## 4     8 0.120  3.1875
## 5     3 0.040 -1.8125
## 6     7 0.095  2.1875</code></pre>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="simple-linear-regression.html#cb36-1" tabindex="-1"></a>beer_slr_ctr <span class="ot">&lt;-</span> <span class="fu">lm</span>(BAC <span class="sc">~</span> beers.c, <span class="at">data =</span> beer)</span>
<span id="cb36-2"><a href="simple-linear-regression.html#cb36-2" tabindex="-1"></a><span class="fu">summary</span>(beer_slr_ctr)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = BAC ~ beers.c, data = beer)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.027118 -0.017350  0.001773  0.008623  0.041027 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 0.073750   0.005110   14.43 8.47e-10 ***
## beers.c     0.017964   0.002402    7.48 2.97e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.02044 on 14 degrees of freedom
## Multiple R-squared:  0.7998, Adjusted R-squared:  0.7855 
## F-statistic: 55.94 on 1 and 14 DF,  p-value: 2.969e-06</code></pre>
<p>The main advantage of centering the predictors is that the intercept now has a nice interpretation. Namely, the intercept is now the value of the regression line when <span class="math inline">\(x = x^{ctr}\)</span>, which happens to equal the average value of <span class="math inline">\(y\)</span> in the data set. Importantly, we have accomplished this without changing anything about the linear association between the predictor and the response, so our inference for the slope remains unchanged. This is perhaps only a small victory, but it’s a nice touch. Centering the predictor also eases the interpretation of regression parameters in more complicated models with <a href="multiple-regression.html#regression-interactions">interactions</a>, as we will see later.</p>
</div>
<div id="appendix-a-fitting-the-slr-model-in-r" class="section level2 unnumbered hasAnchor">
<h2>Appendix A: Fitting the SLR model in R<a href="simple-linear-regression.html#appendix-a-fitting-the-slr-model-in-r" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The basic command in R for fitting a regression model is the function <code>lm</code>, short for [l]inear [m]odel. (As the name suggests, the `lm’ function can be used for more than just SLR.) The basic syntax is</p>
<pre><code>&gt; lm(response ~ predictor)</code></pre>
<p>where “response” and “predictor” would be replaced by the appropriate variable names. The <code>&gt;</code> is the R prompt, and is meant to show what you could type at the command line. Although the above command would work, it would fit the SLR and then forget the model fit. We want to keep the model fit around to analyze it, so we’ll store it in memory under a name of our choosing. Here, we’ll choose the name <code>fm1</code>, although any name would work. Anything proceeded by a pound sign (#) is a comment in R. We’ll assume that the BAC data have already been read into R and reside in memory, and that the variables in the BAC data are named <code>BAC</code> and <code>Beers</code>. Here is code for fitting a SLR model to these data:</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="simple-linear-regression.html#cb39-1" tabindex="-1"></a>fm1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(BAC <span class="sc">~</span> Beers, <span class="at">data =</span> beer)</span>
<span id="cb39-2"><a href="simple-linear-regression.html#cb39-2" tabindex="-1"></a></span>
<span id="cb39-3"><a href="simple-linear-regression.html#cb39-3" tabindex="-1"></a><span class="co"># The &#39;&lt;-&#39; is the assignment operator.</span></span>
<span id="cb39-4"><a href="simple-linear-regression.html#cb39-4" tabindex="-1"></a><span class="co"># Here, the output produced by the call to &#39;lm&#39; is stored in memory under</span></span>
<span id="cb39-5"><a href="simple-linear-regression.html#cb39-5" tabindex="-1"></a><span class="co"># the name &#39;fm1&#39;.  We can learn about &#39;fm1&#39; by asking for a summary.</span></span>
<span id="cb39-6"><a href="simple-linear-regression.html#cb39-6" tabindex="-1"></a></span>
<span id="cb39-7"><a href="simple-linear-regression.html#cb39-7" tabindex="-1"></a><span class="fu">summary</span>(fm1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = BAC ~ Beers, data = beer)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.027118 -0.017350  0.001773  0.008623  0.041027 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -0.012701   0.012638  -1.005    0.332    
## Beers        0.017964   0.002402   7.480 2.97e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.02044 on 14 degrees of freedom
## Multiple R-squared:  0.7998, Adjusted R-squared:  0.7855 
## F-statistic: 55.94 on 1 and 14 DF,  p-value: 2.969e-06</code></pre>
<p>Let’s examine each portion of the R output above.</p>
<p>The portion labeled <code>Call</code> simply tells us what command was used to generate the model.</p>
<p>The portion labeled <code>Residuals</code> tells us a five-number summary (minimum, first quartile, median, third quartile, and maximum) of the residuals.</p>
<p>The portion labeled <code>Coefficients</code> gives us a table of parameter estimates and standard errors. Each row of the table corresponds to a single parameter. The row labeled (Intercept) obviously corresponds to the intercept. The row labeled with the name of the predictor gives information about the slope parameter.</p>
<p>In addition to parameter estimates and standard errors, R (like many computer packages) also automatically generates hypothesis tests of <span class="math inline">\(H_0: \beta_0 = 0\)</span> vs. <span class="math inline">\(H_a: \beta_0 \ne 0\)</span> and <span class="math inline">\(H_0: \beta_1 = 0\)</span> vs. <span class="math inline">\(H_a: \beta_1 \ne 0\)</span>. It is up to you, the user, to determine whether or not these tests are informative.</p>
<p>Finally, the last block of output provides a variety of additional information. The “residual standard error” (perhaps not the best term) is the estimate of the residual standard deviation, <span class="math inline">\(s_{\varepsilon}\)</span>. R also provides two different <span class="math inline">\(R^2\)</span> values; the <span class="math inline">\(R^2\)</span> that we discussed above is labeled as the “Multiple R-squared”. We will discuss adjusted R-squared later. Finally, the <span class="math inline">\(F\)</span>-statistic corresponds to a `model utility test’, which we will discuss in the context of multiple regression. For now, you might notice that in SLR the p-value of the model-utility test is always equal to the p-value for the test of <span class="math inline">\(H_0: \beta_1 = 0\)</span> vs. <span class="math inline">\(H_a: \beta_1 \ne 0\)</span>. We will explain why this is so later.</p>
<p>The SS decomposition for a regression model is also referred to as the analysis of variance for the regression model. We can use the `anova’ command in R to obtain the SS decomposition:</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="simple-linear-regression.html#cb41-1" tabindex="-1"></a><span class="fu">anova</span>(fm1)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: BAC
##           Df    Sum Sq   Mean Sq F value    Pr(&gt;F)    
## Beers      1 0.0233753 0.0233753  55.944 2.969e-06 ***
## Residuals 14 0.0058497 0.0004178                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The <span class="math inline">\(F\)</span>-statistic is the model utility test, which we will examine in more detail when we study multiple regression.</p>
</div>
<div id="appendix-b-regression-models-in-sas-proc-reg" class="section level2 unnumbered hasAnchor">
<h2>Appendix B: Regression models in SAS PROC REG<a href="simple-linear-regression.html#appendix-b-regression-models-in-sas-proc-reg" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>There are two main procedures (‘PROCs’ for short) that can be used to fit regression models: PROC REG (for REGression) and PROC GLM (for General Linear Model). As the names suggest, GLM is more versatile, but both can be used for regression.</p>
<p>Let’s assume the BAC data have already been loaded into memory in a data set called ‘beer’, and the pertinent variables reside under the variable names ‘bac’ and ‘beers’. Here is sample code for fitting an SLR using PROC REG, and some edited output:</p>
<pre><code>proc reg data = beer;
  model bac = beers;  
run;

The SAS System                                                                                 
The REG Procedure

Root MSE              0.02044    R-Square     0.7998
Dependent Mean        0.07375    Adj R-Sq     0.7855
Coeff Var            27.71654

                         Parameter Estimates

                     Parameter       Standard
Variable     DF       Estimate          Error    t Value      Pr&gt;|t|
Intercept     1       -0.01270        0.01264      -1.00      0.3320
beers         1        0.01796        0.00240       7.48      &lt;.0001</code></pre>
<p>Note that even though the output is arranged differently, the parameter estimates and inference provided are exactly the same, regardless of whether one uses PROC REG, PROC GLM, or R.</p>

</div>
</div>
<h3>Bibliography<a href="bibliography.html#bibliography" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-dennis1994density" class="csl-entry">
Dennis, Brian, and Mark L Taper. 1994. <span>“Density Dependence in Time Series Observations of Natural Populations: Estimation and Testing.”</span> <em>Ecological Monographs</em> 64 (2): 205–24.
</div>
<div id="ref-galton1886regression" class="csl-entry">
Galton, Francis. 1886. <span>“Regression Towards Mediocrity in Hereditary Stature.”</span> <em>The Journal of the Anthropological Institute of Great Britain and Ireland</em> 15: 246–63.
</div>
<div id="ref-gelman2020regression" class="csl-entry">
Gelman, Andrew, Jennifer Hill, and Aki Vehtari. 2020. <em>Regression and Other Stories</em>. Cambridge University Press.
</div>
<div id="ref-gotelli2004primer" class="csl-entry">
Gotelli, Nicholas J, Aaron M Ellison, et al. 2004. <em>A Primer of Ecological Statistics</em>. Vol. 1. Sinauer Associates Sunderland.
</div>
<div id="ref-kahneman2011thinking" class="csl-entry">
Kahneman, Daniel. 2011. <em>Thinking, Fast and Slow</em>. Macmillan.
</div>
<div id="ref-martin2017statistical" class="csl-entry">
Martin, Ryan. 2017. <span>“A Statistical Inference Course Based on p-Values.”</span> <em>The American Statistician</em> 71 (2): 128–36.
</div>
<div id="ref-oehlert2010first" class="csl-entry">
Oehlert, Gary W. 2010. <em>A First Course in Design and Analysis of Experiments</em>.
</div>
<div id="ref-rubin2005causal" class="csl-entry">
Rubin, Donald B. 2005. <span>“Causal Inference Using Potential Outcomes: Design, Modeling, Decisions.”</span> <em>Journal of the American Statistical Association</em> 100 (469): 322–31.
</div>
<div id="ref-wasserstein2016asa" class="csl-entry">
Wasserstein, Ronald L, and Nicole A Lazar. 2016. <span>“The ASA Statement on p-Values: Context, Process, and Purpose.”</span> <em>The American Statistician</em> 70 (2): 129–33.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="4">
<li id="fn4"><p>Regrettably, I’ve lost track of the original source of these data.<a href="simple-linear-regression.html#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>This convention is so common that one often hears the horizontal axis referred to as the <span class="math inline">\(x\)</span>-axis and the vertical axis referred to as the <span class="math inline">\(y\)</span>-axis. If we wanted to be exceedingly careful we should only refer to the axes in this way when the variables that they show are in fact <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, but few outside of mathematics find such care necessary.<a href="simple-linear-regression.html#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>More precisely, the least-squares estimates of the intercept and slope are the <em>maximum likelihood</em> estimates, when we assume that the errors take a Gaussian distribution. Maximum likelihood will be discussed in later versions of these notes.<a href="simple-linear-regression.html#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>A note on terminology: It is conventional to refer to a regression model as a regression of the response on, versus, or against the predictor. Thus, the BAC model could be described as a regression of BAC on the number of beers consumed, or alternatively as a regression of BAC against the number of beers consumed.<a href="simple-linear-regression.html#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p>Perhaps this reveals my own ignorance, but I can’t figure out why the R <code>summary</code> of the linear model refers to <span class="math inline">\(s_{\varepsilon}\)</span> as the “Residual standard error”. It seems to me that <span class="math inline">\(s_{\varepsilon}\)</span> is the standard deviation of the residuals, and thus it would be better to call it the “Residual standard deviation”.<a href="simple-linear-regression.html#fnref8" class="footnote-back">↩︎</a></p></li>
<li id="fn9"><p>If we wanted to be more precise, we should note that the value given by eq. <a href="simple-linear-regression.html#eq:se-slope">(1.2)</a> is actually an estimate of the standard error. The true standard error of the slope is a parameter denoted by <span class="math inline">\(\sigma_{\hat{\beta}_1}\)</span> and given by the formula <span class="math inline">\(\sigma_{\hat{\beta}_1} = \frac{\sigma_{\varepsilon}}{\sqrt{S_{xx} } }\)</span>, where <span class="math inline">\(\sigma_{\varepsilon}\)</span> is the (true) residual standard deviation. Of course, we can never compute <span class="math inline">\(\sigma_{\hat{\beta}_1}\)</span>, because we can never know <span class="math inline">\(\sigma_{\varepsilon}\)</span>. So, we do the sensible thing and substitute our estimate of the residual standard deviation <span class="math inline">\(s_{\varepsilon}\)</span> for its unknown counterpart <span class="math inline">\(\sigma_{\varepsilon}\)</span>. The resulting expression in eq. <a href="simple-linear-regression.html#eq:se-slope">(1.2)</a> gives us an estimate of the standard error of the slope. It would be cumbersome to call <span class="math inline">\(s_{\hat{\beta}_1}\)</span> (and every estimated standard error) an “estimated standard error”, so we usually just call it a “standard error”. That said, if we were to repeat the experiment with a different random sample of individuals, we would expect to obtain a different value for <span class="math inline">\(s_{\hat{\beta}_1}\)</span>, because the value is an estimate. (And, yes, because <span class="math inline">\(s_{\hat{\beta}_1}\)</span> is an estimate, it has its own standard error <span class="math inline">\(\sigma_{s_{\hat{\beta}_1}}\)</span> which we could estimate as <span class="math inline">\(s_{s_{\hat{\beta}_1}}\)</span>, and so on to infinity.))<a href="simple-linear-regression.html#fnref9" class="footnote-back">↩︎</a></p></li>
<li id="fn10"><p>Here’s another way to see why it is incorrect to interpret a the coverage level of a confidence interval as a statement about the probability that a random parameter falls in a fixed interval. Suppose we repeated the experiment with a new random sample drawn from the same population and calculated a new 99% confidence interval for <span class="math inline">\(\beta_1\)</span> based on this second experiment. Under the incorrect interpretation, we could immediately use the mathematics of probability to determine that the intersection (or overlap) of the two 99% confidence intervals must itself be a confidence interval with at least 98% coverage. But this can’t be true. Indeed, there is some chance that the two intervals won’t overlap at all! Thus our original premise of treating the coverage level as a statement about the probability that a random parameter is contained in a fixed interval must be wrong. The only way to interpret the situation correctly is to realize that confidence is a statement about the probability that a random interval contains a fixed parameter value.<a href="simple-linear-regression.html#fnref10" class="footnote-back">↩︎</a></p></li>
<li id="fn11"><p>This plot is based on Figure 6.1 of <span class="citation">Oehlert (<a href="#ref-oehlert2010first">2010</a>)</span>.<a href="simple-linear-regression.html#fnref11" class="footnote-back">↩︎</a></p></li>
<li id="fn12"><p>Note that a log transformation will not work if the data contain response values equal to 0. The usual approach in this case is either to take the <span class="math inline">\(\ln(y + 1)\)</span>, or to take <span class="math inline">\(\ln(y + c)\)</span>, where <span class="math inline">\(c\)</span> is one-half of the smallest non-zero response value in the data set. Note also that the base of the logarithm doesn’t matter when taking a log transformation. Natural log is the most common choice, but one can also use <span class="math inline">\(\log_2\)</span> or <span class="math inline">\(\log_{10}\)</span>.<a href="simple-linear-regression.html#fnref12" class="footnote-back">↩︎</a></p></li>
<li id="fn13"><p>One of my instructors used to refer to normality of the residuals in a linear model as a “self-fulfilling prophecy”.<a href="simple-linear-regression.html#fnref13" class="footnote-back">↩︎</a></p></li>
<li id="fn14"><p>Actually, <code>pwrss::pwrss.f.reg</code> computes the power of the model-utility test. Later, we will see that in the context of SLR this test is equivalent to the test of <span class="math inline">\(H_0: \beta_1 = 0\)</span> vs. <span class="math inline">\(H_a: \beta_1 \ne 0\)</span>.<a href="simple-linear-regression.html#fnref14" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="multiple-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
