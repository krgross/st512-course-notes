<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>ST 512 course notes</title>
  <meta name="description" content="Course notes for ST 512, Statistical Methods for Researchers II." />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="ST 512 course notes" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Course notes for ST 512, Statistical Methods for Researchers II." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="ST 512 course notes" />
  
  <meta name="twitter:description" content="Course notes for ST 512, Statistical Methods for Researchers II." />
  

<meta name="author" content="Kevin Gross" />


<meta name="date" content="2022-12-06" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  

<link rel="next" href="simple-linear-regression.html"/>
<script src="libs/header-attrs-2.9/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>1</b> Simple linear regression</a>
<ul>
<li class="chapter" data-level="1.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#the-basics-of-slr"><i class="fa fa-check"></i><b>1.1</b> The basics of SLR</a></li>
<li class="chapter" data-level="1.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#least-squares-estimation"><i class="fa fa-check"></i><b>1.2</b> Least-squares estimation</a></li>
<li class="chapter" data-level="1.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#inference-for-the-slope"><i class="fa fa-check"></i><b>1.3</b> Inference for the slope</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#standard-errors"><i class="fa fa-check"></i><b>1.3.1</b> Standard errors</a></li>
<li class="chapter" data-level="1.3.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#confidence-intervals"><i class="fa fa-check"></i><b>1.3.2</b> Confidence intervals</a></li>
<li class="chapter" data-level="1.3.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#statistical-hypothesis-tests"><i class="fa fa-check"></i><b>1.3.3</b> Statistical hypothesis tests</a></li>
<li class="chapter" data-level="1.3.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#inference-for-the-intercept"><i class="fa fa-check"></i><b>1.3.4</b> Inference for the intercept</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#sums-of-squares-decomposition-and-r2"><i class="fa fa-check"></i><b>1.4</b> Sums of squares decomposition and <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="1.5" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#fitting-the-slr-model-in-r"><i class="fa fa-check"></i><b>1.5</b> Fitting the SLR model in R</a></li>
<li class="chapter" data-level="1.6" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#diagnostic-plots"><i class="fa fa-check"></i><b>1.6</b> Diagnostic plots</a></li>
<li class="chapter" data-level="1.7" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#consequences-of-violating-model-assumptions-and-possible-fixes"><i class="fa fa-check"></i><b>1.7</b> Consequences of violating model assumptions, and possible fixes</a></li>
<li class="chapter" data-level="1.8" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#prediction-with-regression-models"><i class="fa fa-check"></i><b>1.8</b> Prediction with regression models</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="multiple-regression.html"><a href="multiple-regression.html"><i class="fa fa-check"></i><b>2</b> Multiple regression</a>
<ul>
<li class="chapter" data-level="2.1" data-path="multiple-regression.html"><a href="multiple-regression.html#multiple-regression-for-associating-multiple-predictor-variables-with-a-single-response"><i class="fa fa-check"></i><b>2.1</b> Multiple regression for associating multiple predictor variables with a single response</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="multiple-regression.html"><a href="multiple-regression.html#sums-of-squares-decomposition-and-r2."><i class="fa fa-check"></i><b>2.1.1</b> Sums of squares decomposition and <span class="math inline">\(R^2\)</span>.</a></li>
<li class="chapter" data-level="2.1.2" data-path="multiple-regression.html"><a href="multiple-regression.html#partial-regression-coefficients."><i class="fa fa-check"></i><b>2.1.2</b> Partial regression coefficients.</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="multiple-regression.html"><a href="multiple-regression.html#statistical-inference-for-partial-regression-coefficients"><i class="fa fa-check"></i><b>2.2</b> Statistical inference for partial regression coefficients</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="multiple-regression.html"><a href="multiple-regression.html#prediction"><i class="fa fa-check"></i><b>2.2.1</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="multiple-regression.html"><a href="multiple-regression.html#indicator-variables"><i class="fa fa-check"></i><b>2.3</b> Indicator variables</a></li>
<li class="chapter" data-level="2.4" data-path="multiple-regression.html"><a href="multiple-regression.html#the-mlr-model-in-matrix-notation"><i class="fa fa-check"></i><b>2.4</b> The MLR model in matrix notation</a></li>
<li class="chapter" data-level="2.5" data-path="multiple-regression.html"><a href="multiple-regression.html#interactions-between-predictors"><i class="fa fa-check"></i><b>2.5</b> Interactions between predictors</a></li>
<li class="chapter" data-level="2.6" data-path="multiple-regression.html"><a href="multiple-regression.html#polynomial-regression"><i class="fa fa-check"></i><b>2.6</b> Polynomial regression</a></li>
<li class="chapter" data-level="2.7" data-path="multiple-regression.html"><a href="multiple-regression.html#testing-multiple-regression-coefficients-at-once"><i class="fa fa-check"></i><b>2.7</b> Testing multiple regression coefficients at once</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="multiple-regression.html"><a href="multiple-regression.html#model-utility-tests"><i class="fa fa-check"></i><b>2.7.1</b> Model utility tests</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="multiple-regression.html"><a href="multiple-regression.html#multi-collinearity"><i class="fa fa-check"></i><b>2.8</b> (Multi-)Collinearity</a></li>
<li class="chapter" data-level="2.9" data-path="multiple-regression.html"><a href="multiple-regression.html#variable-selection-choosing-the-best-model"><i class="fa fa-check"></i><b>2.9</b> Variable selection: Choosing the best model</a>
<ul>
<li class="chapter" data-level="2.9.1" data-path="multiple-regression.html"><a href="multiple-regression.html#ranking-methods"><i class="fa fa-check"></i><b>2.9.1</b> Ranking methods</a></li>
<li class="chapter" data-level="2.9.2" data-path="multiple-regression.html"><a href="multiple-regression.html#sequential-methods"><i class="fa fa-check"></i><b>2.9.2</b> Sequential methods</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="multiple-regression.html"><a href="multiple-regression.html#non-linear-regression"><i class="fa fa-check"></i><b>2.10</b> Non-linear regression</a></li>
<li class="chapter" data-level="2.11" data-path="multiple-regression.html"><a href="multiple-regression.html#leverage-influential-points-and-standardized-residuals"><i class="fa fa-check"></i><b>2.11</b> Leverage, influential points, and standardized residuals</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="one-factor-anova.html"><a href="one-factor-anova.html"><i class="fa fa-check"></i><b>3</b> One-factor ANOVA</a>
<ul>
<li class="chapter" data-level="3.1" data-path="one-factor-anova.html"><a href="one-factor-anova.html#one-factor-anova-the-basics"><i class="fa fa-check"></i><b>3.1</b> One-factor ANOVA: The basics</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i>Bibliography</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">ST 512 course notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="header">
<h1 class="title">ST 512 course notes</h1>
<p class="author"><em>Kevin Gross</em></p>
<p class="date" style="margin-top: 1.5em;"><em>2022-12-06</em></p>
</div>
<div id="preface" class="section level1 unnumbered">
<h1>Preface</h1>
<p>These are course notes for ST 512, Statistical Methods for Researchers II, taught at North Carolina State University. ST 512 is the second semester of a two-semester sequence in statistical methods. These notes are a proto-textbook, and are available for use by anyone associated with NCSU.</p>
<p><em>Philosophy</em></p>
<!-- Why do we learn statistics?  Statistics is a tool that can make for more effective data analysis.  It is not meant merely to serve a signalling function.   -->
<p>When it comes to statistics, researchers cannot necessarily rely on their common sense to lead them towards correct answers. Statistical reasoning is non-intuitive (<span class="citation"><a href="#ref-kahneman2011thinking" role="doc-biblioref">Kahneman</a> (<a href="#ref-kahneman2011thinking" role="doc-biblioref">2011</a>)</span>), and the foundational ideas of statistics are elusive. Therefore statistical literacy must be learned. The primary goal of this course is to sharpen students’ statistical literacy so that they may become more effective researchers. However, one does not develop a deep conceptual understanding merely by discussing concepts. Instead, conceptual understanding is honed in part by studying the details of particular methods to understand why those details matter. When we study the details of a method, the expectation is not that the student will remember those details in perpetuity. Indeed, practicing scientists are unlikely anyway to have the cognitive bandwidth to remember details about statistical methods that they do not use routinely. Instead, the point of studying statistical methods in detail is to strengthen conceptual understanding by exploring statistical methods at more than a superficial level. Examining details now will also make those details more recognizable if and when one faces a future data-analysis task that requires re-engaging those details. That said, the ultimate emphasis of this course is not on the details of the methods, but is instead on the ideas, concepts, and reasoning that underlie statistical thinking. I hope that students of this course will deepen their conceptual understanding of statistics and by doing so strengthen their effectiveness as scientists.</p>
<p><em>Scope</em></p>
<p>This classes focuses on linear statistical models, that is, regression and ANOVA. These linear models are the backbone of techniques for analyzing designed experiments in science. These methods can also be, and often are, used to analyze so-called “observational data,” that is, data collected outside an experimental context.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> Of course, most graduate students will need to learn specialized statistical methods that are popular in their own field of study. These notes are not meant to cover these specialized methods, and thus they are not meant to embody the whole of statistics. However, study of regression and ANOVA provides an opportunity to master core tools and provides a springboard to the study of more specialized and possibly discipline-specific methods.</p>
<p>This class deals exclusively with so-called “frequentist” statistical inference. We do not engage Bayesian methods. This class is also firmly situated in the study of low-dimensional statistical models. We value parsimony, and we take the view that well constructed models are worthy objects of study in their own right. More concretely, we seek to construct statistical models with parameters that correspond to natural phenomena of interest. This view exists in some tension with the contrasting “big data” culture of statistics, which places more emphasis on the detection of patterns and prediction of future observations, and is less concerned with unpacking the “black box” that characterizes those patterns (<span class="citation"><a href="#ref-breiman2001statistical" role="doc-biblioref">Breiman</a> (<a href="#ref-breiman2001statistical" role="doc-biblioref">2001</a>)</span>).</p>
<p><em>Assumed math background</em></p>
<p>ST 512 does not assume knowledge of or use any math beyond arithmetic and basic probability. At NCSU, it is assumed that students have learned the necessary probability background in a first statistics class like ST 511. This basic probability includes an understanding of random variables, standard distributions — primarily Gaussian (normal) distributions, but also binomial and Poisson — and basic properties of means and variances.</p>
<p>Students who are willing to engage the math a bit more deeply will find that doing so provides a more satisfying path through the material and leads to a more durable understanding. Without knowing the math underneath, one can only learn statistical methods as different recipes in a vast cookbook, a tedious task that taxes the memory and gives statistics courses their reputation for drudgery. For those who are so inclined, learning a bit of the mathematical theory reveals how the methods we study connect with one another, and thus provides a scaffolding to organize the methods sensibly and coherently. Moreover, the underpinning mathematics can be understood with a minimum of calculus. Linear algebra, however, is more essential. Indeed, the linear models that we study are, ultimately, exercises in linear algebra. This course assumes no previous familiarity with linear algebra, and so we will not emphasize the linear algebra underpinnings of the methods. In the fullness of time, I hope that these notes will eventually include sidebars that present the linear algebra underneath the methods, for interested readers.</p>
<p>In this day and age, one might ask why it’s necessary to understand the math at all. Indeed, the internet makes it easy to find quickly code for any standard analysis. Moreover, while the robots’ takeover of humanity may or may not be imminent, we are probably not too far away from the rise of artificial intelligence-based statistical consulting, where anyone can upload a data set and answer a few questions about it in return for an AI’s analysis. In such a world, the primary task facing an analyst is not so much to get the computer to give you an answer, but instead to confirm that the answer is in fact the one you want. Towards this end, knowing a bit about the math behind the methods makes it possible to determine whether the computer output you’ve obtained is indeed the analysis you hoped for. Throughout, we will try to emphasize simple, quick calculations that can be used to verify that computer output is correct, or indicate that something needs to be fixed.</p>
<p><em>Computing</em></p>
<p>ST 512 serves a broad clientele. Some students will be better served learning R, and others will be better served learning SAS. R and SAS code are used throughout these notes, but the notes are not meant to provide fully fledged instruction in R or SAS. For students in the class, instruction in R and SAS will be provided in the labs associated with the course. Eventually, I hope that these notes will eventually include computing companions that discuss implementation of the methods in both R and SAS.</p>
<p><em>Format of these notes</em></p>
<p>Material that appears in <span style="color: gray;"> gray text </span> and is offset by horizontal rules (like the one below this paragraph) is enrichment material to provide a deeper exploration for interested readers. This material may be skipped without loss. This structure is inspired by <span class="citation"><a href="#ref-mascolell1995microeconomic" role="doc-biblioref">Mas-Colell et al.</a> (<a href="#ref-mascolell1995microeconomic" role="doc-biblioref">1995</a>)</span>’s lovely text.</p>
<hr />
</div>
<h3>Bibliography</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-breiman2001statistical" class="csl-entry">
Breiman, Leo. 2001. <span>“Statistical Modeling: The Two Cultures (with Comments and a Rejoinder by the Author).”</span> <em>Statistical Science</em> 16 (3): 199–231.
</div>
<div id="ref-kahneman2011thinking" class="csl-entry">
Kahneman, Daniel. 2011. <em>Thinking, Fast and Slow</em>. Macmillan.
</div>
<div id="ref-mascolell1995microeconomic" class="csl-entry">
Mas-Colell, Andreu, Michael Dennis Whinston, Jerry R Green, and others. 1995. <em>Microeconomic Theory</em>. Vol. 1. Oxford university press New York.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>That said, regression lends itself a bit more to the analysis of observational data than ANOVA does.<a href="index.html#fnref1" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>

<a href="simple-linear-regression.html" class="navigation navigation-next navigation-unique" aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
