<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Blocked designs | ST 512 course notes</title>
  <meta name="description" content="Course notes for ST 512, Statistical Methods for Researchers II." />
  <meta name="generator" content="bookdown 0.30 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Blocked designs | ST 512 course notes" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Course notes for ST 512, Statistical Methods for Researchers II." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Blocked designs | ST 512 course notes" />
  
  <meta name="twitter:description" content="Course notes for ST 512, Statistical Methods for Researchers II." />
  

<meta name="author" content="Kevin Gross" />


<meta name="date" content="2023-03-31" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="random-effects.html"/>
<link rel="next" href="bibliography.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#philosophy"><i class="fa fa-check"></i>Philosophy</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#scope-and-coverage"><i class="fa fa-check"></i>Scope and coverage</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#mathematical-level"><i class="fa fa-check"></i>Mathematical level</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#computing"><i class="fa fa-check"></i>Computing</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#format-of-the-notes"><i class="fa fa-check"></i>Format of the notes</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgments-and-license"><i class="fa fa-check"></i>Acknowledgments and license</a></li>
</ul></li>
<li class="part"><span><b>Part I: Regression modeling</b></span></li>
<li class="chapter" data-level="1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>1</b> Simple linear regression</a>
<ul>
<li class="chapter" data-level="1.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#the-basics-of-slr"><i class="fa fa-check"></i><b>1.1</b> The basics of SLR</a></li>
<li class="chapter" data-level="1.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#least-squares-estimation"><i class="fa fa-check"></i><b>1.2</b> Least-squares estimation</a></li>
<li class="chapter" data-level="1.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#inference-for-the-slope"><i class="fa fa-check"></i><b>1.3</b> Inference for the slope</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#standard-errors"><i class="fa fa-check"></i><b>1.3.1</b> Standard errors</a></li>
<li class="chapter" data-level="1.3.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#confidence-intervals"><i class="fa fa-check"></i><b>1.3.2</b> Confidence intervals</a></li>
<li class="chapter" data-level="1.3.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#statistical-hypothesis-tests"><i class="fa fa-check"></i><b>1.3.3</b> Statistical hypothesis tests</a></li>
<li class="chapter" data-level="1.3.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#inference-for-the-intercept"><i class="fa fa-check"></i><b>1.3.4</b> Inference for the intercept</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#sums-of-squares-decomposition-and-r2"><i class="fa fa-check"></i><b>1.4</b> Sums of squares decomposition and <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="1.5" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#fitting-the-slr-model-in-r"><i class="fa fa-check"></i><b>1.5</b> Fitting the SLR model in R</a></li>
<li class="chapter" data-level="1.6" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#diagnostic-plots"><i class="fa fa-check"></i><b>1.6</b> Diagnostic plots</a></li>
<li class="chapter" data-level="1.7" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#consequences-of-violating-model-assumptions-and-possible-fixes"><i class="fa fa-check"></i><b>1.7</b> Consequences of violating model assumptions, and possible fixes</a></li>
<li class="chapter" data-level="1.8" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#prediction-with-regression-models"><i class="fa fa-check"></i><b>1.8</b> Prediction with regression models</a></li>
<li class="chapter" data-level="1.9" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#regression-design"><i class="fa fa-check"></i><b>1.9</b> Regression design</a></li>
<li class="chapter" data-level="1.10" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#centering-the-predictor"><i class="fa fa-check"></i><b>1.10</b> <span class="math inline">\(^\star\)</span>Centering the predictor</a></li>
<li class="chapter" data-level="" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#appendix-regression-models-in-sas-proc-reg"><i class="fa fa-check"></i>Appendix: Regression models in SAS PROC REG</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="multiple-regression.html"><a href="multiple-regression.html"><i class="fa fa-check"></i><b>2</b> Multiple regression</a>
<ul>
<li class="chapter" data-level="2.1" data-path="multiple-regression.html"><a href="multiple-regression.html#multiple-regression-basics"><i class="fa fa-check"></i><b>2.1</b> Multiple regression basics</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="multiple-regression.html"><a href="multiple-regression.html#the-multiple-regression-model"><i class="fa fa-check"></i><b>2.1.1</b> The multiple regression model</a></li>
<li class="chapter" data-level="2.1.2" data-path="multiple-regression.html"><a href="multiple-regression.html#interpreting-partial-regression-coefficients."><i class="fa fa-check"></i><b>2.1.2</b> Interpreting partial regression coefficients.</a></li>
<li class="chapter" data-level="2.1.3" data-path="multiple-regression.html"><a href="multiple-regression.html#visualizing-a-multiple-regression-model"><i class="fa fa-check"></i><b>2.1.3</b> Visualizing a multiple regression model</a></li>
<li class="chapter" data-level="2.1.4" data-path="multiple-regression.html"><a href="multiple-regression.html#statistical-inference-for-partial-regression-coefficients"><i class="fa fa-check"></i><b>2.1.4</b> Statistical inference for partial regression coefficients</a></li>
<li class="chapter" data-level="2.1.5" data-path="multiple-regression.html"><a href="multiple-regression.html#prediction"><i class="fa fa-check"></i><b>2.1.5</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="multiple-regression.html"><a href="multiple-regression.html#F-test"><i class="fa fa-check"></i><b>2.2</b> <span class="math inline">\(F\)</span>-tests for several regression coefficients</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="multiple-regression.html"><a href="multiple-regression.html#model-utility-tests"><i class="fa fa-check"></i><b>2.2.1</b> Model utility tests</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="multiple-regression.html"><a href="multiple-regression.html#categorical-predictors"><i class="fa fa-check"></i><b>2.3</b> Categorical predictors</a></li>
<li class="chapter" data-level="2.4" data-path="multiple-regression.html"><a href="multiple-regression.html#regression-interactions"><i class="fa fa-check"></i><b>2.4</b> Interactions between predictors</a></li>
<li class="chapter" data-level="2.5" data-path="multiple-regression.html"><a href="multiple-regression.html#collinearity"><i class="fa fa-check"></i><b>2.5</b> (Multi-)Collinearity</a></li>
<li class="chapter" data-level="2.6" data-path="multiple-regression.html"><a href="multiple-regression.html#variable-selection-choosing-the-best-model"><i class="fa fa-check"></i><b>2.6</b> Variable selection: Choosing the best model</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="multiple-regression.html"><a href="multiple-regression.html#model-selection-and-inference"><i class="fa fa-check"></i><b>2.6.1</b> Model selection and inference</a></li>
<li class="chapter" data-level="2.6.2" data-path="multiple-regression.html"><a href="multiple-regression.html#ranking-methods"><i class="fa fa-check"></i><b>2.6.2</b> Ranking methods</a></li>
<li class="chapter" data-level="2.6.3" data-path="multiple-regression.html"><a href="multiple-regression.html#cross-validation"><i class="fa fa-check"></i><b>2.6.3</b> Cross-validation</a></li>
<li class="chapter" data-level="2.6.4" data-path="multiple-regression.html"><a href="multiple-regression.html#sequential-methods"><i class="fa fa-check"></i><b>2.6.4</b> Sequential methods</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="multiple-regression.html"><a href="multiple-regression.html#leverage-influential-points-and-standardized-residuals"><i class="fa fa-check"></i><b>2.7</b> Leverage, influential points, and standardized residuals</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="multiple-regression.html"><a href="multiple-regression.html#leverage"><i class="fa fa-check"></i><b>2.7.1</b> Leverage</a></li>
<li class="chapter" data-level="2.7.2" data-path="multiple-regression.html"><a href="multiple-regression.html#standardized-residuals"><i class="fa fa-check"></i><b>2.7.2</b> Standardized residuals</a></li>
<li class="chapter" data-level="2.7.3" data-path="multiple-regression.html"><a href="multiple-regression.html#cooks-distance"><i class="fa fa-check"></i><b>2.7.3</b> Cook’s distance</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="multiple-regression.html"><a href="multiple-regression.html#appendix-regression-as-a-linear-algebra-problem"><i class="fa fa-check"></i>Appendix: Regression as a linear algebra problem</a>
<ul>
<li class="chapter" data-level="" data-path="multiple-regression.html"><a href="multiple-regression.html#singular-or-pathological-design-matrices"><i class="fa fa-check"></i>Singular, or pathological, design matrices</a></li>
<li class="chapter" data-level="" data-path="multiple-regression.html"><a href="multiple-regression.html#additional-results"><i class="fa fa-check"></i>Additional results</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="non-linear-regression-models.html"><a href="non-linear-regression-models.html"><i class="fa fa-check"></i><b>3</b> Non-linear regression models</a>
<ul>
<li class="chapter" data-level="3.1" data-path="non-linear-regression-models.html"><a href="non-linear-regression-models.html#polynomial-regression"><i class="fa fa-check"></i><b>3.1</b> Polynomial regression</a></li>
<li class="chapter" data-level="3.2" data-path="non-linear-regression-models.html"><a href="non-linear-regression-models.html#nls"><i class="fa fa-check"></i><b>3.2</b> Non-linear least squares</a></li>
<li class="chapter" data-level="3.3" data-path="non-linear-regression-models.html"><a href="non-linear-regression-models.html#starsmoothing-methods"><i class="fa fa-check"></i><b>3.3</b> <em><span class="math inline">\(^\star\)</span>Smoothing methods</em></a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="non-linear-regression-models.html"><a href="non-linear-regression-models.html#loess-smoothers"><i class="fa fa-check"></i><b>3.3.1</b> Loess smoothers</a></li>
<li class="chapter" data-level="3.3.2" data-path="non-linear-regression-models.html"><a href="non-linear-regression-models.html#splines"><i class="fa fa-check"></i><b>3.3.2</b> Splines</a></li>
<li class="chapter" data-level="3.3.3" data-path="non-linear-regression-models.html"><a href="non-linear-regression-models.html#generalized-additive-models-gams"><i class="fa fa-check"></i><b>3.3.3</b> Generalized additive models (GAMs)</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Part II: Designed experiments</b></span></li>
<li class="chapter" data-level="4" data-path="one-factor-anova.html"><a href="one-factor-anova.html"><i class="fa fa-check"></i><b>4</b> One-factor ANOVA</a>
<ul>
<li class="chapter" data-level="4.1" data-path="one-factor-anova.html"><a href="one-factor-anova.html#grouped-data-and-the-design-of-experiments-doe-an-overview"><i class="fa fa-check"></i><b>4.1</b> Grouped data and the design of experiments (DoE): an overview</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="one-factor-anova.html"><a href="one-factor-anova.html#a-vocabulary-for-describing-designed-experiments"><i class="fa fa-check"></i><b>4.1.1</b> A vocabulary for describing designed experiments</a></li>
<li class="chapter" data-level="4.1.2" data-path="one-factor-anova.html"><a href="one-factor-anova.html#roadmap"><i class="fa fa-check"></i><b>4.1.2</b> Roadmap</a></li>
<li class="chapter" data-level="4.1.3" data-path="one-factor-anova.html"><a href="one-factor-anova.html#the-simplest-experiment"><i class="fa fa-check"></i><b>4.1.3</b> The simplest experiment</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="one-factor-anova.html"><a href="one-factor-anova.html#one-factor-anova-the-basics"><i class="fa fa-check"></i><b>4.2</b> One-factor ANOVA: The basics</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="one-factor-anova.html"><a href="one-factor-anova.html#connections-between-one-factor-anova-and-other-statistical-procedures"><i class="fa fa-check"></i><b>4.2.1</b> Connections between one-factor ANOVA and other statistical procedures</a></li>
<li class="chapter" data-level="4.2.2" data-path="one-factor-anova.html"><a href="one-factor-anova.html#assumptions-in-anova"><i class="fa fa-check"></i><b>4.2.2</b> Assumptions in ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="one-factor-anova.html"><a href="one-factor-anova.html#linear-contrasts-of-group-means"><i class="fa fa-check"></i><b>4.3</b> Linear contrasts of group means</a></li>
<li class="chapter" data-level="4.4" data-path="one-factor-anova.html"><a href="one-factor-anova.html#using-sas-the-effects-parameterization-of-the-one-factor-anova"><i class="fa fa-check"></i><b>4.4</b> Using SAS: The effects parameterization of the one-factor ANOVA</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="one-factor-anova.html"><a href="one-factor-anova.html#effects-model-parameterization-of-the-one-factor-anova-model"><i class="fa fa-check"></i><b>4.4.1</b> Effects-model parameterization of the one-factor ANOVA model</a></li>
<li class="chapter" data-level="4.4.2" data-path="one-factor-anova.html"><a href="one-factor-anova.html#sas-implementation-of-the-one-factor-anova-model-in-proc-glm"><i class="fa fa-check"></i><b>4.4.2</b> SAS implementation of the one-factor ANOVA model in PROC GLM</a></li>
<li class="chapter" data-level="4.4.3" data-path="one-factor-anova.html"><a href="one-factor-anova.html#using-the-estimate-and-contrast-statements-for-linear-contrasts-in-proc-glm"><i class="fa fa-check"></i><b>4.4.3</b> Using the ESTIMATE and CONTRAST statements for linear contrasts in PROC GLM</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="one-factor-anova.html"><a href="one-factor-anova.html#linear-contrasts-revisited-testing-multiple-simultaneous-contrasts"><i class="fa fa-check"></i><b>4.5</b> Linear contrasts revisited: Testing multiple simultaneous contrasts</a></li>
<li class="chapter" data-level="4.6" data-path="one-factor-anova.html"><a href="one-factor-anova.html#multiple-comparisons"><i class="fa fa-check"></i><b>4.6</b> Multiple comparisons</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="one-factor-anova.html"><a href="one-factor-anova.html#multiple-testing-in-general"><i class="fa fa-check"></i><b>4.6.1</b> Multiple testing in general</a></li>
<li class="chapter" data-level="4.6.2" data-path="one-factor-anova.html"><a href="one-factor-anova.html#bonferroni-and-bonferroni-like-procedures"><i class="fa fa-check"></i><b>4.6.2</b> Bonferroni and Bonferroni-like procedures</a></li>
<li class="chapter" data-level="4.6.3" data-path="one-factor-anova.html"><a href="one-factor-anova.html#multiple-comparisons-in-anova"><i class="fa fa-check"></i><b>4.6.3</b> Multiple comparisons in ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="one-factor-anova.html"><a href="one-factor-anova.html#general-strategy-for-analyzing-data-from-a-crd-with-a-one-factor-treatment-structure"><i class="fa fa-check"></i><b>4.7</b> General strategy for analyzing data from a CRD with a one-factor treatment structure</a></li>
<li class="chapter" data-level="4.8" data-path="one-factor-anova.html"><a href="one-factor-anova.html#starpower-and-sample-size-determination-in-anova"><i class="fa fa-check"></i><b>4.8</b> <span class="math inline">\(^\star\)</span>Power and sample-size determination in ANOVA</a></li>
<li class="chapter" data-level="4.9" data-path="one-factor-anova.html"><a href="one-factor-anova.html#starorthogonal-contrasts"><i class="fa fa-check"></i><b>4.9</b> <span class="math inline">\(^\star\)</span>Orthogonal contrasts</a></li>
<li class="chapter" data-level="4.10" data-path="one-factor-anova.html"><a href="one-factor-anova.html#starpolynomial-trends"><i class="fa fa-check"></i><b>4.10</b> <span class="math inline">\(^\star\)</span>Polynomial trends</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="factorial-experiments.html"><a href="factorial-experiments.html"><i class="fa fa-check"></i><b>5</b> Factorial experiments</a>
<ul>
<li class="chapter" data-level="5.1" data-path="factorial-experiments.html"><a href="factorial-experiments.html#crossed-vs.-nested-designs"><i class="fa fa-check"></i><b>5.1</b> Crossed vs. nested designs</a></li>
<li class="chapter" data-level="5.2" data-path="factorial-experiments.html"><a href="factorial-experiments.html#simple-effects-main-effects-and-interaction-effects"><i class="fa fa-check"></i><b>5.2</b> Simple effects, main effects, and interaction effects</a></li>
<li class="chapter" data-level="5.3" data-path="factorial-experiments.html"><a href="factorial-experiments.html#analysis-of-a-balanced-2-times-2-factorial-experiment"><i class="fa fa-check"></i><b>5.3</b> Analysis of a balanced 2 <span class="math inline">\(\times\)</span> 2 factorial experiment</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="factorial-experiments.html"><a href="factorial-experiments.html#example-weight-gain-in-rats"><i class="fa fa-check"></i><b>5.3.1</b> Example: Weight gain in rats</a></li>
<li class="chapter" data-level="5.3.2" data-path="factorial-experiments.html"><a href="factorial-experiments.html#analysis-using-proc-glm-in-sas"><i class="fa fa-check"></i><b>5.3.2</b> Analysis using PROC GLM in SAS</a></li>
<li class="chapter" data-level="5.3.3" data-path="factorial-experiments.html"><a href="factorial-experiments.html#effects-notation-for-the-two-factor-anova"><i class="fa fa-check"></i><b>5.3.3</b> Effects notation for the two-factor ANOVA</a></li>
<li class="chapter" data-level="5.3.4" data-path="factorial-experiments.html"><a href="factorial-experiments.html#a-second-example"><i class="fa fa-check"></i><b>5.3.4</b> A second example</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="factorial-experiments.html"><a href="factorial-experiments.html#a-times-b-factorial-designs"><i class="fa fa-check"></i><b>5.4</b> <span class="math inline">\(a \times b\)</span> factorial designs</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="factorial-experiments.html"><a href="factorial-experiments.html#example-without-a-significant-interaction"><i class="fa fa-check"></i><b>5.4.1</b> Example without a significant interaction</a></li>
<li class="chapter" data-level="5.4.2" data-path="factorial-experiments.html"><a href="factorial-experiments.html#example-with-a-significant-interaction"><i class="fa fa-check"></i><b>5.4.2</b> Example with a significant interaction</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="factorial-experiments.html"><a href="factorial-experiments.html#unreplicated-factorial-designs"><i class="fa fa-check"></i><b>5.5</b> Unreplicated factorial designs</a></li>
<li class="chapter" data-level="5.6" data-path="factorial-experiments.html"><a href="factorial-experiments.html#missing-cells"><i class="fa fa-check"></i><b>5.6</b> Missing cells</a></li>
<li class="chapter" data-level="5.7" data-path="factorial-experiments.html"><a href="factorial-experiments.html#more-than-two-factors"><i class="fa fa-check"></i><b>5.7</b> More than two factors</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ancova.html"><a href="ancova.html"><i class="fa fa-check"></i><b>6</b> ANCOVA</a></li>
<li class="chapter" data-level="7" data-path="random-effects.html"><a href="random-effects.html"><i class="fa fa-check"></i><b>7</b> Random effects</a>
<ul>
<li class="chapter" data-level="7.1" data-path="random-effects.html"><a href="random-effects.html#fixed-vs.-random-effects-the-big-picture"><i class="fa fa-check"></i><b>7.1</b> Fixed vs. random effects: the big picture</a></li>
<li class="chapter" data-level="7.2" data-path="random-effects.html"><a href="random-effects.html#random-effects-models"><i class="fa fa-check"></i><b>7.2</b> Random-effects models</a></li>
<li class="chapter" data-level="7.3" data-path="random-effects.html"><a href="random-effects.html#subsampling"><i class="fa fa-check"></i><b>7.3</b> Subsampling</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="random-effects.html"><a href="random-effects.html#equal-subsamples-per-eu"><i class="fa fa-check"></i><b>7.3.1</b> Equal subsamples per EU</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="random-effects.html"><a href="random-effects.html#starmathematical-foundations"><i class="fa fa-check"></i><b>7.4</b> <span class="math inline">\(^\star\)</span>Mathematical foundations</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="random-effects.html"><a href="random-effects.html#probability-refresher"><i class="fa fa-check"></i><b>7.4.1</b> Probability refresher</a></li>
<li class="chapter" data-level="7.4.2" data-path="random-effects.html"><a href="random-effects.html#application-to-models-with-random-effects"><i class="fa fa-check"></i><b>7.4.2</b> Application to models with random effects</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="blocked-designs.html"><a href="blocked-designs.html"><i class="fa fa-check"></i><b>8</b> Blocked designs</a>
<ul>
<li class="chapter" data-level="8.1" data-path="blocked-designs.html"><a href="blocked-designs.html#randomized-complete-block-designs"><i class="fa fa-check"></i><b>8.1</b> Randomized complete block designs</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="blocked-designs.html"><a href="blocked-designs.html#should-a-blocking-factor-be-a-fixed-or-random-effect"><i class="fa fa-check"></i><b>8.1.1</b> *Should a blocking factor be a fixed or random effect?</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="blocked-designs.html"><a href="blocked-designs.html#latin-squares-designs"><i class="fa fa-check"></i><b>8.2</b> Latin-squares designs</a></li>
<li class="chapter" data-level="8.3" data-path="blocked-designs.html"><a href="blocked-designs.html#split-plot-designs"><i class="fa fa-check"></i><b>8.3</b> Split-plot designs</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="blocked-designs.html"><a href="blocked-designs.html#satterthwaite-approximation"><i class="fa fa-check"></i><b>8.3.1</b> Satterthwaite approximation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i>Bibliography</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">ST 512 course notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="blocked-designs" class="section level1 hasAnchor" number="8">
<h1><span class="header-section-number">Chapter 8</span> Blocked designs<a href="blocked-designs.html#blocked-designs" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="randomized-complete-block-designs" class="section level2 hasAnchor" number="8.1">
<h2><span class="header-section-number">8.1</span> Randomized complete block designs<a href="blocked-designs.html#randomized-complete-block-designs" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The strength of people’s grip in their dominant or off-dominant hand was measured for <span class="math inline">\(n=145\)</span> people. Data are below, with strength measured in Newtons of force.
<img src="08-BlockedDesigns_files/figure-html/unnamed-chunk-2-1.png" width="480" style="display: block; margin: auto;" />
Suppose we wanted to use these data to ask if there was a difference in strength between people’s dominant and off-dominant hands. One (wrong) way to analyze these data is with a two-sample <span class="math inline">\(t\)</span>-test:</p>
<pre><code>&gt; with(grip, t.test(x = Dominant, y = Off, var.equal = TRUE))

Two Sample t-test

data:  Dominant and Off
t = 1.7844, df = 288, p-value = 0.07542
alternative hypothesis: true difference in means is not equal to 0

95 percent confidence interval:
-1.812768 36.998975

sample estimates:
mean of x mean of y 
298.6552  281.0621 </code></pre>
<p>The two-sample t-test is the wrong test for these data because it fails to account for the fact that the data are paired. The correct way to analyze these data is to calculate the difference in grip strength for each individual, and then to treat the sample of <span class="math inline">\(n=145\)</span> differences as a single random sample from a population of differences. We then test the null hypothesis that the average of this population of differences is equals 0 against the alternative that the average difference is different from 0.</p>
<pre><code>&gt; with(grip, t.test(x = Dominant - Off))

One Sample t-test

data:  Dominant - Off
t = 6.4883, df = 144, p-value = 1.306e-09
alternative hypothesis: true mean is not equal to 0

95 percent confidence interval:
12.23358 22.95263

sample estimates:
mean of x 
17.5931</code></pre>
<p>The paired analysis estimates the average difference in grip strength more precisely, resulting in a narrower CI and a smaller <span class="math inline">\(p\)</span>-value. The paired analysis is more precise because the experimental error has been reduced by removing person-to-person variability.</p>
<p>Taking differences only works when we are comparing two treatments. When we are comparing more than two treatments, we need a more general strategy. <em>Blocking</em> is a technique that reduces experimental error (and hence increases precision) by grouping heterogeneous experimental units into blocks of homogeneous EUs. Remember that statistical tests boil down to comparing the magnitude of the treatment effect to the precision with which that effect is estimated. We can’t do anything about the magnitude of the treatment effect — that’s set by nature. Blocking is a technique that increases statistical power by reducing experimental error and thus increasing precision.</p>
<p>The canonical example of blocking comes from agriculture. Suppose we want to compare the effects of 3 different fertilizers (call them A, B, and C) on crop yield. Suppose a field can be divided into 12 plots (EUs), and there is a known east-west elevation slope to the field. In a CRD, treatments are randomly assigned to EUs. CRDs are appropriate when EUs are homogeneous. Here, we know that there is a difference between EUs based on where they lie along the east-west gradient. Consequently, a better design is to block against slope by grouping EUs into blocks of plots at similar locations along the east-west gradient. Treatments are then randomly assigned within blocks.</p>
<!-- One such randomization might be: -->
<!-- \begin{center} -->
<!--    \begin{tabular}{|c|c|c|c|} -->
<!--        \hline C & C & B & A \\ \hline -->
<!--        A & B & A & C \\ \hline -->
<!--        B & A & C & B \\ \hline  -->
<!--        \end{tabular} -->
<!-- \end{center} -->
<p>This is a randomized complete block design (RCBD). A RCBD consists of <span class="math inline">\(q\)</span> blocks, each of which is divided into <span class="math inline">\(p\)</span> homogeneous EUs. Treatments are randomly assigned to EUs within each block. This is a “complete” block design because each level of the experimental treatment is represented at least once in every block. In contrast, an “incomplete” block design is one in which not all experimental treatments are represented in every block. A standard RCBD is one in which every treatment (or every treatment combination) is assigned to exactly one EU in each block.</p>
<p>The classical way to analyze data from an RCBD is to include the block as an additional factor in the ANOVA, albeit a factor that is not engaged in interactions with the treatment factors. Example: For the grip strength data, we would treat “subject” (the person) as a blocking factor.</p>
<div class="sourceCode" id="cb268"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb268-1"><a href="blocked-designs.html#cb268-1" aria-hidden="true" tabindex="-1"></a>grip <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="st">&quot;data/gripall-long.txt&quot;</span>, <span class="at">head =</span> T, <span class="at">stringsAsFactors =</span> T)</span>
<span id="cb268-2"><a href="blocked-designs.html#cb268-2" aria-hidden="true" tabindex="-1"></a>fm1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(strength <span class="sc">~</span> subject <span class="sc">+</span> hand, <span class="at">data =</span> grip)</span>
<span id="cb268-3"><a href="blocked-designs.html#cb268-3" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(fm1)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: strength
##            Df  Sum Sq Mean Sq F value    Pr(&gt;F)    
## subject   144 1952993   13562  25.443 &lt; 2.2e-16 ***
## hand        1   22440   22440  42.098 1.306e-09 ***
## Residuals 144   76758     533                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Observe that the <span class="math inline">\(p\)</span>-value for testing an effect of “hand” is exactly the same as the <span class="math inline">\(p\)</span>-value from the paired <span class="math inline">\(t\)</span>-test. This is not a coincidence. These are alternative ways of writing the same model.</p>
<p>Remarks:</p>
<ul>
<li><p>We have fit an additive model that does not include a person-by-hand interaction. In a RCBD, it is common to assume that there is no block-by-treatment interaction.</p></li>
<li><p>Typically we are not interested in the <span class="math inline">\(F\)</span>-test associated with the block effect. Even if the block effect is not significant, we do not remove it from the model. Doing so would be tantamount to treating the design as a CRD, which does not account for the restricted randomization.</p></li>
</ul>
<p>Here is an example of a standard RCBD with one experimental factor, described in the SAS documentation for PROC GLM: <span class="citation">Stenstrom (<a href="#ref-stenstrom40" role="doc-biblioref">1940</a>)</span> investigated how <span class="math inline">\(p = 7\)</span> soil types affect the growth of snapdragons. To control for local fertility variations, the soils were grouped into <span class="math inline">\(q = 3\)</span> blocks. Average stem length of the snapdragons in each EU was recorded. The data are:</p>
<pre><code>                Block
Type        A    B    C
Clarion  32.7 32.3 31.5 
Clinton  32.1 29.7 29.1 
Knox     35.7 35.9 33.1 
O&#39;Neill  36.0 34.2 31.2 
Compost  31.8 28.0 29.2 
Wabash   38.2 37.8 31.9 
Webster  32.5 31.1 29.7 </code></pre>
<p>Here is an analysis with PROC GLM:</p>
<pre><code>proc glm;
  class Block Type;
  model StemLength = Block Type;
  means Type / tukey;
run;

Dependent Variable: stemlength

                                        Sum of
Source                      DF         Squares     Mean Square    F Value    Pr &gt; F
Model                        8     142.1885714      17.7735714      10.80    0.0002
Error                       12      19.7428571       1.6452381
Corrected Total             20     161.9314286

Source                      DF     Type III SS     Mean Square    F Value    Pr &gt; F
blk                          2      39.0371429      19.5185714      11.86    0.0014
type                         6     103.1514286      17.1919048      10.45    0.0004

Tukey&#39;s Studentized Range (HSD) Test for StemLength

Alpha                                   0.05
Error Degrees of Freedom                  12
Error Mean Square                   1.645238
Critical Value of Studentized Range  4.94945
Minimum Significant Difference        3.6653

Means with the same letter are not significantly different.


   Tukey
 Grouping            Mean      N    Type

     A             35.967      3    Wabash
B    A             34.900      3    Knox
B    A    C        33.800      3    O&#39;Neill
B    D    C        32.167      3    Clarion
     D    C        31.100      3    Webster
     D    C        30.300      3    Clinton
     D             29.667      3    Compost</code></pre>
<p>Here is an example of a standard RCBD with a 2 <span class="math inline">\(\times\)</span> 2 factorial treatment structure, described in the on-line SAS documentation. The description of the data there reads: “The data, from Neter, Wasserman, and Kutner (1990, p. 941), are from an experiment examining the effects of codeine and acupuncture on post-operative dental pain in male subjects. Both treatment factors have two levels. The codeine levels are a codeine capsule or a sugar capsule. The acupuncture levels are two inactive acupuncture points or two active acupuncture points. There are four distinct treatment combinations due to the factorial treatment structure. The 32 subjects are assigned to eight blocks of four subjects each based on an assessment of pain tolerance.”</p>
<p>As with any factorial experiment, it is helpful to inspect an interaction plot of the treatment means first:
<img src="08-BlockedDesigns_files/figure-html/unnamed-chunk-4-1.png" width="480" style="display: block; margin: auto;" />
Here is how we might analyze these data with SAS PROC GLM:</p>
<pre><code>proc glm data=dental;
  class block codeine acupuncture;
  model relief = block codeine|acupuncture;
  means codeine acupuncture / tukey;
run;

                                        Sum of
Source                      DF         Squares     Mean Square    F Value    Pr &gt; F
Model                       10     11.33500000      1.13350000      78.37    &lt;.0001
Error                       21      0.30375000      0.01446429
Corrected Total             31     11.63875000

Source                      DF     Type III SS     Mean Square    F Value    Pr &gt; F
block                        7      5.59875000      0.79982143      55.30    &lt;.0001
codeine                      1      2.31125000      2.31125000     159.79    &lt;.0001
acupuncture                  1      3.38000000      3.38000000     233.68    &lt;.0001
codeine*acupuncture          1      0.04500000      0.04500000       3.11    0.0923

Tukey&#39;s Studentized Range (HSD) Test for relief
Minimum Significant Difference        0.0884

Means with the same letter are not significantly different.

Tukey grouping
           Mean      N    codeine
A       1.42500     16    trt
B       0.88750     16    placebo

Tukey grouping
           Mean      N    acupuncture
A       1.48125     16    yes
B       0.83125     16    no</code></pre>
<div id="should-a-blocking-factor-be-a-fixed-or-random-effect" class="section level3 hasAnchor" number="8.1.1">
<h3><span class="header-section-number">8.1.1</span> *Should a blocking factor be a fixed or random effect?<a href="blocked-designs.html#should-a-blocking-factor-be-a-fixed-or-random-effect" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Often, it makes sense to treat block effects as random effects. Block effects should be treated as fixed if one is interested in drawing inferences that pertain to the particular blocks included in the experiment. Block effects should be treated as random the blocks included in the experiment can be regarded as representative draws from a population of blocks, and one is interested in drawing inferences that extend to this population of blocks.</p>
<p>Let’s reconsider the snapdragon example that we used to illustrate a RCBD. Here is PROC MIXED code for these data, but now with the block treated as a random effect.</p>
<pre><code>proc mixed;
  class blk type;
  model stemlength = type;
  random blk;
  lsmeans type;
run;

Covariance Parameter Estimates

Cov Parm     Estimate
blk            2.5533
Residual       1.6452

Type 3 Tests of Fixed Effects

              Num     Den
Effect         DF      DF    F Value    Pr &gt; F
type            6      12      10.45    0.0004

Least Squares Means

                                 Standard
Effect    type       Estimate       Error      DF    t Value    Pr &gt; |t|
type      Clarion     32.1667      1.1830      12      27.19      &lt;.0001
type      Clinton     30.3000      1.1830      12      25.61      &lt;.0001
type      Compost     29.6667      1.1830      12      25.08      &lt;.0001
type      Knox        34.9000      1.1830      12      29.50      &lt;.0001
type      O&#39;Neill     33.8000      1.1830      12      28.57      &lt;.0001
type      Wabash      35.9667      1.1830      12      30.40      &lt;.0001
type      Webster     31.1000      1.1830      12      26.29      &lt;.0001</code></pre>
<p>Remarks:</p>
<ul>
<li><p>The Type III <span class="math inline">\(F\)</span>-tests for the differences among the soil types are the same in both analyses. This is true because the data are balanced. If the data are not balanced, treating the block as a random vs. fixed effect can have a small effect on the Type III <span class="math inline">\(F\)</span>-tests.</p></li>
<li><p>The standard error of the LSMEAN for each type is larger when we treat the block as a random effect. This makes sense, because if we want to expand our scope of inference to the population of blocks from which these blocks were selected (instead of restricting focus to these particular blocks), we incur a cost of greater uncertainty.</p></li>
<li><p>The model with block as a random effect is a mixed model, because it includes both a fixed effect (type) and a random effect (block). An equation for this model is
<span class="math display">\[
  y_{ij} = \mu + \alpha_i + B_j + \varepsilon_{ij}
  \]</span>
where <span class="math inline">\(\mu\)</span> is the reference level or intercept, <span class="math inline">\(\alpha_i\)</span> are the (fixed) effects parameters for the snapdragon type, <span class="math inline">\(B_j \sim \mathcal{N}\left(0, \sigma^2_B \right)\)</span> are the random block effects, and <span class="math inline">\(\varepsilon_{ij} \sim \mathcal{N}\left(0, \sigma^2_\varepsilon \right)\)</span> are the residual errors (also a random effect).</p></li>
</ul>
</div>
</div>
<div id="latin-squares-designs" class="section level2 hasAnchor" number="8.2">
<h2><span class="header-section-number">8.2</span> Latin-squares designs<a href="blocked-designs.html#latin-squares-designs" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Consider the fertilizer again, and suppose that in addition to an east-west slope, there is also a north-south gradient in soil pH. A Latin squares design is a double blocking design that blocks against both east-west and north-south directions.
<!-- \begin{center} -->
<!--    \begin{tabular}{|c|c|c|} -->
<!--        \hline C & B & A \\ \hline -->
<!--        B & A & C \\ \hline -->
<!--        A & C & B \\ \hline  -->
<!--    \end{tabular} -->
<!-- \end{center} -->
<!-- Note that each fertilizer treatment appears once in each row block and once in each column block.  (Much like a sudoku puzzle.)   --></p>
<p>To analyze these data, we need to include a separate factor in the ANOVA for each of the two blocking factors. Here is an example based on a real study.</p>
<p><span class="citation">Taniguchi, Huntington, and Glenn (<a href="#ref-taniguchi1995net" role="doc-biblioref">1995</a>)</span> studied the effects of infusion of casein (a protein) and cornstarch on net nutrient metabolism in beef steers. The investigators are interested in the effect of the location of the infusion (in the rumen vs. in the abomasum, both compartments of the ruminant stomach) for both the starch and the protein. The 4 unique treatment combinations are: starch and protein both delivered to the abomasum (henceforth treatment “A”), starch delivered to the abomasum and protein delivered to the rumen (treatment “B”), starch delivered to the rumen and protein delivered to the abomasum (treatment “C”), and starch and protein both delivered to the rumen (treatment “D”).</p>
<p>Four beef steer were available for the study. Each steer was given each treatment over the course of 4 two-week periods. During each period, the steers were given the infusions during days 1–11, and removed from the infusions during days 12–14. Nutrient metabolism was measured on days 8–11 of each period.</p>
<p>Thus, the data consist of a 2 <span class="math inline">\(\times\)</span> 2 factorial treatment structure with two blocking factors: steer and period. Treatments are assigned to each steer and period using a Latin squares design.</p>
<!-- Although we do not know the actual Latin squares design used, one possibility is: -->
<!-- \begin{center} -->
<!--    \begin{tabular}{|c|c|c|c|c|} -->
<!--        \hline & \multicolumn{4}{|c|}{Period} \\ \hline -->
<!--        Steer & 1 & 2 & 3 & 4 \\ \hline -->
<!--        W & A & B & C & D \\ \hline -->
<!--        X & C & D & A & B \\ \hline -->
<!--        Y & B & A & D & C \\ \hline -->
<!--        Z & D & C & B & A \\ \hline  -->
<!--    \end{tabular} -->
<!-- \end{center} -->
<!-- One of the response variables measured was apparently retained nitrogen, measured as a difference between nitrogen intake and nitrogen excretion.  The original data are unavailable, but one possible data set based on the observed results is  -->
<!-- \begin{center} -->
<!--    \begin{tabular}{|c|c|c|c|c|c|} -->
<!--        \hline & \multicolumn{4}{|c|}{Period} & \\ \hline -->
<!--        Steer & 1 & 2 & 3 & 4 & Mean\\ \hline -->
<!--        W & 94.5 & 93.2 & 101.2 & 102.4 & 97.8 \\ \hline -->
<!--        X & 117.7 & 120.6 & 108.8 & 109.8 & 114.2 \\ \hline -->
<!--        Y & 110.0 & 115.0 & 121.2 & 122.4 & 117.1 \\ \hline -->
<!--        Z & 109.4 & 111.9 & 98.0  & 104.9 & 106.1 \\ \hline  -->
<!--        Mean & 107.9 & 110.2 & 107.3 & 110.0 & 108.8 \\ \hline -->
<!--    \end{tabular} -->
<!-- \end{center} -->
<p>Here is an interaction plot of the treatment means:
<img src="08-BlockedDesigns_files/figure-html/unnamed-chunk-5-1.png" width="480" style="display: block; margin: auto;" />
Here is an analysis with PROC GLM:</p>
<pre><code>proc glm data=steer;
  class steer period starch protein;
  model nitrogen = starch|protein steer period;
run;

Dependent Variable: nitrogen

                                        Sum of
Source                      DF         Squares     Mean Square    F Value    Pr &gt; F
Model                        9     1278.855625      142.095069     166.72    &lt;.0001
Error                        6        5.113750        0.852292
Corrected Total             15     1283.969375

Source                      DF     Type III SS     Mean Square    F Value    Pr &gt; F
starch                       1     328.5156250     328.5156250     385.45    &lt;.0001
protein                      1       8.8506250       8.8506250      10.38    0.0181
starch*protein               1       9.7656250       9.7656250      11.46    0.0148
steer                        3     906.9968750     302.3322917     354.73    &lt;.0001
period                       3      24.7268750       8.2422917       9.67    0.0103</code></pre>
<p>The significant starch*protein interaction suggests that we should inspect the simple effects of the starch and protein treatments. The interaction plot above suggests that the effect of the protein location is small when starch is delivered to the rumen, but that the protein delivery site has a larger effect when starch is delivered to the abomasum.</p>
<p>As a remark, note that the model above has only 6 df available to estimate the experimental error. While blocked designs are powerful, block effects do tend to gobble up lots of df, leaving few df available to estimate the experimental error. This phenomenon is particularly pronounced in Latin squares designs.</p>
</div>
<div id="split-plot-designs" class="section level2 hasAnchor" number="8.3">
<h2><span class="header-section-number">8.3</span> Split-plot designs<a href="blocked-designs.html#split-plot-designs" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A split-plot experiment combines the ideas of blocking and subsampling in a clever way. The essential feature of a split-plot experiment is that there are at least two experimental factors, and the factors are randomized to different EUs. For example, consider a hypothetical
experiment to evaluate the effect of 3 bacterial inoculation treatments applied to 2 grass cultivars (A vs. B). The response variable is dry-weight yield. Eight fields are available for the experiment. Suppose that the different inoculation treatments can be applied to different regions of the same field, but it is impossible to plant different cultivars in the same field. Consequently, cultivars are randomly assigned to fields as a balanced CRD. Fields are then split into 3 thirds, and inoculation treatments are randomly assigned to each third. Dry weight yield is then measured from each third for a total of 24 data points. Here is an interaction plot of the means for each of the 6 treatment combinations:
<img src="08-BlockedDesigns_files/figure-html/unnamed-chunk-6-1.png" width="480" style="display: block; margin: auto;" />
In this experiment, the EU is different for the two experimental factors. For the cultivar treatment, the field is the EU, and the thirds are subsamples. For the bacterial inoculation treatment, however, the thirds are the EUs and the fields are blocks. Split-plot experiments are advantageous when it is more convenient to apply one factor or factors to large EUs and other factor(s) to smaller EUs. Split-plot experiments come with their own conventional terminology. In the example above, the cultivar is the <em>whole-plot</em> factor, and the fields are the whole-plot EU. The inoculation treatment is the <em>split-plot</em> factor, and the thirds are the split-plot EUs (subsamples of the whole-plot EUs).</p>
<p>Because the design contains two different EUs, the analysis must contain two error terms. The critical piece of the analysis is to make sure that the statistical inferences about the whole-plot factor are drawn using the whole-plot error, and conversely inferences about the split-plot factor are drawn using the split-plot error.</p>
<p>Here is an ANOVA model for this experiment:
<span class="math display">\[
y_{ijk} = \mu + \alpha_i + \beta_j + (\alpha \beta)_{ij} + W_{ik} + \varepsilon_{ijk}
\]</span>
where</p>
<ul>
<li><span class="math inline">\(i = 1, 2\)</span> is an index for the grass cultivars</li>
<li><span class="math inline">\(j = 1, 2, 3\)</span> is an index for the inoculation treatment</li>
<li><span class="math inline">\(k = 1, 2, \ldots, 4\)</span> is an index for the replicate fields assigned to each cultivar</li>
<li><span class="math inline">\(\mu\)</span> is a reference level</li>
<li><span class="math inline">\(\alpha_i\)</span>’s are the (fixed) effect parameters for cultvar <span class="math inline">\(i\)</span>, subject to the usual constraints</li>
<li><span class="math inline">\(\beta_j\)</span>’s are the (fixed) effect parameters for bacterial inoculation <span class="math inline">\(j\)</span>, subject to the usual constraints</li>
<li><span class="math inline">\((\alpha \beta)_{ij}\)</span>’s are the (fixed) effect parameters for the cultivar-by-inoculation interaction, subject to the usual constraints</li>
<li><span class="math inline">\(W_{ik}\)</span> is a random effect for the whole-plot error, <span class="math inline">\(W_{ik} \sim \mathcal{N}\left(0, \sigma^2_W \right)\)</span></li>
<li><span class="math inline">\(\varepsilon_{ijk}\)</span> is residual (split-plot) error, <span class="math inline">\(\varepsilon_{ijk} \sim \mathcal{N}\left(0, \sigma^2_{\varepsilon} \right)\)</span></li>
</ul>
<p>As before, we can conduct an ANOVA sum-of-squares decomposition that will lead to <span class="math inline">\(F\)</span>-tests of the factorial effects. We’ll prepare for this ANOVA by first partitioning the df among the various sums of squares. How do we partition the df?</p>
<ul>
<li>The random effect for the field will serve as the whole-plot error term. Because each field is associated with one and only one cultivar, then field is nested within cultivar.</li>
<li>The random effect for the third will serve as the split-plot error term. Because each third is associated with one and only one cultivar, with one and only one field, with one and only one inoculation treatment, and with one and only one cultivar-inoculation treatment combination, then the third is nested in all these other model terms.</li>
</ul>
The df for each term in the ANOVA will be:
<table>
<thead>
<tr>
<th style="text-align:left;">
source
</th>
<th style="text-align:left;">
df
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Cultivar
</td>
<td style="text-align:left;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
Whole-plot error
</td>
<td style="text-align:left;">
6 (=8 - 1 - 1)
</td>
</tr>
<tr>
<td style="text-align:left;">
Inocuolation
</td>
<td style="text-align:left;">
2
</td>
</tr>
<tr>
<td style="text-align:left;">
Cultivar*Inoculation
</td>
<td style="text-align:left;">
2
</td>
</tr>
<tr>
<td style="text-align:left;">
Residual error
</td>
<td style="text-align:left;">
12 (= 24 - 1 - 1 - 6 - 2 - 2)
</td>
</tr>
<tr>
<td style="text-align:left;">
Total
</td>
<td style="text-align:left;">
23
</td>
</tr>
</tbody>
</table>
<p>Because this model has multiple random effects, we’ll use PROC MIXED for our calculations. As before, we can use the METHOD = TYPE3 option to see the ANOVA table, but we’ll use METHOD = REML (the default) to obtain our estimates and F-tests of the fixed effects. (With a balanced data set, both the TYPE3 and REML methods of estimation will yield identical results.)</p>
<p>Here is the TYPE3 analysis first:</p>
<pre><code>proc mixed method = type3;
  class field cult inoc;
  model drywt = cult|inoc;
  random field(cult);
run;

                               Type 3 Analysis of Variance
                               
                           Sum of
Source           DF       Squares   Mean Square  Expected Mean Square
cult              1      2.406667      2.406667  Var(Residual) + 3 Var(field(cult))
                                                 + Q(cult,cult*inoc)
inoc              2    118.175833     59.087917  Var(Residual) + Q(inoc,cult*inoc)
cult*inoc         2      1.825833      0.912917  Var(Residual) + Q(cult*inoc)
field(cult)       6     34.800000      5.800000  Var(Residual) + 3 Var(field(cult))
Residual         12      8.465000      0.705417  Var(Residual)</code></pre>
<p>Note that we’ve coded the random-effect for the fields as FIELD(CULT), because field is nested within the cultivar treatment. Now, here is the REML analysis (the default):</p>
<pre><code>proc mixed;
  class field cult inoc;
  model drywt = cult|inoc;
  random field(cult);
run;

Covariance Parameter Estimates

Cov Parm        Estimate
field(cult)       1.6982
Residual          0.7054

Type 3 Tests of Fixed Effects

              Num     Den
Effect         DF      DF    F Value    Pr &gt; F
cult            1       6       0.41    0.5433
inoc            2      12      83.76    &lt;.0001
cult*inoc       2      12       1.29    0.3098</code></pre>
<p>We see that there is evidence of a difference among the inoculation treatments, but no evidence of an interaction between the inoculation treatments and the cultivar, and no evidence of a difference among the cultivars.</p>
<p>To explore the differences among the inoculation treatments, we’ll use an LSMEANS statement using Tukey’s HSD procedure:</p>
<pre><code>proc mixed;
  class field cult inoc;
  model drywt = cult|inoc / ddfm=satterth;
  random field(cult);
  lsmeans inoc / pdiff adjust=tukey;
run;

                         Least Squares Means
                         
                              Standard
Effect    inoc    Estimate       Error      DF    t Value    Pr &gt; |t|
inoc      con      27.9625      0.5481    9.01      51.01      &lt;.0001
inoc      dea      29.9500      0.5481    9.01      54.64      &lt;.0001
inoc      liv      33.3375      0.5481    9.01      60.82      &lt;.0001
                         
                         
                         Differences of Least Squares Means
                         
                               Standard
Effect  inoc  _inoc  Estimate     Error    DF  t Value  Pr &gt; |t|  Adjustment     Adj P
inoc    con   dea     -1.9875    0.4199    12    -4.73    0.0005  Tukey-Kramer  0.0013
inoc    con   liv     -5.3750    0.4199    12   -12.80    &lt;.0001  Tukey-Kramer  &lt;.0001
inoc    dea   liv     -3.3875    0.4199    12    -8.07    &lt;.0001  Tukey-Kramer  &lt;.0001</code></pre>
<p>Remarks:</p>
<ul>
<li>The DDFM = SATTERTH option tells SAS to calculate df using a Satterthwaite approximation. See below.</li>
<li>The LSMEANS statement calculates the average response for each inoculation treatment (the split-plot factor) averaging over the levels of the whole-plot factor, cultivar. The PDIFF option provides pairwise comparisons, and the ADJUST=TUKEY option adjusts these p-values for multiple comparisons.
\end{enumerate}
Analysis and interpretation: There is no evidence of an interaction between cultivar and inoculation treatment (<span class="math inline">\(F_{2,12} = 1.29\)</span>, <span class="math inline">\(p= 0.31\)</span>). There is no evidence of a main effect of cultivar (<span class="math inline">\(F_{1,6} = 0.41\)</span>, <span class="math inline">\(p= 0.54\)</span>). There is strong evidence of a main effect of inoculation treatment (<span class="math inline">\(F_{2,12} = 83.76\)</span>, <span class="math inline">\(p&lt;.0001\)</span>). Pairwise comparisons of LSMEANS suggest that all inoculation treatments are significantly different from one another. Variance component estimates suggest that the experimental error associated with the whole-plot is roughly twice as great as the experimental error associated with the split-plot (1.70 vs. 0.70).</li>
</ul>
<div id="satterthwaite-approximation" class="section level3 hasAnchor" number="8.3.1">
<h3><span class="header-section-number">8.3.1</span> Satterthwaite approximation<a href="blocked-designs.html#satterthwaite-approximation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Standard errors of the LSMEANS for the split-plot factor (here, inoculation treatment) are functions of both the whole-plot error and the split-plot error. Consequently, the df associated with these standard errors are intermediate between the df available for the whole-plot error (here, 6) and the df available for the split-plot error (12). The Satterthwaite approximation is a computationally intensive method for approximating the appropriate df. (It’s computationally intensive because it entails inverting a big matrix.) With big models or small computers, calculating the Satterthwaite approximation may not be feasible. See section 11.4 of Oehlert for a more detailed discussion of the Satterthwaite approximation.</p>
<p>You may have already encountered the Satterthwaite approximation in the context of Welch’s two-sample <span class="math inline">\(t\)</span>-test. (Recall that Welch’s two-sample <span class="math inline">\(t\)</span>-test can be used to compare the means of two samples when the variances of those two samples are not equal. In that context, the standard error of the difference between the means blends two different variance estimates, and thus the Satterthwaite approximation is needed to calculate the associated df. The key feature to both of these calculations is the presence of multiple variance estimates in the calculation of a standard error.)</p>

</div>
</div>
</div>
<h3>Bibliography<a href="bibliography.html#bibliography" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-stenstrom40" class="csl-entry">
Stenstrom, F. H. 1940. <span>“The Growth of Snapdragons, Stocks, Cinerarias, and Carnations on Six Iowa Soils.”</span> Master’s thesis, Iowa State College.
</div>
<div id="ref-taniguchi1995net" class="csl-entry">
Taniguchi, K, GB Huntington, and BP Glenn. 1995. <span>“Net Nutrient Flux by Visceral Tissues of Beef Steers Given Abomasal and Ruminal Infusions of Casein and Starch.”</span> <em>Journal of Animal Science</em> 73 (1): 236–49.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="random-effects.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bibliography.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
