<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>ST 512 course notes</title>
  <meta name="description" content="Course notes for ST 512, Statistical Methods for Researchers, taught at NCSU in Spring 2022." />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="ST 512 course notes" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Course notes for ST 512, Statistical Methods for Researchers, taught at NCSU in Spring 2022." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="ST 512 course notes" />
  
  <meta name="twitter:description" content="Course notes for ST 512, Statistical Methods for Researchers, taught at NCSU in Spring 2022." />
  

<meta name="author" content="Kevin Gross" />


<meta name="date" content="2022-01-12" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  


<script src="libs/header-attrs-2.9/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path=""><a href="#simple-linear-regression"><i class="fa fa-check"></i><b>1</b> Simple linear regression</a>
<ul>
<li class="chapter" data-level="1.1" data-path=""><a href="#introduction-to-simple-linear-regression"><i class="fa fa-check"></i><b>1.1</b> Introduction to simple linear regression</a></li>
<li class="chapter" data-level="1.2" data-path=""><a href="#least-squares-estimation"><i class="fa fa-check"></i><b>1.2</b> Least-squares estimation</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path=""><a href="#sidebar-on-degrees-of-freedom"><i class="fa fa-check"></i><b>1.2.1</b> Sidebar on degrees of freedom</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path=""><a href="#inference-for-the-slope"><i class="fa fa-check"></i><b>1.3</b> Inference for the slope</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path=""><a href="#standard-errors"><i class="fa fa-check"></i><b>1.3.1</b> Standard errors</a></li>
<li class="chapter" data-level="1.3.2" data-path=""><a href="#confidence-intervals"><i class="fa fa-check"></i><b>1.3.2</b> Confidence intervals</a></li>
<li class="chapter" data-level="1.3.3" data-path=""><a href="#statistical-hypothesis-tests"><i class="fa fa-check"></i><b>1.3.3</b> Statistical hypothesis tests</a></li>
<li class="chapter" data-level="1.3.4" data-path=""><a href="#inference-for-the-intercept"><i class="fa fa-check"></i><b>1.3.4</b> Inference for the intercept</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">ST 512 course notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="header">
<h1 class="title">ST 512 course notes</h1>
<p class="author"><em>Kevin Gross</em></p>
<p class="date" style="margin-top: 1.5em;"><em>2022-01-12</em></p>
</div>
<div id="simple-linear-regression" class="section level1" number="1">
<h1><span class="header-section-number">Chapter 1</span> Simple linear regression</h1>
<div id="introduction-to-simple-linear-regression" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> Introduction to simple linear regression</h2>
<p>Linear regression is a versatile statistical tool that can be used to characterize relationships between quantitative variables. We will study linear regression in depth, and begin with a simple example.</p>
<p><em>Example</em>: Blood alcohol content (BAC) vs. number of beers consumed. Data were obtained for <span class="math inline">\(n=16\)</span> individuals. Here is a scatter plot of the data:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>beer <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="st">&quot;data/beer.txt&quot;</span>, <span class="at">head =</span> T)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">with</span>(beer, <span class="fu">plot</span>(BAC <span class="sc">~</span> Beers, <span class="at">xlab =</span> <span class="st">&quot;beers consumed&quot;</span>))</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-2"></span>
<img src="index_files/figure-html/unnamed-chunk-2-1.png" alt="BAC vs. beers consumed." width="384" />
<p class="caption">
Figure 1.1: BAC vs. beers consumed.
</p>
</div>
<p>We seek to quantify the relationship between beers and BAC in these data by fitting a statistical model. A statistical model is a mathematical description of the relationship between the sample data and the population from which it was drawn. Because samples are collected randomly, statistical models are written using the mathematics of probability. Statistical models can be thought of as consisting of two parts: a signal or mean component that quantifies the patterns in the data that are repeatable from one sample to the next, and the error or noise component that captures the variation in the data unique to a given sample. In words, then, we might represent a statistical model using the equation “data = signal + error.” The plus sign in this word equation should not be taken too literally, because the signal and error are not always combined in an additive way. Statistical models can be written in words or in mathematical notation. Word models are helpful for building understanding, but they are somewhat ambiguous and are not as mathematically precise as we need. Consequently, we’ll use word models to build intuition, and mathematical notation for precision.</p>
<p>A <em>simple linear regression</em> (SLR) is a simple statistical model for these data. In words, we can write an SLR model for these data as
<span class="math display">\[
\mbox{BAC = intercept + slope} \times \mbox{beers + error}
\]</span>
In notation, the model is
<span class="math display" id="eq:slr">\[\begin{equation}
y_i =\beta_0 +\beta_1 x_i +\varepsilon_i \tag{1.1}
\end{equation}\]</span></p>
<p>The components of this model are:</p>
<ul>
<li><p><span class="math inline">\(y\)</span>: the “response” or “dependent” variable. Here, the response is BAC. By convention, the response variable is usually written on the left of the equals sign. The <em>i</em> subscript is used to distinguish among individual data points. For example, <span class="math inline">\(y_1\)</span> is the value of the response associated with the first observation in the data set. Usually, we use the notation <span class="math inline">\(n\)</span> for the total number of data points, and so to be precise we might also write <span class="math inline">\(i = 1, \ldots, n\)</span>. In words, we say that “<span class="math inline">\(i\)</span> varies from 1 to <span class="math inline">\(n\)</span>” or “<span class="math inline">\(i\)</span> ranges from 1 to <span class="math inline">\(n\)</span>.” We’ll suppress the <span class="math inline">\(i\)</span> subscript when we don’t need it.</p></li>
<li><p><span class="math inline">\(x\)</span>: the “predictor” or “independent” variable. Here, the predictor is the number of beers consumed.</p></li>
<li><p><span class="math inline">\(\beta_0\)</span>: intercept. In SLR, the intercept is a parameter that gives the value of the regression line when the predictor <span class="math inline">\(x = 0\)</span>. Sometimes this is a meaningful quantity, and other times it isn’t.</p></li>
<li><p><span class="math inline">\(\beta_1\)</span>: slope. In SLR, the slope is a parameter tells us by how much regression line rises or falls as the predictor changes. Positive values of the slope indicate that the regression line increases as the predictor increases, and negative values of the slope indicate that the regression line decreases as the predictor increases.</p></li>
<li><p><span class="math inline">\(\varepsilon\)</span>: error. The error term is a catch-all that subsumes all the other factors that might influence the response that are not included in the predictors. In the context of the BAC example, these might include body weight, metabolism, and/or alcohol content of the beer (if it differed among subjects).</p></li>
</ul>
<p>Although they look similar, it is important to realize that <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, and <span class="math inline">\(\varepsilon\)</span> are different beasts. The quantities <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are parameters. Recall that in statistics, <em>parameters</em> are quantities that characterize a population. We assume that true values of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> exist; those values are just unknown to us. We will estimate these parameters and draw inferences about their values on the basis of data.</p>
<p>In contrast, the error term <span class="math inline">\(\varepsilon\)</span> is a random variable. It does not have one single value, but instead takes a different value for every member of a population. We describe the distribution of the errors across the members of the population using a probability distribution. In simple linear regression, we assume that the random errors have a normal (or bell-shaped) distribution with mean 0 and variance $_{}^{2} $. We also assume that the random errors are independent among individuals in our sample. A succinct way of stating this is to state that the errors are normal and “independent and identically distributed” (abbreviated “iid”). In notation, we write <span class="math inline">\(\varepsilon_{i} \sim \mathcal{N}\left(0, \sigma_{\varepsilon }^2 \right)\)</span>.</p>
<!-- Need to add iid over squiggle above. -->
<p>Thus, individual error terms are not parameters. However, the error variance <span class="math inline">\(\sigma_{\varepsilon }^2\)</span> is a parameter, and it measure of the variability in the response that is not explained by the predictor. We will also discuss how to estimate <span class="math inline">\(\sigma_{\varepsilon }^2\)</span>. (It is also possible to draw statistical inferences for <span class="math inline">\(\sigma_{\varepsilon }^2\)</span>, although we will not discuss how to do so in ST512.)</p>
<p>Another way to think of the SLR model is this. Consider a single value of the predictor <span class="math inline">\(x\)</span>. For the subset of individuals in the population that possess that particular value of <span class="math inline">\(x\)</span>, the population of responses (for that subset) has a normal (bell-shaped, or Gaussian) distribution with mean <span class="math inline">\(\beta_0 +\beta_1 x_i\)</span> and variance <span class="math inline">\(\sigma_{\varepsilon }^2\)</span>. Thus, when we consider all possible values of the predictor, the SLR model describes a family of normally distributed responses, with the mean of that normal distribution changing linearly as a function of the predictor.</p>
<p>A note on terminology: the “simple” in simple linear regression refers to the fact that there is only one independent variable. Models with more than one predictor, which we will study later, are referred to as multiple linear regression models.</p>
</div>
<div id="least-squares-estimation" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span> Least-squares estimation</h2>
<p>The parameters of an SLR model are estimated by fitting a least-squares line to the data. That is to say, we find the values of the parameters that minimize the sum of the squared differences between the data points themselves and the line. The estimates are denoted by “hats,” i.e., <span class="math inline">\(\widehat{\beta_0}\)</span> is the estimate of <span class="math inline">\(\beta_0\)</span>. Other authors use <span class="math inline">\(b\)</span>’s instead of <span class="math inline">\(\widehat{\beta}\)</span>’s for parameter estimates in regression. Both types of notation commonly appear in the scientific literature.</p>
<p>In ST511 or a similar course, you may have derived formulas for calculating the least-squares estimates <span class="math inline">\(\widehat{\beta_1}\)</span> and <span class="math inline">\(\widehat{\beta_1}\)</span> by hand. In ST512, we will use a computer (although it is worth noting that one could derive the formulas for <span class="math inline">\(\widehat{\beta_0}\)</span> and <span class="math inline">\(\widehat{\beta_1}\)</span> by using basic calculus tools to minimize the error sum-of squares). We’ll defer a discussion of how to use R until a later section of the notes. For now, we’ll observe that the least-squares estimates of the intercept and slope for the BAC data are <span class="math inline">\(\widehat{\beta_0} = -0.013\)</span> and <span class="math inline">\(\widehat{\beta_1} = 0.018\)</span>. Here’s a picture of the scatter-plot with the least-squares line:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>fm1 <span class="ot">&lt;-</span> <span class="fu">with</span>(beer, <span class="fu">lm</span>(BAC <span class="sc">~</span> Beers))</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="fu">with</span>(beer, <span class="fu">plot</span>(BAC <span class="sc">~</span> Beers, <span class="at">xlab =</span> <span class="st">&quot;beers consumed&quot;</span>))</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(fm1)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-3"></span>
<img src="index_files/figure-html/unnamed-chunk-3-1.png" alt="SLR fit of BAC vs. beers consumed." width="384" />
<p class="caption">
Figure 1.2: SLR fit of BAC vs. beers consumed.
</p>
</div>
<p>Thus, the best fitting line predicts a positive relationship between BAC and beers consumed. More precisely, it tells us that (on average) BAC increases by 0.018 for every additional beer consumed. This estimate for the slope is a start, but we’ll want to go further and try to use this estimate to draw statistical inferences.</p>
<p>A note on terminology: It is conventional to refer to a regression model as a regression of the response on, versus, or against the predictor. That is, the model above could be described as a regression of BAC on the number of beers consumed, or alternatively as a regression of BAC against the number of beers consumed.</p>
<p>Evaluating the fitted regression line for a given value of the predictor generates a <em>fitted value</em> for each data point. Fitted values are denoted <span class="math inline">\(\widehat{y_i}\)</span>. In notation, $ =  +  x_i $. Again, the <span class="math inline">\(i\)</span> subscript is used to distinguish the individual observations.</p>
<p>Why did the error term vanish in the equation for <span class="math inline">\(\widehat{y_i}\)</span>?</p>
<p>The <em>residual</em> for observation <span class="math inline">\(i\)</span>, denoted <span class="math inline">\(e_i\)</span>, is the difference between the actual observation and the fitted value. In notation, <span class="math inline">\(e_i = y_i -\widehat{y_i}\)</span>. In terms of the data plot, the residuals can be thought of as the vertical differences between the actual data points and the fitted line. In the figure below, the vertical line represents the residual for the individual who consumed 9 beers.</p>
<p><img src="index_files/figure-html/unnamed-chunk-4-1.png" width="384" style="display: block; margin: auto;" /></p>
<p><em>Example</em>: The first individual in the data set drank <span class="math inline">\(x_1 = 5\)</span> beers and had a BAC of <span class="math inline">\(y_1 = 0.1\)</span>. Find <span class="math inline">\(\widehat{y_1}\)</span> and <span class="math inline">\(e_1\)</span>. Answer: <span class="math inline">\(\widehat{y_1} = 0.077\)</span>, <span class="math inline">\(e_1 = 0.023\)</span>.</p>
<p>The <em>error sum of squares</em> (SSE) is
<span class="math display">\[
SSE = \sum_{i=1}^{n} e_i^{2} = \sum_{i=1}^{n} \left(y_{i} - \widehat{y_i} \right)^{2}. 
\]</span>
The SSE is a measure of the unexplained variability in the data. The least squares estimates, <span class="math inline">\(\widehat{\beta_0}\)</span> and <span class="math inline">\(\widehat{\beta_1}\)</span>, are called the least squares estimates because they minimize the SSE.</p>
<p>We can use the SSE to find an estimate of the error variance parameter by using the formula
<span class="math display">\[
\widehat{\sigma}_\varepsilon^2 = s_\varepsilon^2 = \dfrac{SSE}{n-2} = MSE
\]</span>
The above is also known as the <em>mean squared error</em> (MSE).</p>
<p>Actually, it is more common to talk about the error standard deviation, <span class="math inline">\(\sigma _{\varepsilon}\)</span>, which is estimated by the residual standard deviation <span class="math inline">\(s_{\varepsilon}\)</span>:
<span class="math display">\[
s_{\varepsilon} =\sqrt{\dfrac{SSE}{n-2}} = \sqrt{MSE} 
\]</span>
Note that we divide by <span class="math inline">\(n - 2\)</span> because there are <span class="math inline">\(n - 2\)</span> degrees of freedom (df) associated with the SSE. For the BAC data, <span class="math inline">\(s_{\varepsilon} = 0.020\)</span>.</p>
<div id="sidebar-on-degrees-of-freedom" class="section level3" number="1.2.1">
<h3><span class="header-section-number">1.2.1</span> Sidebar on degrees of freedom</h3>
<p>Degrees of freedom are associated with variance estimates in statistical models. We will spend quite a bit of effort in ST512 keeping track of degrees of freedom, so it’s helpful to understand this concept well. We’ll look carefully at df in the simple case of SLR to build intuition that will carry over into more complicated models.</p>
<p>Most error terms, like the SLR error variance <span class="math inline">\(\sigma_\varepsilon^2\)</span>, are estimated by sums of squares. The concept of degrees of freedom quantifies how many `free differences’ are available to compute a sum of squares.</p>
<p>Consider the following thought experiment. Suppose that, bizarrely, we knew the values of the parameters <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> in an SLR, and only needed to estimate the error variance <span class="math inline">\(\sigma_\varepsilon^2\)</span>. We could do so using the sum of squares <span class="math inline">\(\sum_{i=1}^{n}\left(y_{i} -\left[\beta_0 +\beta_1 x_i \right]\right)^2\)</span>. In this case, each of our <span class="math inline">\(n\)</span> data points would contribute a `free difference’ to the summation above, and so there would be <span class="math inline">\(n\)</span> free differences with which we could estimate the error variance <span class="math inline">\(\sigma_\varepsilon^2\)</span>.</p>
<p>However, we are almost never know the values of the <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> in advance. Instead, we have to use the data to estimate both <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>. Now, because we have to estimate both <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, there are only <span class="math inline">\(n - 2\)</span> free differences in the sum of squares <span class="math inline">\(\sum_{i=1}^{n}\left(y_{i} -\left[\widehat{\beta_0} +\widehat{\beta_1} x_i \right]\right)^{2}\)</span>. One way to visualize this is to imagine fitting a line to a data set with only <span class="math inline">\(n = 2\)</span> data points (with different <span class="math inline">\(x\)</span> values). The line would be guaranteed to pass through both points, and consequently both residuals would equal 0. Because both residuals equal 0, the SSE would also equal 0. However, the SSE doesn’t equal 0 because the actual value of <span class="math inline">\(\sigma_\varepsilon^2\)</span> equals 0. Instead, the SSE equals 0 because there is no information remaining to estimate the residual variance.</p>
<p>In general, when we have to use the same data set to estimate the parameters of the signal component  to estimate a variance parameter, then each parameter that we have to estimate in the mean component eliminates a free difference from the sum of squares <span class="math inline">\(\sum_{i=1}^{n}\left(y_{i} -\hat{y}_{i} \right)^{2}\)</span>. To convert the sum of squares into an estimate of an error variance, we need to count the number of free differences (or degrees of freedom) correctly, and divide the sum of squares by the appropriate number of df to make sure we get a valid variance estimate.</p>
<p>[end sidebar on df]</p>
<p>Some additional notation: In general, we’ll use the notation <span class="math inline">\(\mu \left(x\right)\)</span> to denote the signal or mean component of the model. In simple linear regression, the mean is simply a linear function of the predictor: <span class="math inline">\(\mu \left(x\right) = \beta_0 +\beta_1 x\)</span>. Although the notation <span class="math inline">\(\mu \left(x\right)\)</span> might seem like overkill for SLR, it will prove handy for more complicated models.</p>
</div>
</div>
<div id="inference-for-the-slope" class="section level2" number="1.3">
<h2><span class="header-section-number">1.3</span> Inference for the slope</h2>
<p>To draw statistical inferences about the slope parameter <span class="math inline">\(\beta_1\)</span>, we make the following assumptions:</p>
<ol style="list-style-type: decimal">
<li><p>Linearity: The population mean <span class="math inline">\(\mu \left(x\right)\)</span> is a linear function of <span class="math inline">\(x\)</span>.</p></li>
<li><p>Equal variance (“homoscedasticity”): The variance of the error terms (the <span class="math inline">\(\varepsilon_i\)</span>’s) is the same for all observations.</p></li>
<li><p>Independence: The error terms are independent of one another.</p></li>
<li><p>Normality. The errors have a normal (i.e., bell-shaped, or Gaussian) distribution.</p></li>
<li><p>The predictors are measured without error.</p></li>
</ol>
<p>This fifth assumption is usually not listed as one of the assumptions in SLR, but it is useful to keep in mind. The predictor and the response are <em>not</em> placed on equal footing. Note that assumption number 1 deals with the mean component of the model, while assumptions 2–4 deal with the error component of the model.</p>
<div id="standard-errors" class="section level3" number="1.3.1">
<h3><span class="header-section-number">1.3.1</span> Standard errors</h3>
<p>As intelligent scientists, we realize that estimates are not exactly equal to the parameters that they seek to estimate. We can characterize the uncertainty in parameter estimates in different ways. One tool that we have for quantifying uncertainty in parameter estimates is to calculate a standard error. In general, a <em>standard error</em> quantifies the variability in an estimate that is attributable to random sampling. Most parameter estimates that we will encounter have known formulas for their standard errors. In most cases, these formulas are complicated, and we will rely on computers to calculate standard errors for us. However, the formula for the standard error of the slope parameter in SLR is interesting to examine because it contains a valuable insight that we can use when collecting data for a regression study. The standard error of $ $, denoted <span class="math inline">\(s_{\widehat{\beta_1}}\)</span>, is given by the formula
<span class="math display">\[
s_{\widehat{\beta_1}} = \dfrac{s_{\varepsilon}}{\sqrt{S_{xx} } } 
\]</span>
where $S_{xx} =<em>{i}(x</em>{i} -{x})^2 $ quantifies the dispersion in the predictor variables.</p>
<p>Although this formula looks a bit daunting, there’s some intuition to be gained here, and a lesson for experimental design. Suppose we had designed a regression experiment in which all of the individuals were assigned similar values of the predictor. In this case, <span class="math inline">\(S_{xx}\)</span> would be small, and consequently the standard error <span class="math inline">\(s_{\widehat{\beta_1}}\)</span> would be large. Conversely, if the values of the predictor were very different among individuals in the study, then <span class="math inline">\(S_{xx}\)</span> would be large and the standard error <span class="math inline">\(s_{\widehat{\beta_1}}\)</span> would be small. Thus, if we want a precise estimate of the slope, we should choose predictor values that span the range over which we want to learn.</p>
<p>Thought question: Following this line of reasoning, is it a good idea to design a study so that half the individuals are assigned a very large value of the predictor, and the other half are assigned a very small value? Why or why not?</p>
<p>For the BAC example, <span class="math inline">\(s_{\widehat{\beta_1}} = 0.0024\)</span>.</p>
</div>
<div id="confidence-intervals" class="section level3" number="1.3.2">
<h3><span class="header-section-number">1.3.2</span> Confidence intervals</h3>
<p>A second way in which we can measure the uncertainty in a parameter estimate is to calculate a confidence interval (CI). Recall that the general formula for a confidence interval associated with a statistic is:
<span class="math display">\[
\mathrm{estimate} \pm  \mathrm{critical\ value} \times \mathrm{standard\ error}
\]</span>
Critical values are found either by consulting a table (and re-living the good old days) or using the internet or a computer program. Critical values depend on the {} that you want to associate with the CI. Although it seems a bit backwards, we typically denote the confidence level of a CI as <span class="math inline">\(100 \times \left(1-\alpha \right)\%\)</span>. Thus, for a 95% confidence interval (a common choice), <span class="math inline">\(\alpha = 0.05\)</span>. Alternatively, we might seek a 99% CI, in which case <span class="math inline">\(\alpha = 0.01\)</span>.</p>
<p>To construct a CI for <span class="math inline">\(\beta_1\)</span> , we find the appropriate critical values from a <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n - 2\)</span> df. For a <span class="math inline">\(100\times \left(1-\alpha \right)\%\)</span> CI, the critical value is the value that ``cuts-off’’ an upper tail of <span class="math inline">\(\alpha / 2\)</span> %. For example, to calculate a 99% CI for $_{1} $, we need to find the critical value of a <span class="math inline">\(t\)</span>-distribution with 14 df that cuts-off an upper 0.5%-tail. Using an online calculator, or another tool, we find that this critical value is 2.977. Thus, a 99% CI is 0.018 <span class="math inline">\(\pm\)</span> 2.977 <span class="math inline">\(\times\)</span> 0.0024 = (0.011, 0.025).</p>
<p>Recall that the appropriate interpretation of the confidence level a CI is fairly tricky. A proper interpretation is that, if we were to repeat this experiment a large number of times, and calculate a 99% CI for each experiment, in the long run 99% of those CIs would contain the true value of <span class="math inline">\(\beta_1\)</span>. Of course, in real life, we’ll only do the experiment once, and we don’t know if our experiment is one of the 99% in which the CI contains the true parameter value or not. It is often tempting to abbreviate this interpretation by saying that ``there is a 99% chance that <span class="math inline">\(\beta_1\)</span> is in the CI’’, although technically this interpretation is incorrect (because any single CI either contains the parameter or it doesn’t).</p>
<p>Note also that there is a trade-off between the confidence level and the width of the interval. If we wanted greater confidence that our interval contained the true parameter value, we could increase the confidence level. However, increasing the confidence level increases the width of the interval, and thus provides less information about the true parameter value in some sense. If we follow this argument to its (il)logical extreme, a 100% CI for <span class="math inline">\(\beta_1\)</span> covers the interval from negative infinity to positive infinity. Now we are fully confident that our interval contains <span class="math inline">\(\beta_1\)</span>, but at the cost of having no information whatsoever about the actual value of <span class="math inline">\(\beta_1\)</span>.</p>
</div>
<div id="statistical-hypothesis-tests" class="section level3" number="1.3.3">
<h3><span class="header-section-number">1.3.3</span> Statistical hypothesis tests</h3>
<p>Finally, a third way to characterize the statistical uncertainty in $ $ is to conduct a statistical hypothesis test. Recall that statistical hypotheses are statements about the values of unknown parameters, and a statistical hypothesis test is a way to measure the strength of evidence against a `null hypothesis’. In the context of SLR, we are almost always interested in testing the null hypothesis that the true value of the slope parameter is equal to zero. In notation, we write this as <span class="math inline">\(H_0: \beta_1 = 0\)</span>. Evidence against this null hypothesis is taken as evidence that the predictor is linearly related to the response.</p>
<p>Recall that in statistical hypothesis testing, we must also specify an alternative hypothesis. In SLR, we are almost always interested in testing <span class="math inline">\(H_0: \beta_1 = 0\)</span> vs. the two-sided alternative <span class="math inline">\(H_a: \beta_1 \ne 0\)</span>. We conduct a statistical hypothesis test by first calculating a test statistic. In general, formulas for test statistics take the form:
</p>
<p>Test statistics have the property that if the null hypothesis is true, then the test statistic has a known sampling distribution. In the case of testing <span class="math inline">\(H_0: \beta_1 = 0\)</span> vs. <span class="math inline">\(H_a: \beta_1 \ne 0\)</span> in SLR, if the null hypothesis is true, then the test statistic will have a <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-2\)</span> df. In notation, the test statistic is

In SLR, this test is so common that the value of the <span class="math inline">\(t\)</span>-statistic is provided automatically by most statistical software packages, including R. For the BAC data, the <span class="math inline">\(t\)</span>-statistic associated with the test of <span class="math inline">\(H_0: \beta_1 = 0\)</span> vs. <span class="math inline">\(H_a: \beta_1 \ne 0\)</span> is <span class="math inline">\(t = 7.48\)</span>.</p>
<p>Values of the test statistic by themselves are not terribly enlightening. Instead, we use the test statistic to find a <span class="math inline">\(p\)</span>-value. <span class="math inline">\(P\)</span>-values are famously difficult to interpret, and those difficulties in interpretation have impeded their proper use. In 2016, a blue-ribbon panel of experts were convened by the American Statistical Association (the leading professional organization for statisticians in the US) to take the remarkable step of issuing a policy statement regarding the use of <span class="math inline">\(p\)</span>-values. That statement (Wasserstein &amp; Lazar, 2016,  70:129-133) defines a <span class="math inline">\(p\)</span>-value as follows: ``Informally, a <span class="math inline">\(p\)</span>-value is the probability under a specified statistical model that a statistical summary of the data (e.g., the sample mean difference between two compared groups) would be equal to or more extreme than its observed value.’’
(Bear in mind that this definition is the work of two dozen of the world’s leading statisticians.)</p>
<p>In the context of the test of <span class="math inline">\(H_0: \beta_1 = 0\)</span> vs. <span class="math inline">\(H_a: \beta_1 \ne 0\)</span> in SLR, this means finding the probability that a <span class="math inline">\(t\)</span>-statistic with <span class="math inline">\(n-2\)</span> df is at least as different from zero as the value observed. For a two-sided alternative hypothesis, we say ``different from zero’’ because the sign (positive vs. negative) of the <span class="math inline">\(t\)</span>-statistic is irrelevant. Be careful, though: for a one-sided alternative hypothesis, the sign of the observed <span class="math inline">\(t\)</span>-statistic is critical!</p>
<p>For the BAC data, we find the area under the tail of a <span class="math inline">\(t\)</span>-distribution with 14 df that is greater than 7.48, and then (because the <span class="math inline">\(t\)</span>-distribution is symmetric) multiply by 2. That is,
<span class="math display">\[\begin{align*}
p &amp; = \Pr{ t_{14} &lt; -7.48} +\Pr{ t_{14} &gt; 7.48}  \\ 
  &amp; = 2 \times \Pr{ t_{14} &gt;7.48  } \\
  &amp; = 3\times 10^{-6}  
\end{align*}\]</span>
Thus, there is exceedingly strong evidence that BAC is related to the number of beers consumed.</p>
<p>The values above could be found by consulting a table, or by using statistical software such as R. Because the test of <span class="math inline">\(H_0: \beta_1 = 0\)</span> vs. <span class="math inline">\(H_a: \beta_1 \ne 0\)</span> is sufficiently common in SLR, most computer packages will do this calculation for us.</p>
<p>We’ll sweep a lot of acrimonious debate about statistical hypothesis testing under the rug and simply say that some scientists like to make a decision about whether or not to “reject” the null hypothesis. Although R.A. Fisher (a founding father of statistics) would roll over in his grave if he heard us saying this, most scientists make these “reject” or “do not reject” decisions by comparing the <span class="math inline">\(p\)</span>-value to the test’s {}, which is usually denoted by the Greek letter <span class="math inline">\(\alpha\)</span>. The significance level of a test is the frequency with which one would erroneously reject a true null hypothesis; you might also think of it as the allowable false-positive rate. Consequently, tests with smaller significance levels require more evidence against the null to reject it (this sounds backwards at first, but makes sense when you think about it). Most scientists conventionally make reject / do not reject decisions with a significance level of <span class="math inline">\(\alpha = .05\)</span>, but you are free to use whatever significance level you deem appropriate. If <span class="math inline">\(p \le \alpha\)</span>, we reject the null hypothesis; otherwise, we fail to reject it. (Remember that we never `accept’ the null hypothesis. We only fail to reject it.)</p>
<p>Although it is rare, we can also entertain so-called ‘one-sided’ alternative hypotheses. For example, suppose that we were uninterested in the (somewhat nonsensical) possibility that the numbers of beers consumed decreased BAC, and only were interested in measuring the evidence that the numbers of beers consumed increases BAC. To do so, we might test the same null hypothesis <span class="math inline">\(H_0: \beta_1 = 0\)</span> vs. the one-sided alternative <span class="math inline">\(H_a: \beta_1 &gt; 0\)</span>. To conduct this test, the test statistic is still

However, because the alternative hypothesis is one-sided, to calculate a <span class="math inline">\(p\)</span>-value, we interpret ``equal to or more extreme than its observed value" as the probability of observing a test statistic  than 7.48, i.e.,

We would then reject <span class="math inline">\(H_0: \beta_1 = 0\)</span> in favor of the one-sided alternative <span class="math inline">\(H_a: \beta_1 &gt; 0\)</span> at the <span class="math inline">\(\alpha = .05\)</span> significance level.</p>
<p>Finally, although it doesn’t make much sense in terms of what we know about alcohol, we could consider testing <span class="math inline">\(H_0: \beta_1 = 0\)</span> vs. the one-sided alternative <span class="math inline">\(H_a: \beta_1 &lt; 0\)</span>. Again, the test statistic is the same (<span class="math inline">\(t\)</span> = 7.48), but now evidence against the null and in favor of the alternative is provided by negative values of the test statistic, so the p-value is the probability of observing a test statistic  than 7.48, i.e.,<br />

Thus, there is no evidence that would allow us to reject <span class="math inline">\(H_0: \beta_1 = 0\)</span> in favor of the one-sided alternative <span class="math inline">\(H_a: \beta_1 &lt; 0\)</span>.</p>
<p>One final note: Although it is rarely done, there is no reason why we must restrict ourselves to testing <span class="math inline">\(H_0: \beta_1 = 0\)</span>. We could in fact test any null hypothesis. For example, suppose conventional wisdom held that each additional beer consumed increased BAC by 0.02, and we were interested in asking if these data contain evidence that the conventional wisdom is false. Then we could test <span class="math inline">\(H_0: \beta_1 = 0.02\)</span> vs. <span class="math inline">\(H_a: \beta_1 \ne 0.02\)</span>, although we have to calculate the test statistic and <span class="math inline">\(p\)</span>-value manually instead of relying on computer output:
<span class="math display">\[\begin{align*}
t &amp; = &amp; \dfrac{\widehat{\beta_1} -0.02}{s_{\widehat{\beta_1} }} = \dfrac{0.0180-0.02}{0.0024} =-0.83 \\ 
p &amp; = &amp; \Pr{t_{14} &lt;-0.83} +\Pr{t_{14} &gt;0.83} = 2 \times \Pr{ t_{14} &gt;0.83} =  0.421. 
\end{align*}\]</span>
Thus, these data contain no evidence that would allow us to reject <span class="math inline">\(H_0: \beta_1 = 0.02\)</span> vs. <span class="math inline">\(H_a: \beta_1 \ne 0.02\)</span> at any reasonable significance level.</p>
<p>Confusion alert: Do be mindful of the distinction between a statistical hypothesis and a scientific hypothesis. The following excerpt from an article by B. Dennis and M.L. Taper puts it nicely: ``A statistical hypothesis is an assumption about the form of a probability model, and a statistical hypothesis test is the use of data to make a decision between two probability models. A scientific hypothesis, on the other hand, is an explanatory assertion about some aspect of nature.’’ (, 1994, v64 p210). Thus, while a statistical hypothesis can often embody a scientific hypothesis, a scientific hypothesis does not always boil down to a statistical hypothesis.</p>
</div>
<div id="inference-for-the-intercept" class="section level3" number="1.3.4">
<h3><span class="header-section-number">1.3.4</span> Inference for the intercept</h3>
<p>Most statistical packages automatically provide the standard errors for the intercept, $s_{} $, as well as a test of <span class="math inline">\(H_0: \beta_0 = 0\)</span> vs. <span class="math inline">\(H_a: \beta_0 \ne 0\)</span>. Sometimes this is a meaningful test, but usually it isn’t. The scientific context of the problem will determine whether or not it makes sense to pay attention to this test.</p>
<p>There is a special type of regression called ``regression through the origin’’ that is appropriate when we can assume <span class="math inline">\(\beta_0 = 0\)</span> automatically. Should we use regression through the origin for the BAC example?</p>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>


    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"search": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
